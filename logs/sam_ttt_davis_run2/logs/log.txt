INFO 2025-12-09 22:14:39,694 train_utils.py: 108: MACHINE SEED: 6150
INFO 2025-12-09 22:14:39,695 train_utils.py: 154: Logging ENV_VARIABLES
INFO 2025-12-09 22:14:39,695 train_utils.py: 155: AgentHost=10.17.176.67
AutoDLContainerMonitorSetting=
AutoDLContainerUUID=c6d54aa471-2ea91646
AutoDLDataCenter=neimengDC2
AutoDLRegion=nm-A1
AutoDLService6006URL=https://u829339-a471-2ea91646.nma1.seetacloud.com:8448
AutoDLService6008URL=https://uu829339-a471-2ea91646.nma1.seetacloud.com:8448
AutoDLServiceURL=https://u829339-a471-2ea91646.nma1.seetacloud.com:8448
AutodlAutoPanelToken=jupyter-autodl-container-c69945a881-892d9774-6ddd30cef03e642fcbb23db5203d964cbcb4bbac56da548f7ba86e0aef3fc6423
BROWSER=/root/.vscode-server/cli/servers/Stable-bf9252a2fb45be6893dd8870c0bf37e2e1766d61/server/bin/helpers/browser.sh
COLORTERM=truecolor
CONDA_DEFAULT_ENV=ttt_sam
CONDA_EXE=/root/miniconda3/bin/conda
CONDA_PREFIX=/root/miniconda3/envs/ttt_sam
CONDA_PREFIX_1=/root/miniconda3
CONDA_PROMPT_MODIFIER=(ttt_sam) 
CONDA_PYTHON_EXE=/root/miniconda3/bin/python
CONDA_SHLVL=2
CUDA_MODULE_LOADING=LAZY
GIT_ASKPASS=/root/.vscode-server/cli/servers/Stable-bf9252a2fb45be6893dd8870c0bf37e2e1766d61/server/extensions/git/dist/askpass.sh
GIT_PAGER=cat
HOME=/root
HYDRA_FULL_ERROR=1
LANG=C.UTF-8
LOCAL_RANK=0
LOGNAME=root
LS_COLORS=rs=0:di=01;34:ln=01;36:mh=00:pi=40;33:so=01;35:do=01;35:bd=40;33;01:cd=40;33;01:or=40;31;01:mi=00:su=37;41:sg=30;43:ca=30;41:tw=30;42:ow=34;42:st=37;44:ex=01;32:*.tar=01;31:*.tgz=01;31:*.arc=01;31:*.arj=01;31:*.taz=01;31:*.lha=01;31:*.lz4=01;31:*.lzh=01;31:*.lzma=01;31:*.tlz=01;31:*.txz=01;31:*.tzo=01;31:*.t7z=01;31:*.zip=01;31:*.z=01;31:*.dz=01;31:*.gz=01;31:*.lrz=01;31:*.lz=01;31:*.lzo=01;31:*.xz=01;31:*.zst=01;31:*.tzst=01;31:*.bz2=01;31:*.bz=01;31:*.tbz=01;31:*.tbz2=01;31:*.tz=01;31:*.deb=01;31:*.rpm=01;31:*.jar=01;31:*.war=01;31:*.ear=01;31:*.sar=01;31:*.rar=01;31:*.alz=01;31:*.ace=01;31:*.zoo=01;31:*.cpio=01;31:*.7z=01;31:*.rz=01;31:*.cab=01;31:*.wim=01;31:*.swm=01;31:*.dwm=01;31:*.esd=01;31:*.jpg=01;35:*.jpeg=01;35:*.mjpg=01;35:*.mjpeg=01;35:*.gif=01;35:*.bmp=01;35:*.pbm=01;35:*.pgm=01;35:*.ppm=01;35:*.tga=01;35:*.xbm=01;35:*.xpm=01;35:*.tif=01;35:*.tiff=01;35:*.png=01;35:*.svg=01;35:*.svgz=01;35:*.mng=01;35:*.pcx=01;35:*.mov=01;35:*.mpg=01;35:*.mpeg=01;35:*.m2v=01;35:*.mkv=01;35:*.webm=01;35:*.webp=01;35:*.ogm=01;35:*.mp4=01;35:*.m4v=01;35:*.mp4v=01;35:*.vob=01;35:*.qt=01;35:*.nuv=01;35:*.wmv=01;35:*.asf=01;35:*.rm=01;35:*.rmvb=01;35:*.flc=01;35:*.avi=01;35:*.fli=01;35:*.flv=01;35:*.gl=01;35:*.dl=01;35:*.xcf=01;35:*.xwd=01;35:*.yuv=01;35:*.cgm=01;35:*.emf=01;35:*.ogv=01;35:*.ogx=01;35:*.aac=00;36:*.au=00;36:*.flac=00;36:*.m4a=00;36:*.mid=00;36:*.midi=00;36:*.mka=00;36:*.mp3=00;36:*.mpc=00;36:*.ogg=00;36:*.ra=00;36:*.wav=00;36:*.oga=00;36:*.opus=00;36:*.spx=00;36:*.xspf=00;36:
MASTER_ADDR=localhost
MASTER_PORT=48740
MKL_NUM_THREADS=14
MOTD_SHOWN=pam
OLDPWD=/root/autodl-tmp/ttt_rr
OMP_NUM_THREADS=14
PATH=/root/miniconda3/envs/ttt_sam/bin:/usr/local/bin:/root/.vscode-server/data/User/globalStorage/github.copilot-chat/debugCommand:/root/.vscode-server/data/User/globalStorage/github.copilot-chat/copilotCli:/root/.vscode-server/cli/servers/Stable-bf9252a2fb45be6893dd8870c0bf37e2e1766d61/server/bin/remote-cli:/root/miniconda3/bin:/root/miniconda3/condabin:/root/miniconda3/bin:/usr/local/bin:/root/miniconda3/bin:/usr/local/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin
PWD=/root/autodl-tmp/ttt_rr
PYTHONPATH=:.:.:.
RANK=0
REQUESTS_CA_BUNDLE=/etc/ssl/certs/ca-certificates.crt
SHELL=/bin/bash
SHLVL=1
SSH_CLIENT=127.0.0.1 39646 22
SSH_CONNECTION=127.0.0.1 39646 127.0.0.1 22
SSL_CERT_DIR=/usr/lib/ssl/certs
SSL_CERT_FILE=/usr/lib/ssl/certs/ca-certificates.crt
TERM=xterm-256color
TERM_PROGRAM=vscode
TERM_PROGRAM_VERSION=1.106.3
TORCH_NCCL_ASYNC_ERROR_HANDLING=1
TZ=Asia/Shanghai
USER=root
VSCODE_GIT_ASKPASS_EXTRA_ARGS=
VSCODE_GIT_ASKPASS_MAIN=/root/.vscode-server/cli/servers/Stable-bf9252a2fb45be6893dd8870c0bf37e2e1766d61/server/extensions/git/dist/askpass-main.js
VSCODE_GIT_ASKPASS_NODE=/root/.vscode-server/cli/servers/Stable-bf9252a2fb45be6893dd8870c0bf37e2e1766d61/server/node
VSCODE_GIT_IPC_HANDLE=/tmp/vscode-git-1853e26595.sock
VSCODE_IPC_HOOK_CLI=/tmp/vscode-ipc-b03f0d85-68a5-403a-9691-fb91abace89e.sock
VSCODE_PYTHON_AUTOACTIVATE_GUARD=1
WORLD_SIZE=1
_=/root/miniconda3/envs/ttt_sam/bin/python
_CE_CONDA=
_CE_M=

INFO 2025-12-09 22:14:39,695 trainer.py: 989: Setting up components: Model, loss, optim, meters etc.
INFO 2025-12-09 22:14:39,696 logger.py:  66: TensorBoard SummaryWriter instantiated. Files will be stored in: ./logs/sam_ttt_davis_run2/tensorboard
INFO 2025-12-09 22:14:41,211 sam2.py:  81: Training with points (sampled from masks) as inputs with p=0.5
INFO 2025-12-09 22:14:41,217 trainer.py:1059: ====================
INFO 2025-12-09 22:14:41,217 trainer.py:1060: Summary for model <class 'training.model.sam2.SAM2Train'>
INFO 2025-12-09 22:14:41,220 trainer.py:1061: Model is SAM2Train(
  (image_encoder): ImageEncoder(
    (trunk): Hiera(
      (patch_embed): PatchEmbed(
        (proj): Conv2d(3, 144, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))
      )
      (blocks): ModuleList(
        (0-1): 2 x MultiScaleBlock(
          (norm1): LayerNorm((144,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=144, out_features=432, bias=True)
            (proj): Linear(in_features=144, out_features=144, bias=True)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((144,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=144, out_features=576, bias=True)
              (1): Linear(in_features=576, out_features=144, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
        (2): MultiScaleBlock(
          (norm1): LayerNorm((144,), eps=1e-06, elementwise_affine=True)
          (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
          (attn): MultiScaleAttention(
            (q_pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
            (qkv): Linear(in_features=144, out_features=864, bias=True)
            (proj): Linear(in_features=288, out_features=288, bias=True)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((288,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=288, out_features=1152, bias=True)
              (1): Linear(in_features=1152, out_features=288, bias=True)
            )
            (act): GELU(approximate='none')
          )
          (proj): Linear(in_features=144, out_features=288, bias=True)
        )
        (3-7): 5 x MultiScaleBlock(
          (norm1): LayerNorm((288,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=288, out_features=864, bias=True)
            (proj): Linear(in_features=288, out_features=288, bias=True)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((288,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=288, out_features=1152, bias=True)
              (1): Linear(in_features=1152, out_features=288, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
        (8): MultiScaleBlock(
          (norm1): LayerNorm((288,), eps=1e-06, elementwise_affine=True)
          (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
          (attn): MultiScaleAttention(
            (q_pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
            (qkv): Linear(in_features=288, out_features=1728, bias=True)
            (proj): Linear(in_features=576, out_features=576, bias=True)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((576,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=576, out_features=2304, bias=True)
              (1): Linear(in_features=2304, out_features=576, bias=True)
            )
            (act): GELU(approximate='none')
          )
          (proj): Linear(in_features=288, out_features=576, bias=True)
        )
        (9-43): 35 x MultiScaleBlock(
          (norm1): LayerNorm((576,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=576, out_features=1728, bias=True)
            (proj): Linear(in_features=576, out_features=576, bias=True)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((576,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=576, out_features=2304, bias=True)
              (1): Linear(in_features=2304, out_features=576, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
        (44): MultiScaleBlock(
          (norm1): LayerNorm((576,), eps=1e-06, elementwise_affine=True)
          (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
          (attn): MultiScaleAttention(
            (q_pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
            (qkv): Linear(in_features=576, out_features=3456, bias=True)
            (proj): Linear(in_features=1152, out_features=1152, bias=True)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=1152, out_features=4608, bias=True)
              (1): Linear(in_features=4608, out_features=1152, bias=True)
            )
            (act): GELU(approximate='none')
          )
          (proj): Linear(in_features=576, out_features=1152, bias=True)
        )
        (45-47): 3 x MultiScaleBlock(
          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=1152, out_features=3456, bias=True)
            (proj): Linear(in_features=1152, out_features=1152, bias=True)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=1152, out_features=4608, bias=True)
              (1): Linear(in_features=4608, out_features=1152, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
      )
    )
    (neck): FpnNeck(
      (position_encoding): PositionEmbeddingSine()
      (convs): ModuleList(
        (0): Sequential(
          (conv): Conv2d(1152, 256, kernel_size=(1, 1), stride=(1, 1))
        )
        (1): Sequential(
          (conv): Conv2d(576, 256, kernel_size=(1, 1), stride=(1, 1))
        )
        (2): Sequential(
          (conv): Conv2d(288, 256, kernel_size=(1, 1), stride=(1, 1))
        )
        (3): Sequential(
          (conv): Conv2d(144, 256, kernel_size=(1, 1), stride=(1, 1))
        )
      )
    )
  )
  (mask_downsample): Conv2d(1, 1, kernel_size=(4, 4), stride=(4, 4))
  (memory_attention): MemoryAttention(
    (layers): ModuleList(
      (0-3): 4 x MemoryAttentionLayer(
        (self_attn): RoPEAttention(
          (q_proj): Linear(in_features=256, out_features=256, bias=True)
          (k_proj): Linear(in_features=256, out_features=256, bias=True)
          (v_proj): Linear(in_features=256, out_features=256, bias=True)
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
        )
        (cross_attn_image): RoPEAttention(
          (q_proj): Linear(in_features=256, out_features=256, bias=True)
          (k_proj): Linear(in_features=64, out_features=256, bias=True)
          (v_proj): Linear(in_features=64, out_features=256, bias=True)
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
        )
        (linear1): Linear(in_features=256, out_features=2048, bias=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (linear2): Linear(in_features=2048, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.1, inplace=False)
        (dropout3): Dropout(p=0.1, inplace=False)
      )
    )
    (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (memory_encoder): MemoryEncoder(
    (mask_downsampler): MaskDownSampler(
      (encoder): Sequential(
        (0): Conv2d(1, 4, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (1): LayerNorm2d()
        (2): GELU(approximate='none')
        (3): Conv2d(4, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (4): LayerNorm2d()
        (5): GELU(approximate='none')
        (6): Conv2d(16, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (7): LayerNorm2d()
        (8): GELU(approximate='none')
        (9): Conv2d(64, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (10): LayerNorm2d()
        (11): GELU(approximate='none')
        (12): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (pix_feat_proj): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fuser): Fuser(
      (proj): Identity()
      (layers): ModuleList(
        (0-1): 2 x CXBlock(
          (dwconv): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)
          (norm): LayerNorm2d()
          (pwconv1): Linear(in_features=256, out_features=1024, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1024, out_features=256, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (position_encoding): PositionEmbeddingSine()
    (out_proj): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
  )
  (sam_prompt_encoder): PromptEncoder(
    (pe_layer): PositionEmbeddingRandom()
    (point_embeddings): ModuleList(
      (0-3): 4 x Embedding(1, 256)
    )
    (not_a_point_embed): Embedding(1, 256)
    (mask_downscaling): Sequential(
      (0): Conv2d(1, 4, kernel_size=(2, 2), stride=(2, 2))
      (1): LayerNorm2d()
      (2): GELU(approximate='none')
      (3): Conv2d(4, 16, kernel_size=(2, 2), stride=(2, 2))
      (4): LayerNorm2d()
      (5): GELU(approximate='none')
      (6): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))
    )
    (no_mask_embed): Embedding(1, 256)
  )
  (sam_mask_decoder): MaskDecoder(
    (transformer): TwoWayTransformer(
      (layers): ModuleList(
        (0-1): 2 x TwoWayAttentionBlock(
          (self_attn): Attention(
            (q_proj): Linear(in_features=256, out_features=256, bias=True)
            (k_proj): Linear(in_features=256, out_features=256, bias=True)
            (v_proj): Linear(in_features=256, out_features=256, bias=True)
            (out_proj): Linear(in_features=256, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (cross_attn_token_to_image): Attention(
            (q_proj): Linear(in_features=256, out_features=128, bias=True)
            (k_proj): Linear(in_features=256, out_features=128, bias=True)
            (v_proj): Linear(in_features=256, out_features=128, bias=True)
            (out_proj): Linear(in_features=128, out_features=256, bias=True)
          )
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=256, out_features=2048, bias=True)
              (1): Linear(in_features=2048, out_features=256, bias=True)
            )
            (act): ReLU()
          )
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (cross_attn_image_to_token): Attention(
            (q_proj): Linear(in_features=256, out_features=128, bias=True)
            (k_proj): Linear(in_features=256, out_features=128, bias=True)
            (v_proj): Linear(in_features=256, out_features=128, bias=True)
            (out_proj): Linear(in_features=128, out_features=256, bias=True)
          )
        )
      )
      (final_attn_token_to_image): Attention(
        (q_proj): Linear(in_features=256, out_features=128, bias=True)
        (k_proj): Linear(in_features=256, out_features=128, bias=True)
        (v_proj): Linear(in_features=256, out_features=128, bias=True)
        (out_proj): Linear(in_features=128, out_features=256, bias=True)
      )
      (norm_final_attn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (iou_token): Embedding(1, 256)
    (mask_tokens): Embedding(4, 256)
    (obj_score_token): Embedding(1, 256)
    (output_upscaling): Sequential(
      (0): ConvTranspose2d(256, 64, kernel_size=(2, 2), stride=(2, 2))
      (1): LayerNorm2d()
      (2): GELU(approximate='none')
      (3): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2))
      (4): GELU(approximate='none')
    )
    (conv_s0): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
    (conv_s1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
    (output_hypernetworks_mlps): ModuleList(
      (0-3): 4 x MLP(
        (layers): ModuleList(
          (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=32, bias=True)
        )
        (act): ReLU()
      )
    )
    (iou_prediction_head): MLP(
      (layers): ModuleList(
        (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=4, bias=True)
      )
      (act): ReLU()
    )
    (pred_obj_score_head): MLP(
      (layers): ModuleList(
        (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=1, bias=True)
      )
      (act): ReLU()
    )
  )
  (obj_ptr_proj): MLP(
    (layers): ModuleList(
      (0-2): 3 x Linear(in_features=256, out_features=256, bias=True)
    )
    (act): ReLU()
  )
  (obj_ptr_tpos_proj): Linear(in_features=256, out_features=64, bias=True)
  (DWT): extract_high_frequency(
    (dwt): DWT()
  )
  (ME): ME(
    (depthwise_conv_reduce_channels_in): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), groups=32)
    (depthwise_conv_reduce_channels_out1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), groups=32)
    (depthwise_conv_reduce_channels_out2): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), groups=32)
    (relu): ReLU(inplace=True)
    (branch1): Sequential(
      (0): BasicConv2d(
        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): GroupNorm(32, 256, eps=1e-05, affine=True)
        (relu): ReLU()
      )
      (1): BasicConv2d(
        (conv): Conv2d(256, 256, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
        (bn): GroupNorm(32, 256, eps=1e-05, affine=True)
        (relu): ReLU()
      )
      (2): BasicConv2d(
        (conv): Conv2d(256, 256, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
        (bn): GroupNorm(32, 256, eps=1e-05, affine=True)
        (relu): ReLU()
      )
      (3): BasicConv2d(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3), dilation=(3, 3), bias=False)
        (bn): GroupNorm(32, 256, eps=1e-05, affine=True)
        (relu): ReLU()
      )
    )
    (seq_modeling_block): TTTLinear(
      (q_proj): Linear(in_features=256, out_features=256, bias=False)
      (v_proj): Linear(in_features=256, out_features=256, bias=False)
      (o_proj): Linear(in_features=256, out_features=256, bias=False)
      (conv_q): Conv1d(256, 256, kernel_size=(4,), stride=(1,), padding=(3,), groups=256)
      (conv_k): Conv1d(256, 256, kernel_size=(4,), stride=(1,), padding=(3,), groups=256)
      (rotary_emb): RotaryEmbedding()
      (post_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
    )
    (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (embed_tokens): Embedding(256, 256)
  )
  (routefuse): routefuse(
    (conv_dense): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
  )
)
INFO 2025-12-09 22:14:41,220 trainer.py:1062: 	Total parameters 226 M
INFO 2025-12-09 22:14:41,220 trainer.py:1063: 	Trainable parameters 13.7 M
INFO 2025-12-09 22:14:41,220 trainer.py:1066: 	Non-Trainable parameters 212 M
INFO 2025-12-09 22:14:41,220 trainer.py:1069: ====================
INFO 2025-12-09 22:14:41,226 trainer.py:1023: Finished setting up components: Model, loss, optim, meters etc.
INFO 2025-12-09 22:14:41,226 trainer.py: 314: Moving components to device cuda:0 and local rank 0.
INFO 2025-12-09 22:14:41,369 trainer.py: 320: Done moving components to device cuda:0 and local rank 0.
INFO 2025-12-09 22:14:41,383 optimizer.py: 248: Matches for param_name [image_encoder.*]: {'image_encoder.trunk.blocks.32.attn.proj.bias', 'image_encoder.trunk.blocks.34.mlp.layers.1.weight', 'image_encoder.trunk.blocks.26.mlp.layers.0.weight', 'image_encoder.trunk.blocks.6.mlp.layers.1.weight', 'image_encoder.trunk.blocks.7.attn.qkv.weight', 'image_encoder.trunk.blocks.8.norm1.bias', 'image_encoder.trunk.blocks.42.norm2.weight', 'image_encoder.trunk.blocks.35.norm1.bias', 'image_encoder.trunk.blocks.31.norm2.weight', 'image_encoder.trunk.blocks.10.mlp.layers.0.weight', 'image_encoder.trunk.blocks.40.attn.proj.weight', 'image_encoder.trunk.blocks.23.mlp.layers.0.bias', 'image_encoder.trunk.blocks.39.mlp.layers.1.weight', 'image_encoder.trunk.blocks.11.attn.qkv.weight', 'image_encoder.trunk.blocks.0.mlp.layers.0.weight', 'image_encoder.trunk.blocks.46.norm2.bias', 'image_encoder.trunk.blocks.6.mlp.layers.1.bias', 'image_encoder.trunk.blocks.23.attn.qkv.weight', 'image_encoder.trunk.blocks.28.mlp.layers.1.bias', 'image_encoder.trunk.blocks.35.attn.qkv.weight', 'image_encoder.trunk.blocks.24.attn.qkv.weight', 'image_encoder.trunk.blocks.33.mlp.layers.1.weight', 'image_encoder.trunk.blocks.24.mlp.layers.0.weight', 'image_encoder.trunk.blocks.31.attn.proj.bias', 'image_encoder.trunk.blocks.39.attn.qkv.bias', 'image_encoder.trunk.blocks.25.attn.qkv.weight', 'image_encoder.trunk.blocks.33.attn.qkv.bias', 'image_encoder.trunk.blocks.40.mlp.layers.1.weight', 'image_encoder.trunk.blocks.37.attn.proj.weight', 'image_encoder.trunk.blocks.22.norm1.bias', 'image_encoder.trunk.blocks.38.norm1.bias', 'image_encoder.trunk.blocks.13.attn.qkv.weight', 'image_encoder.trunk.blocks.18.mlp.layers.0.weight', 'image_encoder.trunk.blocks.45.attn.qkv.bias', 'image_encoder.trunk.blocks.45.mlp.layers.0.weight', 'image_encoder.trunk.blocks.34.attn.proj.weight', 'image_encoder.trunk.blocks.41.mlp.layers.1.weight', 'image_encoder.trunk.blocks.2.attn.proj.weight', 'image_encoder.trunk.blocks.6.norm1.bias', 'image_encoder.trunk.blocks.36.attn.proj.weight', 'image_encoder.trunk.blocks.30.attn.proj.weight', 'image_encoder.trunk.blocks.39.norm1.weight', 'image_encoder.trunk.blocks.30.norm1.bias', 'image_encoder.trunk.blocks.0.attn.qkv.bias', 'image_encoder.trunk.blocks.11.norm2.weight', 'image_encoder.trunk.blocks.24.attn.qkv.bias', 'image_encoder.trunk.blocks.27.attn.proj.bias', 'image_encoder.trunk.blocks.33.attn.qkv.weight', 'image_encoder.trunk.blocks.47.attn.proj.weight', 'image_encoder.trunk.blocks.9.mlp.layers.0.weight', 'image_encoder.trunk.blocks.19.norm2.weight', 'image_encoder.trunk.blocks.43.norm2.weight', 'image_encoder.trunk.blocks.17.norm1.weight', 'image_encoder.trunk.blocks.29.attn.proj.weight', 'image_encoder.trunk.blocks.32.attn.qkv.bias', 'image_encoder.trunk.blocks.38.mlp.layers.0.bias', 'image_encoder.trunk.blocks.4.mlp.layers.0.bias', 'image_encoder.trunk.blocks.7.attn.proj.bias', 'image_encoder.trunk.blocks.11.norm2.bias', 'image_encoder.trunk.blocks.47.attn.proj.bias', 'image_encoder.trunk.blocks.27.attn.proj.weight', 'image_encoder.trunk.blocks.10.norm2.bias', 'image_encoder.trunk.blocks.1.mlp.layers.0.weight', 'image_encoder.trunk.blocks.0.attn.qkv.weight', 'image_encoder.trunk.blocks.20.mlp.layers.1.weight', 'image_encoder.trunk.blocks.43.mlp.layers.0.weight', 'image_encoder.trunk.blocks.20.attn.proj.bias', 'image_encoder.trunk.blocks.46.attn.proj.bias', 'image_encoder.trunk.blocks.21.attn.proj.weight', 'image_encoder.trunk.blocks.28.attn.qkv.weight', 'image_encoder.trunk.blocks.42.attn.qkv.bias', 'image_encoder.trunk.blocks.15.mlp.layers.0.weight', 'image_encoder.trunk.blocks.31.norm1.bias', 'image_encoder.trunk.blocks.35.norm2.weight', 'image_encoder.trunk.blocks.36.attn.proj.bias', 'image_encoder.trunk.blocks.16.norm2.bias', 'image_encoder.trunk.blocks.25.mlp.layers.0.weight', 'image_encoder.trunk.blocks.8.norm1.weight', 'image_encoder.trunk.blocks.9.mlp.layers.1.bias', 'image_encoder.trunk.blocks.6.norm2.bias', 'image_encoder.trunk.blocks.38.attn.proj.bias', 'image_encoder.trunk.blocks.29.attn.qkv.weight', 'image_encoder.trunk.blocks.38.norm1.weight', 'image_encoder.trunk.blocks.46.mlp.layers.1.bias', 'image_encoder.trunk.blocks.4.attn.proj.weight', 'image_encoder.trunk.blocks.18.attn.qkv.bias', 'image_encoder.trunk.blocks.29.norm1.weight', 'image_encoder.trunk.blocks.4.mlp.layers.0.weight', 'image_encoder.trunk.blocks.16.attn.proj.bias', 'image_encoder.trunk.blocks.9.norm1.bias', 'image_encoder.trunk.blocks.14.attn.qkv.bias', 'image_encoder.trunk.blocks.15.mlp.layers.0.bias', 'image_encoder.trunk.blocks.4.norm2.weight', 'image_encoder.trunk.blocks.25.norm2.bias', 'image_encoder.trunk.blocks.31.norm2.bias', 'image_encoder.trunk.blocks.33.norm2.weight', 'image_encoder.trunk.blocks.2.mlp.layers.1.bias', 'image_encoder.trunk.blocks.23.norm1.weight', 'image_encoder.trunk.blocks.10.norm1.weight', 'image_encoder.trunk.blocks.17.attn.proj.bias', 'image_encoder.trunk.blocks.10.norm1.bias', 'image_encoder.trunk.blocks.26.norm1.weight', 'image_encoder.trunk.blocks.39.mlp.layers.0.bias', 'image_encoder.trunk.blocks.22.norm2.bias', 'image_encoder.trunk.blocks.19.norm2.bias', 'image_encoder.trunk.blocks.25.norm1.weight', 'image_encoder.trunk.blocks.16.norm1.weight', 'image_encoder.trunk.blocks.28.attn.proj.bias', 'image_encoder.trunk.blocks.28.attn.proj.weight', 'image_encoder.trunk.blocks.42.mlp.layers.1.weight', 'image_encoder.trunk.blocks.39.mlp.layers.1.bias', 'image_encoder.trunk.blocks.0.norm1.bias', 'image_encoder.trunk.blocks.25.mlp.layers.0.bias', 'image_encoder.trunk.blocks.41.norm2.weight', 'image_encoder.trunk.blocks.15.attn.qkv.bias', 'image_encoder.trunk.blocks.47.norm2.weight', 'image_encoder.trunk.blocks.31.mlp.layers.1.bias', 'image_encoder.trunk.blocks.13.norm2.bias', 'image_encoder.trunk.blocks.23.attn.proj.weight', 'image_encoder.trunk.blocks.19.norm1.weight', 'image_encoder.trunk.blocks.7.norm2.bias', 'image_encoder.trunk.blocks.44.attn.proj.bias', 'image_encoder.trunk.blocks.6.mlp.layers.0.bias', 'image_encoder.trunk.blocks.0.mlp.layers.1.bias', 'image_encoder.trunk.blocks.4.mlp.layers.1.bias', 'image_encoder.trunk.blocks.36.norm2.weight', 'image_encoder.trunk.blocks.33.attn.proj.weight', 'image_encoder.trunk.blocks.40.mlp.layers.0.weight', 'image_encoder.trunk.blocks.3.attn.qkv.bias', 'image_encoder.trunk.blocks.19.attn.qkv.weight', 'image_encoder.trunk.blocks.27.norm1.weight', 'image_encoder.trunk.blocks.29.norm2.weight', 'image_encoder.trunk.blocks.2.norm1.bias', 'image_encoder.trunk.blocks.40.norm2.bias', 'image_encoder.trunk.blocks.14.norm2.weight', 'image_encoder.trunk.blocks.1.norm1.bias', 'image_encoder.trunk.blocks.14.mlp.layers.1.bias', 'image_encoder.trunk.blocks.2.mlp.layers.0.bias', 'image_encoder.trunk.blocks.6.attn.qkv.weight', 'image_encoder.trunk.blocks.35.norm1.weight', 'image_encoder.trunk.blocks.17.norm2.weight', 'image_encoder.trunk.blocks.13.mlp.layers.0.bias', 'image_encoder.trunk.blocks.25.attn.proj.weight', 'image_encoder.trunk.blocks.20.norm2.weight', 'image_encoder.trunk.blocks.26.norm1.bias', 'image_encoder.trunk.blocks.47.norm2.bias', 'image_encoder.trunk.blocks.19.mlp.layers.1.bias', 'image_encoder.trunk.blocks.31.mlp.layers.0.bias', 'image_encoder.trunk.blocks.36.attn.qkv.weight', 'image_encoder.trunk.blocks.1.attn.qkv.weight', 'image_encoder.trunk.blocks.35.mlp.layers.1.bias', 'image_encoder.trunk.blocks.7.norm1.weight', 'image_encoder.trunk.blocks.1.mlp.layers.0.bias', 'image_encoder.trunk.blocks.9.attn.qkv.bias', 'image_encoder.trunk.blocks.32.norm1.weight', 'image_encoder.trunk.blocks.31.mlp.layers.0.weight', 'image_encoder.trunk.blocks.17.mlp.layers.0.weight', 'image_encoder.trunk.blocks.22.mlp.layers.1.bias', 'image_encoder.trunk.blocks.11.mlp.layers.0.weight', 'image_encoder.trunk.blocks.26.norm2.weight', 'image_encoder.trunk.blocks.29.attn.proj.bias', 'image_encoder.trunk.blocks.6.attn.qkv.bias', 'image_encoder.trunk.blocks.3.mlp.layers.0.weight', 'image_encoder.trunk.blocks.3.mlp.layers.1.weight', 'image_encoder.trunk.blocks.15.norm1.weight', 'image_encoder.trunk.blocks.24.norm2.weight', 'image_encoder.trunk.blocks.3.mlp.layers.0.bias', 'image_encoder.trunk.blocks.33.mlp.layers.1.bias', 'image_encoder.neck.convs.1.conv.bias', 'image_encoder.trunk.blocks.14.mlp.layers.0.weight', 'image_encoder.trunk.blocks.17.attn.proj.weight', 'image_encoder.trunk.blocks.15.attn.proj.bias', 'image_encoder.trunk.blocks.18.mlp.layers.0.bias', 'image_encoder.trunk.blocks.13.attn.proj.bias', 'image_encoder.trunk.blocks.26.mlp.layers.1.weight', 'image_encoder.trunk.blocks.9.norm1.weight', 'image_encoder.trunk.patch_embed.proj.weight', 'image_encoder.trunk.blocks.27.mlp.layers.1.weight', 'image_encoder.trunk.blocks.10.mlp.layers.1.bias', 'image_encoder.trunk.blocks.28.norm2.weight', 'image_encoder.trunk.blocks.30.attn.qkv.bias', 'image_encoder.trunk.blocks.33.norm1.weight', 'image_encoder.trunk.blocks.18.attn.qkv.weight', 'image_encoder.trunk.blocks.45.norm2.bias', 'image_encoder.trunk.blocks.22.attn.qkv.weight', 'image_encoder.trunk.blocks.0.mlp.layers.0.bias', 'image_encoder.trunk.blocks.40.attn.proj.bias', 'image_encoder.trunk.blocks.2.proj.bias', 'image_encoder.trunk.blocks.2.mlp.layers.0.weight', 'image_encoder.trunk.blocks.47.mlp.layers.0.weight', 'image_encoder.trunk.blocks.41.norm1.weight', 'image_encoder.trunk.blocks.28.mlp.layers.0.bias', 'image_encoder.trunk.blocks.34.attn.qkv.weight', 'image_encoder.trunk.blocks.20.mlp.layers.0.weight', 'image_encoder.trunk.blocks.39.attn.qkv.weight', 'image_encoder.trunk.blocks.24.mlp.layers.1.bias', 'image_encoder.trunk.blocks.13.attn.proj.weight', 'image_encoder.trunk.blocks.28.norm1.bias', 'image_encoder.trunk.blocks.47.attn.qkv.weight', 'image_encoder.trunk.blocks.12.attn.proj.bias', 'image_encoder.trunk.blocks.14.mlp.layers.1.weight', 'image_encoder.trunk.blocks.21.attn.proj.bias', 'image_encoder.trunk.blocks.43.norm1.bias', 'image_encoder.trunk.blocks.35.mlp.layers.0.weight', 'image_encoder.trunk.blocks.29.mlp.layers.1.bias', 'image_encoder.trunk.blocks.24.norm2.bias', 'image_encoder.trunk.blocks.5.attn.proj.weight', 'image_encoder.trunk.blocks.24.mlp.layers.1.weight', 'image_encoder.trunk.blocks.43.attn.qkv.bias', 'image_encoder.trunk.blocks.14.attn.qkv.weight', 'image_encoder.trunk.blocks.3.norm2.weight', 'image_encoder.trunk.blocks.13.norm1.bias', 'image_encoder.trunk.blocks.24.attn.proj.bias', 'image_encoder.trunk.blocks.8.norm2.weight', 'image_encoder.trunk.blocks.1.norm2.bias', 'image_encoder.trunk.blocks.26.mlp.layers.1.bias', 'image_encoder.trunk.blocks.36.mlp.layers.1.bias', 'image_encoder.trunk.blocks.30.mlp.layers.1.bias', 'image_encoder.trunk.blocks.36.mlp.layers.0.weight', 'image_encoder.trunk.blocks.25.mlp.layers.1.bias', 'image_encoder.trunk.blocks.18.attn.proj.bias', 'image_encoder.trunk.blocks.25.norm2.weight', 'image_encoder.trunk.blocks.14.attn.proj.weight', 'image_encoder.trunk.blocks.28.mlp.layers.1.weight', 'image_encoder.trunk.blocks.40.mlp.layers.1.bias', 'image_encoder.trunk.blocks.33.attn.proj.bias', 'image_encoder.trunk.blocks.36.attn.qkv.bias', 'image_encoder.trunk.blocks.44.mlp.layers.1.bias', 'image_encoder.trunk.blocks.4.attn.qkv.bias', 'image_encoder.trunk.blocks.40.norm1.weight', 'image_encoder.trunk.blocks.14.norm2.bias', 'image_encoder.trunk.blocks.12.attn.proj.weight', 'image_encoder.trunk.blocks.46.norm1.bias', 'image_encoder.trunk.blocks.12.norm1.weight', 'image_encoder.trunk.blocks.22.norm2.weight', 'image_encoder.trunk.blocks.42.norm1.bias', 'image_encoder.trunk.blocks.35.attn.proj.bias', 'image_encoder.trunk.blocks.45.attn.proj.bias', 'image_encoder.trunk.blocks.34.norm1.bias', 'image_encoder.trunk.blocks.35.mlp.layers.1.weight', 'image_encoder.trunk.blocks.36.mlp.layers.0.bias', 'image_encoder.trunk.blocks.4.attn.qkv.weight', 'image_encoder.trunk.blocks.9.mlp.layers.1.weight', 'image_encoder.trunk.blocks.8.proj.bias', 'image_encoder.trunk.blocks.1.mlp.layers.1.bias', 'image_encoder.trunk.blocks.27.mlp.layers.0.bias', 'image_encoder.trunk.blocks.21.norm2.weight', 'image_encoder.trunk.blocks.20.mlp.layers.0.bias', 'image_encoder.trunk.blocks.41.norm1.bias', 'image_encoder.trunk.blocks.13.attn.qkv.bias', 'image_encoder.trunk.blocks.0.attn.proj.bias', 'image_encoder.trunk.blocks.23.norm2.bias', 'image_encoder.trunk.blocks.37.mlp.layers.0.weight', 'image_encoder.trunk.blocks.41.mlp.layers.1.bias', 'image_encoder.trunk.blocks.10.mlp.layers.1.weight', 'image_encoder.trunk.blocks.23.mlp.layers.0.weight', 'image_encoder.trunk.blocks.14.mlp.layers.0.bias', 'image_encoder.trunk.blocks.27.norm2.weight', 'image_encoder.trunk.blocks.45.mlp.layers.1.bias', 'image_encoder.trunk.blocks.32.mlp.layers.1.weight', 'image_encoder.trunk.blocks.3.norm1.bias', 'image_encoder.trunk.blocks.30.norm1.weight', 'image_encoder.trunk.blocks.20.attn.qkv.weight', 'image_encoder.trunk.blocks.46.mlp.layers.0.bias', 'image_encoder.trunk.blocks.17.mlp.layers.1.bias', 'image_encoder.trunk.blocks.8.mlp.layers.1.weight', 'image_encoder.trunk.blocks.21.mlp.layers.1.weight', 'image_encoder.trunk.blocks.39.attn.proj.weight', 'image_encoder.trunk.blocks.47.mlp.layers.1.weight', 'image_encoder.trunk.blocks.29.norm2.bias', 'image_encoder.trunk.blocks.38.norm2.weight', 'image_encoder.trunk.blocks.31.mlp.layers.1.weight', 'image_encoder.trunk.blocks.34.mlp.layers.1.bias', 'image_encoder.trunk.blocks.12.norm2.weight', 'image_encoder.trunk.blocks.34.mlp.layers.0.weight', 'image_encoder.trunk.blocks.41.norm2.bias', 'image_encoder.trunk.blocks.44.attn.qkv.weight', 'image_encoder.trunk.blocks.43.norm1.weight', 'image_encoder.trunk.blocks.46.attn.qkv.bias', 'image_encoder.trunk.blocks.10.norm2.weight', 'image_encoder.trunk.blocks.31.norm1.weight', 'image_encoder.trunk.blocks.18.mlp.layers.1.bias', 'image_encoder.trunk.blocks.16.norm1.bias', 'image_encoder.trunk.blocks.35.norm2.bias', 'image_encoder.trunk.blocks.27.attn.qkv.bias', 'image_encoder.trunk.blocks.44.norm1.bias', 'image_encoder.trunk.blocks.0.mlp.layers.1.weight', 'image_encoder.trunk.blocks.38.mlp.layers.1.bias', 'image_encoder.trunk.blocks.16.attn.proj.weight', 'image_encoder.trunk.blocks.23.norm1.bias', 'image_encoder.trunk.blocks.28.attn.qkv.bias', 'image_encoder.trunk.blocks.3.mlp.layers.1.bias', 'image_encoder.trunk.blocks.32.mlp.layers.0.bias', 'image_encoder.trunk.blocks.42.attn.proj.weight', 'image_encoder.trunk.blocks.19.attn.proj.weight', 'image_encoder.trunk.blocks.37.norm1.weight', 'image_encoder.trunk.blocks.2.norm2.weight', 'image_encoder.trunk.blocks.24.attn.proj.weight', 'image_encoder.trunk.blocks.43.mlp.layers.1.weight', 'image_encoder.trunk.blocks.36.norm1.weight', 'image_encoder.trunk.blocks.26.attn.proj.weight', 'image_encoder.trunk.blocks.32.norm2.weight', 'image_encoder.trunk.blocks.36.norm1.bias', 'image_encoder.trunk.blocks.0.norm2.bias', 'image_encoder.trunk.blocks.44.attn.qkv.bias', 'image_encoder.trunk.blocks.12.norm1.bias', 'image_encoder.trunk.patch_embed.proj.bias', 'image_encoder.trunk.blocks.23.norm2.weight', 'image_encoder.trunk.blocks.11.mlp.layers.1.weight', 'image_encoder.trunk.blocks.2.attn.qkv.weight', 'image_encoder.trunk.blocks.21.mlp.layers.1.bias', 'image_encoder.trunk.blocks.41.mlp.layers.0.bias', 'image_encoder.trunk.blocks.42.mlp.layers.0.bias', 'image_encoder.trunk.blocks.12.mlp.layers.0.bias', 'image_encoder.trunk.blocks.9.attn.qkv.weight', 'image_encoder.trunk.blocks.18.norm1.weight', 'image_encoder.trunk.blocks.43.mlp.layers.0.bias', 'image_encoder.trunk.blocks.19.mlp.layers.0.weight', 'image_encoder.trunk.blocks.17.attn.qkv.weight', 'image_encoder.trunk.blocks.7.mlp.layers.1.weight', 'image_encoder.trunk.blocks.32.attn.proj.weight', 'image_encoder.trunk.blocks.40.attn.qkv.weight', 'image_encoder.trunk.blocks.2.norm2.bias', 'image_encoder.trunk.blocks.10.attn.proj.weight', 'image_encoder.trunk.blocks.37.attn.proj.bias', 'image_encoder.trunk.blocks.23.mlp.layers.1.weight', 'image_encoder.trunk.blocks.38.mlp.layers.0.weight', 'image_encoder.trunk.blocks.19.mlp.layers.0.bias', 'image_encoder.trunk.blocks.16.mlp.layers.0.weight', 'image_encoder.trunk.blocks.22.attn.proj.weight', 'image_encoder.trunk.blocks.36.mlp.layers.1.weight', 'image_encoder.trunk.blocks.16.mlp.layers.0.bias', 'image_encoder.trunk.blocks.12.mlp.layers.1.bias', 'image_encoder.trunk.blocks.19.mlp.layers.1.weight', 'image_encoder.trunk.blocks.44.norm2.bias', 'image_encoder.trunk.blocks.14.norm1.weight', 'image_encoder.trunk.blocks.44.mlp.layers.1.weight', 'image_encoder.trunk.blocks.44.proj.bias', 'image_encoder.trunk.blocks.29.mlp.layers.1.weight', 'image_encoder.trunk.blocks.35.attn.proj.weight', 'image_encoder.trunk.blocks.43.attn.proj.weight', 'image_encoder.trunk.blocks.12.norm2.bias', 'image_encoder.trunk.blocks.7.mlp.layers.1.bias', 'image_encoder.trunk.blocks.17.mlp.layers.1.weight', 'image_encoder.trunk.blocks.28.norm1.weight', 'image_encoder.trunk.blocks.9.mlp.layers.0.bias', 'image_encoder.trunk.blocks.1.attn.proj.weight', 'image_encoder.trunk.blocks.16.attn.qkv.bias', 'image_encoder.trunk.blocks.8.attn.proj.weight', 'image_encoder.trunk.blocks.42.norm1.weight', 'image_encoder.trunk.blocks.47.norm1.bias', 'image_encoder.trunk.blocks.23.mlp.layers.1.bias', 'image_encoder.trunk.blocks.34.norm2.bias', 'image_encoder.trunk.blocks.6.norm2.weight', 'image_encoder.trunk.blocks.25.norm1.bias', 'image_encoder.trunk.blocks.1.attn.proj.bias', 'image_encoder.trunk.blocks.26.attn.qkv.bias', 'image_encoder.trunk.blocks.46.attn.proj.weight', 'image_encoder.trunk.blocks.12.attn.qkv.weight', 'image_encoder.trunk.blocks.15.attn.proj.weight', 'image_encoder.trunk.blocks.44.norm2.weight', 'image_encoder.trunk.blocks.13.mlp.layers.0.weight', 'image_encoder.trunk.blocks.20.norm1.bias', 'image_encoder.trunk.blocks.11.attn.proj.weight', 'image_encoder.trunk.blocks.24.norm1.weight', 'image_encoder.trunk.blocks.45.mlp.layers.0.bias', 'image_encoder.trunk.blocks.42.mlp.layers.0.weight', 'image_encoder.trunk.blocks.41.attn.proj.bias', 'image_encoder.trunk.blocks.12.mlp.layers.0.weight', 'image_encoder.trunk.blocks.11.attn.proj.bias', 'image_encoder.trunk.blocks.34.mlp.layers.0.bias', 'image_encoder.trunk.blocks.9.norm2.bias', 'image_encoder.trunk.blocks.46.mlp.layers.0.weight', 'image_encoder.trunk.blocks.21.norm1.weight', 'image_encoder.trunk.blocks.37.mlp.layers.1.bias', 'image_encoder.trunk.blocks.15.attn.qkv.weight', 'image_encoder.trunk.blocks.45.mlp.layers.1.weight', 'image_encoder.trunk.blocks.32.mlp.layers.1.bias', 'image_encoder.trunk.blocks.17.mlp.layers.0.bias', 'image_encoder.trunk.blocks.24.mlp.layers.0.bias', 'image_encoder.trunk.blocks.8.mlp.layers.1.bias', 'image_encoder.trunk.blocks.4.norm1.bias', 'image_encoder.trunk.blocks.15.norm1.bias', 'image_encoder.trunk.blocks.19.attn.proj.bias', 'image_encoder.trunk.blocks.46.mlp.layers.1.weight', 'image_encoder.trunk.blocks.42.mlp.layers.1.bias', 'image_encoder.trunk.blocks.22.attn.qkv.bias', 'image_encoder.trunk.blocks.19.attn.qkv.bias', 'image_encoder.trunk.blocks.9.norm2.weight', 'image_encoder.trunk.blocks.21.attn.qkv.bias', 'image_encoder.trunk.blocks.17.norm1.bias', 'image_encoder.trunk.blocks.20.norm2.bias', 'image_encoder.trunk.blocks.18.norm2.bias', 'image_encoder.trunk.blocks.38.attn.qkv.weight', 'image_encoder.trunk.blocks.3.attn.proj.weight', 'image_encoder.trunk.blocks.22.mlp.layers.1.weight', 'image_encoder.trunk.blocks.31.attn.qkv.weight', 'image_encoder.trunk.blocks.24.norm1.bias', 'image_encoder.trunk.blocks.34.attn.proj.bias', 'image_encoder.trunk.blocks.5.mlp.layers.0.bias', 'image_encoder.trunk.blocks.21.attn.qkv.weight', 'image_encoder.trunk.blocks.38.attn.qkv.bias', 'image_encoder.trunk.blocks.44.mlp.layers.0.bias', 'image_encoder.trunk.blocks.13.norm1.weight', 'image_encoder.trunk.blocks.2.proj.weight', 'image_encoder.trunk.blocks.4.attn.proj.bias', 'image_encoder.trunk.blocks.43.norm2.bias', 'image_encoder.trunk.blocks.46.norm1.weight', 'image_encoder.trunk.blocks.39.attn.proj.bias', 'image_encoder.trunk.blocks.33.mlp.layers.0.weight', 'image_encoder.trunk.blocks.39.norm2.bias', 'image_encoder.trunk.blocks.37.norm2.bias', 'image_encoder.trunk.blocks.37.mlp.layers.0.bias', 'image_encoder.trunk.blocks.4.norm1.weight', 'image_encoder.trunk.blocks.26.mlp.layers.0.bias', 'image_encoder.trunk.blocks.2.attn.proj.bias', 'image_encoder.trunk.blocks.30.attn.proj.bias', 'image_encoder.trunk.blocks.0.attn.proj.weight', 'image_encoder.trunk.blocks.29.mlp.layers.0.bias', 'image_encoder.trunk.blocks.45.norm2.weight', 'image_encoder.trunk.blocks.16.attn.qkv.weight', 'image_encoder.trunk.pos_embed_window', 'image_encoder.trunk.blocks.5.norm2.bias', 'image_encoder.trunk.blocks.19.norm1.bias', 'image_encoder.trunk.blocks.37.norm2.weight', 'image_encoder.trunk.blocks.28.norm2.bias', 'image_encoder.trunk.blocks.18.norm1.bias', 'image_encoder.trunk.blocks.27.norm2.bias', 'image_encoder.neck.convs.3.conv.weight', 'image_encoder.trunk.blocks.12.mlp.layers.1.weight', 'image_encoder.trunk.blocks.30.mlp.layers.1.weight', 'image_encoder.trunk.blocks.14.attn.proj.bias', 'image_encoder.trunk.blocks.22.mlp.layers.0.bias', 'image_encoder.trunk.blocks.22.attn.proj.bias', 'image_encoder.trunk.blocks.33.mlp.layers.0.bias', 'image_encoder.trunk.blocks.5.mlp.layers.0.weight', 'image_encoder.trunk.blocks.42.attn.qkv.weight', 'image_encoder.trunk.blocks.42.attn.proj.bias', 'image_encoder.trunk.blocks.41.attn.proj.weight', 'image_encoder.trunk.blocks.47.norm1.weight', 'image_encoder.trunk.blocks.44.norm1.weight', 'image_encoder.trunk.blocks.46.attn.qkv.weight', 'image_encoder.trunk.blocks.7.mlp.layers.0.weight', 'image_encoder.trunk.blocks.14.norm1.bias', 'image_encoder.trunk.blocks.11.norm1.bias', 'image_encoder.trunk.blocks.4.norm2.bias', 'image_encoder.trunk.blocks.37.norm1.bias', 'image_encoder.trunk.blocks.39.norm2.weight', 'image_encoder.trunk.blocks.8.attn.qkv.weight', 'image_encoder.neck.convs.0.conv.bias', 'image_encoder.trunk.blocks.40.norm2.weight', 'image_encoder.trunk.blocks.16.mlp.layers.1.weight', 'image_encoder.trunk.blocks.5.norm2.weight', 'image_encoder.trunk.blocks.15.mlp.layers.1.weight', 'image_encoder.trunk.blocks.21.norm1.bias', 'image_encoder.trunk.blocks.11.mlp.layers.1.bias', 'image_encoder.trunk.blocks.38.mlp.layers.1.weight', 'image_encoder.trunk.blocks.30.mlp.layers.0.weight', 'image_encoder.trunk.blocks.43.mlp.layers.1.bias', 'image_encoder.trunk.blocks.47.mlp.layers.0.bias', 'image_encoder.trunk.blocks.29.norm1.bias', 'image_encoder.trunk.blocks.21.norm2.bias', 'image_encoder.trunk.blocks.7.attn.qkv.bias', 'image_encoder.trunk.blocks.30.mlp.layers.0.bias', 'image_encoder.neck.convs.1.conv.weight', 'image_encoder.trunk.blocks.1.mlp.layers.1.weight', 'image_encoder.trunk.blocks.47.attn.qkv.bias', 'image_encoder.trunk.blocks.41.attn.qkv.bias', 'image_encoder.trunk.blocks.13.mlp.layers.1.bias', 'image_encoder.trunk.blocks.7.norm1.bias', 'image_encoder.trunk.blocks.5.norm1.bias', 'image_encoder.trunk.blocks.47.mlp.layers.1.bias', 'image_encoder.trunk.blocks.5.mlp.layers.1.bias', 'image_encoder.neck.convs.3.conv.bias', 'image_encoder.trunk.blocks.5.attn.qkv.weight', 'image_encoder.trunk.blocks.35.mlp.layers.0.bias', 'image_encoder.trunk.blocks.11.norm1.weight', 'image_encoder.trunk.blocks.15.mlp.layers.1.bias', 'image_encoder.trunk.blocks.10.attn.qkv.weight', 'image_encoder.trunk.blocks.29.attn.qkv.bias', 'image_encoder.trunk.blocks.2.attn.qkv.bias', 'image_encoder.neck.convs.2.conv.bias', 'image_encoder.trunk.blocks.40.mlp.layers.0.bias', 'image_encoder.trunk.blocks.8.norm2.bias', 'image_encoder.trunk.blocks.45.attn.qkv.weight', 'image_encoder.trunk.blocks.22.norm1.weight', 'image_encoder.trunk.blocks.39.mlp.layers.0.weight', 'image_encoder.neck.convs.0.conv.weight', 'image_encoder.trunk.pos_embed', 'image_encoder.trunk.blocks.20.attn.proj.weight', 'image_encoder.trunk.blocks.39.norm1.bias', 'image_encoder.trunk.blocks.17.norm2.bias', 'image_encoder.trunk.blocks.33.norm1.bias', 'image_encoder.trunk.blocks.26.attn.proj.bias', 'image_encoder.neck.convs.2.conv.weight', 'image_encoder.trunk.blocks.16.norm2.weight', 'image_encoder.trunk.blocks.43.attn.proj.bias', 'image_encoder.trunk.blocks.28.mlp.layers.0.weight', 'image_encoder.trunk.blocks.4.mlp.layers.1.weight', 'image_encoder.trunk.blocks.2.norm1.weight', 'image_encoder.trunk.blocks.30.norm2.weight', 'image_encoder.trunk.blocks.43.attn.qkv.weight', 'image_encoder.trunk.blocks.1.attn.qkv.bias', 'image_encoder.trunk.blocks.42.norm2.bias', 'image_encoder.trunk.blocks.40.attn.qkv.bias', 'image_encoder.trunk.blocks.25.attn.qkv.bias', 'image_encoder.trunk.blocks.3.norm1.weight', 'image_encoder.trunk.blocks.15.norm2.bias', 'image_encoder.trunk.blocks.18.norm2.weight', 'image_encoder.trunk.blocks.37.attn.qkv.bias', 'image_encoder.trunk.blocks.7.norm2.weight', 'image_encoder.trunk.blocks.23.attn.proj.bias', 'image_encoder.trunk.blocks.21.mlp.layers.0.weight', 'image_encoder.trunk.blocks.6.attn.proj.bias', 'image_encoder.trunk.blocks.16.mlp.layers.1.bias', 'image_encoder.trunk.blocks.3.norm2.bias', 'image_encoder.trunk.blocks.44.mlp.layers.0.weight', 'image_encoder.trunk.blocks.5.attn.qkv.bias', 'image_encoder.trunk.blocks.11.mlp.layers.0.bias', 'image_encoder.trunk.blocks.8.proj.weight', 'image_encoder.trunk.blocks.5.mlp.layers.1.weight', 'image_encoder.trunk.blocks.10.mlp.layers.0.bias', 'image_encoder.trunk.blocks.27.mlp.layers.1.bias', 'image_encoder.trunk.blocks.34.attn.qkv.bias', 'image_encoder.trunk.blocks.22.mlp.layers.0.weight', 'image_encoder.trunk.blocks.10.attn.proj.bias', 'image_encoder.trunk.blocks.5.norm1.weight', 'image_encoder.trunk.blocks.32.attn.qkv.weight', 'image_encoder.trunk.blocks.44.proj.weight', 'image_encoder.trunk.blocks.31.attn.proj.weight', 'image_encoder.trunk.blocks.6.mlp.layers.0.weight', 'image_encoder.trunk.blocks.25.attn.proj.bias', 'image_encoder.trunk.blocks.13.norm2.weight', 'image_encoder.trunk.blocks.26.attn.qkv.weight', 'image_encoder.trunk.blocks.44.attn.proj.weight', 'image_encoder.trunk.blocks.2.mlp.layers.1.weight', 'image_encoder.trunk.blocks.37.mlp.layers.1.weight', 'image_encoder.trunk.blocks.18.attn.proj.weight', 'image_encoder.trunk.blocks.41.attn.qkv.weight', 'image_encoder.trunk.blocks.12.attn.qkv.bias', 'image_encoder.trunk.blocks.40.norm1.bias', 'image_encoder.trunk.blocks.38.attn.proj.weight', 'image_encoder.trunk.blocks.20.attn.qkv.bias', 'image_encoder.trunk.blocks.27.norm1.bias', 'image_encoder.trunk.blocks.9.attn.proj.weight', 'image_encoder.trunk.blocks.34.norm2.weight', 'image_encoder.trunk.blocks.20.norm1.weight', 'image_encoder.trunk.blocks.46.norm2.weight', 'image_encoder.trunk.blocks.27.attn.qkv.weight', 'image_encoder.trunk.blocks.32.norm2.bias', 'image_encoder.trunk.blocks.34.norm1.weight', 'image_encoder.trunk.blocks.7.mlp.layers.0.bias', 'image_encoder.trunk.blocks.30.attn.qkv.weight', 'image_encoder.trunk.blocks.18.mlp.layers.1.weight', 'image_encoder.trunk.blocks.25.mlp.layers.1.weight', 'image_encoder.trunk.blocks.21.mlp.layers.0.bias', 'image_encoder.trunk.blocks.26.norm2.bias', 'image_encoder.trunk.blocks.6.norm1.weight', 'image_encoder.trunk.blocks.45.attn.proj.weight', 'image_encoder.trunk.blocks.20.mlp.layers.1.bias', 'image_encoder.trunk.blocks.45.norm1.weight', 'image_encoder.trunk.blocks.11.attn.qkv.bias', 'image_encoder.trunk.blocks.8.attn.qkv.bias', 'image_encoder.trunk.blocks.32.mlp.layers.0.weight', 'image_encoder.trunk.blocks.23.attn.qkv.bias', 'image_encoder.trunk.blocks.8.mlp.layers.0.weight', 'image_encoder.trunk.blocks.27.mlp.layers.0.weight', 'image_encoder.trunk.blocks.13.mlp.layers.1.weight', 'image_encoder.trunk.blocks.29.mlp.layers.0.weight', 'image_encoder.trunk.blocks.3.attn.qkv.weight', 'image_encoder.trunk.blocks.1.norm2.weight', 'image_encoder.trunk.blocks.9.attn.proj.bias', 'image_encoder.trunk.blocks.3.attn.proj.bias', 'image_encoder.trunk.blocks.32.norm1.bias', 'image_encoder.trunk.blocks.6.attn.proj.weight', 'image_encoder.trunk.blocks.1.norm1.weight', 'image_encoder.trunk.blocks.0.norm1.weight', 'image_encoder.trunk.blocks.35.attn.qkv.bias', 'image_encoder.trunk.blocks.30.norm2.bias', 'image_encoder.trunk.blocks.31.attn.qkv.bias', 'image_encoder.trunk.blocks.8.mlp.layers.0.bias', 'image_encoder.trunk.blocks.15.norm2.weight', 'image_encoder.trunk.blocks.36.norm2.bias', 'image_encoder.trunk.blocks.38.norm2.bias', 'image_encoder.trunk.blocks.7.attn.proj.weight', 'image_encoder.trunk.blocks.41.mlp.layers.0.weight', 'image_encoder.trunk.blocks.8.attn.proj.bias', 'image_encoder.trunk.blocks.17.attn.qkv.bias', 'image_encoder.trunk.blocks.10.attn.qkv.bias', 'image_encoder.trunk.blocks.37.attn.qkv.weight', 'image_encoder.trunk.blocks.5.attn.proj.bias', 'image_encoder.trunk.blocks.33.norm2.bias', 'image_encoder.trunk.blocks.45.norm1.bias', 'image_encoder.trunk.blocks.0.norm2.weight'}
INFO 2025-12-09 22:14:41,384 optimizer.py: 248: Matches for param_name [*bias*]: {'image_encoder.trunk.blocks.32.attn.proj.bias', 'image_encoder.trunk.blocks.8.norm1.bias', 'image_encoder.trunk.blocks.35.norm1.bias', 'sam_mask_decoder.output_hypernetworks_mlps.1.layers.2.bias', 'image_encoder.trunk.blocks.23.mlp.layers.0.bias', 'obj_ptr_proj.layers.0.bias', 'image_encoder.trunk.blocks.46.norm2.bias', 'image_encoder.trunk.blocks.6.mlp.layers.1.bias', 'image_encoder.trunk.blocks.28.mlp.layers.1.bias', 'sam_mask_decoder.transformer.layers.0.cross_attn_token_to_image.q_proj.bias', 'sam_mask_decoder.transformer.layers.1.cross_attn_image_to_token.k_proj.bias', 'sam_prompt_encoder.mask_downscaling.0.bias', 'image_encoder.trunk.blocks.31.attn.proj.bias', 'image_encoder.trunk.blocks.39.attn.qkv.bias', 'image_encoder.trunk.blocks.33.attn.qkv.bias', 'memory_attention.layers.2.cross_attn_image.q_proj.bias', 'image_encoder.trunk.blocks.22.norm1.bias', 'image_encoder.trunk.blocks.38.norm1.bias', 'image_encoder.trunk.blocks.45.attn.qkv.bias', 'memory_attention.layers.3.cross_attn_image.k_proj.bias', 'sam_mask_decoder.output_hypernetworks_mlps.3.layers.2.bias', 'image_encoder.trunk.blocks.6.norm1.bias', 'image_encoder.trunk.blocks.30.norm1.bias', 'image_encoder.trunk.blocks.0.attn.qkv.bias', 'sam_mask_decoder.transformer.layers.0.self_attn.q_proj.bias', 'image_encoder.trunk.blocks.24.attn.qkv.bias', 'image_encoder.trunk.blocks.27.attn.proj.bias', 'sam_mask_decoder.transformer.final_attn_token_to_image.q_proj.bias', 'sam_mask_decoder.pred_obj_score_head.layers.2.bias', 'ME.depthwise_conv_reduce_channels_out2.bias', 'memory_attention.layers.0.self_attn.k_proj.bias', 'memory_attention.layers.1.cross_attn_image.v_proj.bias', 'sam_mask_decoder.transformer.layers.0.self_attn.v_proj.bias', 'sam_mask_decoder.output_upscaling.3.bias', 'memory_attention.layers.1.norm3.bias', 'memory_attention.layers.0.cross_attn_image.v_proj.bias', 'image_encoder.trunk.blocks.32.attn.qkv.bias', 'image_encoder.trunk.blocks.38.mlp.layers.0.bias', 'image_encoder.trunk.blocks.4.mlp.layers.0.bias', 'memory_attention.layers.2.norm2.bias', 'image_encoder.trunk.blocks.7.attn.proj.bias', 'image_encoder.trunk.blocks.11.norm2.bias', 'image_encoder.trunk.blocks.47.attn.proj.bias', 'ME.norm.bias', 'image_encoder.trunk.blocks.10.norm2.bias', 'memory_attention.layers.2.norm1.bias', 'ME.depthwise_conv_reduce_channels_out1.bias', 'sam_mask_decoder.output_hypernetworks_mlps.3.layers.0.bias', 'memory_encoder.pix_feat_proj.bias', 'image_encoder.trunk.blocks.20.attn.proj.bias', 'image_encoder.trunk.blocks.46.attn.proj.bias', 'image_encoder.trunk.blocks.42.attn.qkv.bias', 'image_encoder.trunk.blocks.31.norm1.bias', 'image_encoder.trunk.blocks.36.attn.proj.bias', 'ME.branch1.0.bn.bias', 'image_encoder.trunk.blocks.16.norm2.bias', 'sam_mask_decoder.transformer.layers.0.mlp.layers.0.bias', 'image_encoder.trunk.blocks.9.mlp.layers.1.bias', 'image_encoder.trunk.blocks.6.norm2.bias', 'image_encoder.trunk.blocks.38.attn.proj.bias', 'sam_mask_decoder.transformer.layers.0.norm4.bias', 'image_encoder.trunk.blocks.46.mlp.layers.1.bias', 'image_encoder.trunk.blocks.18.attn.qkv.bias', 'memory_attention.layers.3.self_attn.out_proj.bias', 'image_encoder.trunk.blocks.16.attn.proj.bias', 'memory_encoder.fuser.layers.0.pwconv2.bias', 'memory_attention.layers.1.norm1.bias', 'memory_attention.layers.0.linear1.bias', 'image_encoder.trunk.blocks.9.norm1.bias', 'image_encoder.trunk.blocks.14.attn.qkv.bias', 'image_encoder.trunk.blocks.15.mlp.layers.0.bias', 'image_encoder.trunk.blocks.25.norm2.bias', 'image_encoder.trunk.blocks.31.norm2.bias', 'sam_mask_decoder.iou_prediction_head.layers.0.bias', 'memory_encoder.fuser.layers.1.dwconv.bias', 'image_encoder.trunk.blocks.2.mlp.layers.1.bias', 'image_encoder.trunk.blocks.17.attn.proj.bias', 'image_encoder.trunk.blocks.10.norm1.bias', 'image_encoder.trunk.blocks.39.mlp.layers.0.bias', 'image_encoder.trunk.blocks.22.norm2.bias', 'image_encoder.trunk.blocks.19.norm2.bias', 'image_encoder.trunk.blocks.28.attn.proj.bias', 'memory_attention.layers.1.cross_attn_image.k_proj.bias', 'image_encoder.trunk.blocks.39.mlp.layers.1.bias', 'image_encoder.trunk.blocks.0.norm1.bias', 'image_encoder.trunk.blocks.25.mlp.layers.0.bias', 'sam_mask_decoder.transformer.layers.1.cross_attn_token_to_image.k_proj.bias', 'image_encoder.trunk.blocks.15.attn.qkv.bias', 'sam_mask_decoder.output_hypernetworks_mlps.2.layers.2.bias', 'ME.seq_modeling_block.post_norm.bias', 'image_encoder.trunk.blocks.31.mlp.layers.1.bias', 'image_encoder.trunk.blocks.13.norm2.bias', 'image_encoder.trunk.blocks.7.norm2.bias', 'image_encoder.trunk.blocks.44.attn.proj.bias', 'image_encoder.trunk.blocks.6.mlp.layers.0.bias', 'image_encoder.trunk.blocks.0.mlp.layers.1.bias', 'image_encoder.trunk.blocks.4.mlp.layers.1.bias', 'memory_attention.layers.3.self_attn.k_proj.bias', 'image_encoder.trunk.blocks.3.attn.qkv.bias', 'image_encoder.trunk.blocks.40.norm2.bias', 'image_encoder.trunk.blocks.2.norm1.bias', 'memory_attention.layers.1.cross_attn_image.q_proj.bias', 'image_encoder.trunk.blocks.1.norm1.bias', 'image_encoder.trunk.blocks.14.mlp.layers.1.bias', 'memory_attention.norm.bias', 'memory_encoder.fuser.layers.0.norm.bias', 'image_encoder.trunk.blocks.2.mlp.layers.0.bias', 'memory_encoder.mask_downsampler.encoder.3.bias', 'image_encoder.trunk.blocks.13.mlp.layers.0.bias', 'memory_encoder.fuser.layers.0.pwconv1.bias', 'image_encoder.trunk.blocks.26.norm1.bias', 'image_encoder.trunk.blocks.47.norm2.bias', 'image_encoder.trunk.blocks.19.mlp.layers.1.bias', 'image_encoder.trunk.blocks.31.mlp.layers.0.bias', 'sam_mask_decoder.transformer.layers.0.cross_attn_image_to_token.q_proj.bias', 'image_encoder.trunk.blocks.35.mlp.layers.1.bias', 'memory_attention.layers.1.self_attn.k_proj.bias', 'image_encoder.trunk.blocks.1.mlp.layers.0.bias', 'memory_attention.layers.1.self_attn.out_proj.bias', 'image_encoder.trunk.blocks.9.attn.qkv.bias', 'memory_attention.layers.0.cross_attn_image.k_proj.bias', 'image_encoder.trunk.blocks.22.mlp.layers.1.bias', 'image_encoder.trunk.blocks.29.attn.proj.bias', 'image_encoder.trunk.blocks.6.attn.qkv.bias', 'sam_mask_decoder.pred_obj_score_head.layers.0.bias', 'sam_mask_decoder.transformer.layers.0.cross_attn_token_to_image.k_proj.bias', 'image_encoder.trunk.blocks.3.mlp.layers.0.bias', 'image_encoder.trunk.blocks.33.mlp.layers.1.bias', 'image_encoder.neck.convs.1.conv.bias', 'obj_ptr_tpos_proj.bias', 'image_encoder.trunk.blocks.15.attn.proj.bias', 'image_encoder.trunk.blocks.18.mlp.layers.0.bias', 'image_encoder.trunk.blocks.13.attn.proj.bias', 'sam_mask_decoder.transformer.layers.1.cross_attn_image_to_token.q_proj.bias', 'sam_mask_decoder.output_upscaling.1.bias', 'image_encoder.trunk.blocks.10.mlp.layers.1.bias', 'sam_mask_decoder.pred_obj_score_head.layers.1.bias', 'image_encoder.trunk.blocks.30.attn.qkv.bias', 'memory_attention.layers.3.cross_attn_image.q_proj.bias', 'ME.branch1.1.bn.bias', 'memory_encoder.out_proj.bias', 'image_encoder.trunk.blocks.45.norm2.bias', 'image_encoder.trunk.blocks.0.mlp.layers.0.bias', 'image_encoder.trunk.blocks.40.attn.proj.bias', 'memory_attention.layers.3.norm2.bias', 'image_encoder.trunk.blocks.2.proj.bias', 'sam_mask_decoder.transformer.norm_final_attn.bias', 'sam_mask_decoder.transformer.layers.1.mlp.layers.0.bias', 'image_encoder.trunk.blocks.28.mlp.layers.0.bias', 'image_encoder.trunk.blocks.24.mlp.layers.1.bias', 'image_encoder.trunk.blocks.28.norm1.bias', 'mask_downsample.bias', 'image_encoder.trunk.blocks.12.attn.proj.bias', 'image_encoder.trunk.blocks.21.attn.proj.bias', 'image_encoder.trunk.blocks.43.norm1.bias', 'image_encoder.trunk.blocks.29.mlp.layers.1.bias', 'image_encoder.trunk.blocks.24.norm2.bias', 'sam_mask_decoder.conv_s0.bias', 'sam_mask_decoder.transformer.layers.1.self_attn.out_proj.bias', 'image_encoder.trunk.blocks.43.attn.qkv.bias', 'image_encoder.trunk.blocks.13.norm1.bias', 'image_encoder.trunk.blocks.24.attn.proj.bias', 'memory_attention.layers.0.linear2.bias', 'image_encoder.trunk.blocks.1.norm2.bias', 'image_encoder.trunk.blocks.26.mlp.layers.1.bias', 'image_encoder.trunk.blocks.36.mlp.layers.1.bias', 'memory_attention.layers.0.cross_attn_image.out_proj.bias', 'image_encoder.trunk.blocks.30.mlp.layers.1.bias', 'image_encoder.trunk.blocks.25.mlp.layers.1.bias', 'image_encoder.trunk.blocks.18.attn.proj.bias', 'memory_attention.layers.2.self_attn.v_proj.bias', 'sam_mask_decoder.transformer.layers.0.self_attn.out_proj.bias', 'memory_attention.layers.1.norm2.bias', 'image_encoder.trunk.blocks.40.mlp.layers.1.bias', 'memory_attention.layers.1.self_attn.v_proj.bias', 'image_encoder.trunk.blocks.33.attn.proj.bias', 'image_encoder.trunk.blocks.36.attn.qkv.bias', 'image_encoder.trunk.blocks.44.mlp.layers.1.bias', 'image_encoder.trunk.blocks.4.attn.qkv.bias', 'sam_mask_decoder.transformer.layers.0.norm3.bias', 'image_encoder.trunk.blocks.14.norm2.bias', 'image_encoder.trunk.blocks.46.norm1.bias', 'sam_prompt_encoder.mask_downscaling.1.bias', 'memory_attention.layers.0.norm2.bias', 'memory_attention.layers.1.linear2.bias', 'image_encoder.trunk.blocks.42.norm1.bias', 'image_encoder.trunk.blocks.35.attn.proj.bias', 'image_encoder.trunk.blocks.45.attn.proj.bias', 'memory_encoder.mask_downsampler.encoder.7.bias', 'image_encoder.trunk.blocks.34.norm1.bias', 'image_encoder.trunk.blocks.36.mlp.layers.0.bias', 'image_encoder.trunk.blocks.8.proj.bias', 'image_encoder.trunk.blocks.1.mlp.layers.1.bias', 'memory_encoder.mask_downsampler.encoder.1.bias', 'image_encoder.trunk.blocks.27.mlp.layers.0.bias', 'image_encoder.trunk.blocks.20.mlp.layers.0.bias', 'ME.branch1.2.bn.bias', 'memory_encoder.mask_downsampler.encoder.4.bias', 'image_encoder.trunk.blocks.41.norm1.bias', 'image_encoder.trunk.blocks.13.attn.qkv.bias', 'image_encoder.trunk.blocks.0.attn.proj.bias', 'sam_mask_decoder.output_hypernetworks_mlps.0.layers.1.bias', 'image_encoder.trunk.blocks.23.norm2.bias', 'image_encoder.trunk.blocks.41.mlp.layers.1.bias', 'sam_mask_decoder.transformer.layers.0.cross_attn_image_to_token.v_proj.bias', 'image_encoder.trunk.blocks.14.mlp.layers.0.bias', 'image_encoder.trunk.blocks.45.mlp.layers.1.bias', 'image_encoder.trunk.blocks.3.norm1.bias', 'image_encoder.trunk.blocks.46.mlp.layers.0.bias', 'image_encoder.trunk.blocks.17.mlp.layers.1.bias', 'memory_attention.layers.3.linear2.bias', 'sam_mask_decoder.transformer.layers.1.self_attn.k_proj.bias', 'memory_attention.layers.0.norm1.bias', 'sam_mask_decoder.transformer.final_attn_token_to_image.v_proj.bias', 'image_encoder.trunk.blocks.29.norm2.bias', 'memory_attention.layers.3.self_attn.v_proj.bias', 'image_encoder.trunk.blocks.34.mlp.layers.1.bias', 'image_encoder.trunk.blocks.41.norm2.bias', 'memory_encoder.mask_downsampler.encoder.10.bias', 'image_encoder.trunk.blocks.46.attn.qkv.bias', 'sam_mask_decoder.transformer.final_attn_token_to_image.k_proj.bias', 'sam_mask_decoder.output_upscaling.0.bias', 'image_encoder.trunk.blocks.18.mlp.layers.1.bias', 'image_encoder.trunk.blocks.16.norm1.bias', 'image_encoder.trunk.blocks.35.norm2.bias', 'image_encoder.trunk.blocks.27.attn.qkv.bias', 'image_encoder.trunk.blocks.44.norm1.bias', 'image_encoder.trunk.blocks.38.mlp.layers.1.bias', 'image_encoder.trunk.blocks.23.norm1.bias', 'image_encoder.trunk.blocks.28.attn.qkv.bias', 'image_encoder.trunk.blocks.3.mlp.layers.1.bias', 'image_encoder.trunk.blocks.32.mlp.layers.0.bias', 'sam_mask_decoder.output_hypernetworks_mlps.0.layers.0.bias', 'ME.seq_modeling_block.learnable_ttt_lr_bias', 'ME.branch1.3.bn.bias', 'memory_encoder.mask_downsampler.encoder.12.bias', 'image_encoder.trunk.blocks.36.norm1.bias', 'memory_attention.layers.2.linear2.bias', 'sam_prompt_encoder.mask_downscaling.3.bias', 'image_encoder.trunk.blocks.0.norm2.bias', 'image_encoder.trunk.blocks.44.attn.qkv.bias', 'image_encoder.trunk.blocks.12.norm1.bias', 'image_encoder.trunk.patch_embed.proj.bias', 'image_encoder.trunk.blocks.41.mlp.layers.0.bias', 'image_encoder.trunk.blocks.21.mlp.layers.1.bias', 'image_encoder.trunk.blocks.42.mlp.layers.0.bias', 'image_encoder.trunk.blocks.12.mlp.layers.0.bias', 'memory_attention.layers.0.self_attn.out_proj.bias', 'image_encoder.trunk.blocks.43.mlp.layers.0.bias', 'image_encoder.trunk.blocks.2.norm2.bias', 'image_encoder.trunk.blocks.37.attn.proj.bias', 'image_encoder.trunk.blocks.19.mlp.layers.0.bias', 'memory_attention.layers.0.self_attn.q_proj.bias', 'memory_attention.layers.2.linear1.bias', 'image_encoder.trunk.blocks.16.mlp.layers.0.bias', 'image_encoder.trunk.blocks.12.mlp.layers.1.bias', 'image_encoder.trunk.blocks.44.norm2.bias', 'image_encoder.trunk.blocks.44.proj.bias', 'sam_mask_decoder.transformer.layers.0.cross_attn_token_to_image.out_proj.bias', 'memory_attention.layers.2.self_attn.k_proj.bias', 'image_encoder.trunk.blocks.12.norm2.bias', 'image_encoder.trunk.blocks.7.mlp.layers.1.bias', 'image_encoder.trunk.blocks.9.mlp.layers.0.bias', 'image_encoder.trunk.blocks.45.norm1.bias', 'image_encoder.trunk.blocks.16.attn.qkv.bias', 'image_encoder.trunk.blocks.47.norm1.bias', 'image_encoder.trunk.blocks.23.mlp.layers.1.bias', 'image_encoder.trunk.blocks.34.norm2.bias', 'image_encoder.trunk.blocks.25.norm1.bias', 'sam_mask_decoder.transformer.layers.0.cross_attn_image_to_token.k_proj.bias', 'image_encoder.trunk.blocks.1.attn.proj.bias', 'sam_mask_decoder.transformer.layers.0.self_attn.k_proj.bias', 'image_encoder.trunk.blocks.26.attn.qkv.bias', 'sam_mask_decoder.transformer.layers.1.norm3.bias', 'memory_attention.layers.2.norm3.bias', 'image_encoder.trunk.blocks.20.norm1.bias', 'image_encoder.trunk.blocks.45.mlp.layers.0.bias', 'image_encoder.trunk.blocks.41.attn.proj.bias', 'image_encoder.trunk.blocks.11.attn.proj.bias', 'image_encoder.trunk.blocks.34.mlp.layers.0.bias', 'image_encoder.trunk.blocks.9.norm2.bias', 'image_encoder.trunk.blocks.37.mlp.layers.1.bias', 'ME.seq_modeling_block.ttt_norm_bias', 'image_encoder.trunk.blocks.32.mlp.layers.1.bias', 'image_encoder.trunk.blocks.17.mlp.layers.0.bias', 'image_encoder.trunk.blocks.24.mlp.layers.0.bias', 'image_encoder.trunk.blocks.8.mlp.layers.1.bias', 'image_encoder.trunk.blocks.19.attn.proj.bias', 'image_encoder.trunk.blocks.4.norm1.bias', 'image_encoder.trunk.blocks.15.norm1.bias', 'image_encoder.trunk.blocks.42.mlp.layers.1.bias', 'image_encoder.trunk.blocks.22.attn.qkv.bias', 'memory_attention.layers.1.self_attn.q_proj.bias', 'image_encoder.trunk.blocks.19.attn.qkv.bias', 'image_encoder.trunk.blocks.21.attn.qkv.bias', 'image_encoder.trunk.blocks.17.norm1.bias', 'image_encoder.trunk.blocks.20.norm2.bias', 'image_encoder.trunk.blocks.18.norm2.bias', 'memory_attention.layers.2.self_attn.out_proj.bias', 'image_encoder.trunk.blocks.24.norm1.bias', 'image_encoder.trunk.blocks.34.attn.proj.bias', 'sam_prompt_encoder.mask_downscaling.6.bias', 'image_encoder.trunk.blocks.5.mlp.layers.0.bias', 'memory_attention.layers.3.cross_attn_image.out_proj.bias', 'image_encoder.trunk.blocks.38.attn.qkv.bias', 'image_encoder.trunk.blocks.44.mlp.layers.0.bias', 'memory_encoder.mask_downsampler.encoder.9.bias', 'sam_mask_decoder.conv_s1.bias', 'image_encoder.trunk.blocks.4.attn.proj.bias', 'image_encoder.trunk.blocks.43.norm2.bias', 'memory_attention.layers.3.self_attn.q_proj.bias', 'image_encoder.trunk.blocks.39.attn.proj.bias', 'image_encoder.trunk.blocks.39.norm2.bias', 'image_encoder.trunk.blocks.37.norm2.bias', 'image_encoder.trunk.blocks.37.mlp.layers.0.bias', 'image_encoder.trunk.blocks.26.mlp.layers.0.bias', 'sam_mask_decoder.transformer.layers.1.cross_attn_token_to_image.v_proj.bias', 'memory_attention.layers.3.linear1.bias', 'sam_prompt_encoder.mask_downscaling.4.bias', 'memory_encoder.fuser.layers.1.norm.bias', 'image_encoder.trunk.blocks.2.attn.proj.bias', 'image_encoder.trunk.blocks.30.attn.proj.bias', 'memory_attention.layers.2.self_attn.q_proj.bias', 'sam_mask_decoder.transformer.layers.1.norm2.bias', 'image_encoder.trunk.blocks.29.mlp.layers.0.bias', 'image_encoder.trunk.blocks.5.norm2.bias', 'image_encoder.trunk.blocks.19.norm1.bias', 'sam_mask_decoder.transformer.layers.1.self_attn.v_proj.bias', 'image_encoder.trunk.blocks.28.norm2.bias', 'image_encoder.trunk.blocks.18.norm1.bias', 'memory_attention.layers.1.linear1.bias', 'image_encoder.trunk.blocks.27.norm2.bias', 'sam_mask_decoder.transformer.layers.1.self_attn.q_proj.bias', 'sam_mask_decoder.transformer.layers.1.cross_attn_image_to_token.v_proj.bias', 'sam_mask_decoder.output_hypernetworks_mlps.0.layers.2.bias', 'image_encoder.trunk.blocks.14.attn.proj.bias', 'image_encoder.trunk.blocks.22.mlp.layers.0.bias', 'image_encoder.trunk.blocks.22.attn.proj.bias', 'image_encoder.trunk.blocks.33.mlp.layers.0.bias', 'sam_mask_decoder.iou_prediction_head.layers.1.bias', 'image_encoder.trunk.blocks.42.attn.proj.bias', 'memory_attention.layers.2.cross_attn_image.v_proj.bias', 'sam_mask_decoder.transformer.layers.1.norm4.bias', 'sam_mask_decoder.transformer.layers.1.cross_attn_token_to_image.q_proj.bias', 'image_encoder.trunk.blocks.14.norm1.bias', 'image_encoder.trunk.blocks.11.norm1.bias', 'image_encoder.trunk.blocks.4.norm2.bias', 'image_encoder.trunk.blocks.37.norm1.bias', 'obj_ptr_proj.layers.1.bias', 'image_encoder.neck.convs.0.conv.bias', 'sam_mask_decoder.output_hypernetworks_mlps.1.layers.1.bias', 'memory_encoder.mask_downsampler.encoder.0.bias', 'memory_attention.layers.3.norm1.bias', 'image_encoder.trunk.blocks.21.norm1.bias', 'image_encoder.trunk.blocks.11.mlp.layers.1.bias', 'image_encoder.trunk.blocks.43.mlp.layers.1.bias', 'memory_attention.layers.3.norm3.bias', 'obj_ptr_proj.layers.2.bias', 'image_encoder.trunk.blocks.47.mlp.layers.0.bias', 'image_encoder.trunk.blocks.29.norm1.bias', 'image_encoder.trunk.blocks.21.norm2.bias', 'image_encoder.trunk.blocks.7.attn.qkv.bias', 'image_encoder.trunk.blocks.30.mlp.layers.0.bias', 'memory_attention.layers.0.self_attn.v_proj.bias', 'image_encoder.trunk.blocks.47.attn.qkv.bias', 'image_encoder.trunk.blocks.41.attn.qkv.bias', 'image_encoder.trunk.blocks.13.mlp.layers.1.bias', 'sam_mask_decoder.transformer.layers.0.norm1.bias', 'ME.seq_modeling_block.conv_q.bias', 'sam_mask_decoder.transformer.final_attn_token_to_image.out_proj.bias', 'image_encoder.trunk.blocks.7.norm1.bias', 'image_encoder.trunk.blocks.5.norm1.bias', 'image_encoder.trunk.blocks.47.mlp.layers.1.bias', 'image_encoder.trunk.blocks.5.mlp.layers.1.bias', 'image_encoder.neck.convs.3.conv.bias', 'sam_mask_decoder.transformer.layers.0.cross_attn_token_to_image.v_proj.bias', 'image_encoder.trunk.blocks.35.mlp.layers.0.bias', 'image_encoder.trunk.blocks.15.mlp.layers.1.bias', 'image_encoder.trunk.blocks.29.attn.qkv.bias', 'memory_attention.layers.1.cross_attn_image.out_proj.bias', 'image_encoder.trunk.blocks.2.attn.qkv.bias', 'image_encoder.neck.convs.2.conv.bias', 'image_encoder.trunk.blocks.40.mlp.layers.0.bias', 'image_encoder.trunk.blocks.8.norm2.bias', 'memory_attention.layers.2.cross_attn_image.k_proj.bias', 'sam_mask_decoder.transformer.layers.0.mlp.layers.1.bias', 'image_encoder.trunk.blocks.39.norm1.bias', 'image_encoder.trunk.blocks.17.norm2.bias', 'image_encoder.trunk.blocks.33.norm1.bias', 'image_encoder.trunk.blocks.26.attn.proj.bias', 'image_encoder.trunk.blocks.43.attn.proj.bias', 'image_encoder.trunk.blocks.1.attn.qkv.bias', 'image_encoder.trunk.blocks.42.norm2.bias', 'image_encoder.trunk.blocks.40.attn.qkv.bias', 'image_encoder.trunk.blocks.25.attn.qkv.bias', 'sam_mask_decoder.transformer.layers.1.norm1.bias', 'image_encoder.trunk.blocks.15.norm2.bias', 'image_encoder.trunk.blocks.37.attn.qkv.bias', 'image_encoder.trunk.blocks.23.attn.proj.bias', 'image_encoder.trunk.blocks.6.attn.proj.bias', 'image_encoder.trunk.blocks.16.mlp.layers.1.bias', 'image_encoder.trunk.blocks.3.norm2.bias', 'memory_attention.layers.0.cross_attn_image.q_proj.bias', 'sam_mask_decoder.output_hypernetworks_mlps.2.layers.1.bias', 'image_encoder.trunk.blocks.5.attn.qkv.bias', 'image_encoder.trunk.blocks.11.mlp.layers.0.bias', 'sam_mask_decoder.output_hypernetworks_mlps.1.layers.0.bias', 'image_encoder.trunk.blocks.10.mlp.layers.0.bias', 'memory_attention.layers.3.cross_attn_image.v_proj.bias', 'image_encoder.trunk.blocks.27.mlp.layers.1.bias', 'image_encoder.trunk.blocks.34.attn.qkv.bias', 'image_encoder.trunk.blocks.10.attn.proj.bias', 'image_encoder.trunk.blocks.25.attn.proj.bias', 'sam_mask_decoder.transformer.layers.0.norm2.bias', 'sam_mask_decoder.transformer.layers.1.cross_attn_token_to_image.out_proj.bias', 'sam_mask_decoder.transformer.layers.1.mlp.layers.1.bias', 'memory_attention.layers.0.norm3.bias', 'image_encoder.trunk.blocks.12.attn.qkv.bias', 'image_encoder.trunk.blocks.40.norm1.bias', 'image_encoder.trunk.blocks.20.attn.qkv.bias', 'image_encoder.trunk.blocks.27.norm1.bias', 'memory_encoder.fuser.layers.0.dwconv.bias', 'sam_mask_decoder.transformer.layers.1.cross_attn_image_to_token.out_proj.bias', 'memory_encoder.mask_downsampler.encoder.6.bias', 'memory_attention.layers.2.cross_attn_image.out_proj.bias', 'memory_encoder.fuser.layers.1.pwconv2.bias', 'image_encoder.trunk.blocks.32.norm2.bias', 'sam_mask_decoder.output_hypernetworks_mlps.2.layers.0.bias', 'image_encoder.trunk.blocks.7.mlp.layers.0.bias', 'image_encoder.trunk.blocks.26.norm2.bias', 'image_encoder.trunk.blocks.21.mlp.layers.0.bias', 'image_encoder.trunk.blocks.20.mlp.layers.1.bias', 'image_encoder.trunk.blocks.11.attn.qkv.bias', 'image_encoder.trunk.blocks.8.attn.qkv.bias', 'ME.seq_modeling_block.conv_k.bias', 'image_encoder.trunk.blocks.23.attn.qkv.bias', 'image_encoder.trunk.blocks.9.attn.proj.bias', 'image_encoder.trunk.blocks.3.attn.proj.bias', 'sam_mask_decoder.output_hypernetworks_mlps.3.layers.1.bias', 'image_encoder.trunk.blocks.32.norm1.bias', 'memory_encoder.fuser.layers.1.pwconv1.bias', 'image_encoder.trunk.blocks.35.attn.qkv.bias', 'image_encoder.trunk.blocks.30.norm2.bias', 'image_encoder.trunk.blocks.31.attn.qkv.bias', 'image_encoder.trunk.blocks.8.mlp.layers.0.bias', 'image_encoder.trunk.blocks.36.norm2.bias', 'image_encoder.trunk.blocks.38.norm2.bias', 'image_encoder.trunk.blocks.8.attn.proj.bias', 'sam_mask_decoder.iou_prediction_head.layers.2.bias', 'image_encoder.trunk.blocks.17.attn.qkv.bias', 'image_encoder.trunk.blocks.10.attn.qkv.bias', 'sam_mask_decoder.transformer.layers.0.cross_attn_image_to_token.out_proj.bias', 'image_encoder.trunk.blocks.5.attn.proj.bias', 'ME.depthwise_conv_reduce_channels_in.bias', 'image_encoder.trunk.blocks.33.norm2.bias', 'routefuse.conv_dense.bias'}
INFO 2025-12-09 22:14:41,384 optimizer.py: 220: Matches for module_cls_name [torch.nn.LayerNorm]: {'memory_attention.norm.bias', 'image_encoder.trunk.blocks.37.norm1.weight', 'sam_mask_decoder.transformer.layers.1.norm2.weight', 'image_encoder.trunk.blocks.2.norm2.weight', 'image_encoder.trunk.blocks.35.norm1.weight', 'image_encoder.trunk.blocks.17.norm2.weight', 'image_encoder.trunk.blocks.36.norm1.weight', 'image_encoder.trunk.blocks.40.norm2.weight', 'memory_attention.layers.3.norm1.bias', 'image_encoder.trunk.blocks.32.norm2.weight', 'image_encoder.trunk.blocks.8.norm1.bias', 'image_encoder.trunk.blocks.20.norm2.weight', 'image_encoder.trunk.blocks.26.norm1.bias', 'image_encoder.trunk.blocks.36.norm1.bias', 'image_encoder.trunk.blocks.47.norm2.bias', 'image_encoder.trunk.blocks.35.norm1.bias', 'image_encoder.trunk.blocks.42.norm2.weight', 'memory_attention.layers.3.norm2.weight', 'image_encoder.trunk.blocks.0.norm2.bias', 'image_encoder.trunk.blocks.5.norm2.weight', 'image_encoder.trunk.blocks.31.norm2.weight', 'image_encoder.trunk.blocks.12.norm1.bias', 'image_encoder.trunk.blocks.21.norm1.bias', 'image_encoder.trunk.blocks.7.norm1.weight', 'image_encoder.trunk.blocks.23.norm2.weight', 'memory_attention.layers.3.norm3.bias', 'image_encoder.trunk.blocks.32.norm1.weight', 'image_encoder.trunk.blocks.29.norm1.bias', 'image_encoder.trunk.blocks.21.norm2.bias', 'image_encoder.trunk.blocks.26.norm2.weight', 'image_encoder.trunk.blocks.46.norm2.bias', 'image_encoder.trunk.blocks.18.norm1.weight', 'image_encoder.trunk.blocks.15.norm1.weight', 'image_encoder.trunk.blocks.24.norm2.weight', 'sam_mask_decoder.transformer.layers.0.norm1.bias', 'sam_mask_decoder.transformer.layers.1.norm1.weight', 'image_encoder.trunk.blocks.7.norm1.bias', 'image_encoder.trunk.blocks.5.norm1.bias', 'image_encoder.trunk.blocks.2.norm2.bias', 'image_encoder.trunk.blocks.9.norm1.weight', 'image_encoder.trunk.blocks.11.norm1.weight', 'image_encoder.trunk.blocks.22.norm1.bias', 'image_encoder.trunk.blocks.38.norm1.bias', 'ME.seq_modeling_block.post_norm.weight', 'image_encoder.trunk.blocks.44.norm2.bias', 'image_encoder.trunk.blocks.14.norm1.weight', 'image_encoder.trunk.blocks.8.norm2.bias', 'image_encoder.trunk.blocks.28.norm2.weight', 'memory_attention.layers.0.norm1.weight', 'image_encoder.trunk.blocks.22.norm1.weight', 'image_encoder.trunk.blocks.33.norm1.weight', 'memory_attention.layers.2.norm3.weight', 'image_encoder.trunk.blocks.6.norm1.bias', 'image_encoder.trunk.blocks.12.norm2.bias', 'image_encoder.trunk.blocks.45.norm2.bias', 'image_encoder.trunk.blocks.28.norm1.weight', 'image_encoder.trunk.blocks.39.norm1.weight', 'image_encoder.trunk.blocks.30.norm1.bias', 'memory_attention.layers.3.norm2.bias', 'image_encoder.trunk.blocks.39.norm1.bias', 'image_encoder.trunk.blocks.17.norm2.bias', 'sam_mask_decoder.transformer.norm_final_attn.bias', 'image_encoder.trunk.blocks.11.norm2.weight', 'image_encoder.trunk.blocks.45.norm1.bias', 'sam_mask_decoder.transformer.layers.0.norm3.weight', 'image_encoder.trunk.blocks.33.norm1.bias', 'image_encoder.trunk.blocks.41.norm1.weight', 'image_encoder.trunk.blocks.16.norm2.weight', 'memory_attention.layers.3.norm3.weight', 'image_encoder.trunk.blocks.19.norm2.weight', 'image_encoder.trunk.blocks.42.norm1.weight', 'image_encoder.trunk.blocks.2.norm1.weight', 'image_encoder.trunk.blocks.30.norm2.weight', 'image_encoder.trunk.blocks.43.norm2.weight', 'image_encoder.trunk.blocks.34.norm2.bias', 'image_encoder.trunk.blocks.42.norm2.bias', 'image_encoder.trunk.blocks.6.norm2.weight', 'image_encoder.trunk.blocks.25.norm1.bias', 'image_encoder.trunk.blocks.47.norm1.bias', 'ME.norm.weight', 'image_encoder.trunk.blocks.3.norm1.weight', 'image_encoder.trunk.blocks.15.norm2.bias', 'image_encoder.trunk.blocks.18.norm2.weight', 'sam_mask_decoder.transformer.layers.1.norm1.bias', 'sam_mask_decoder.transformer.layers.0.norm2.weight', 'sam_mask_decoder.transformer.layers.0.norm1.weight', 'image_encoder.trunk.blocks.28.norm1.bias', 'memory_attention.layers.1.norm3.bias', 'sam_mask_decoder.transformer.layers.1.norm3.bias', 'image_encoder.trunk.blocks.17.norm1.weight', 'sam_mask_decoder.transformer.layers.0.norm4.weight', 'image_encoder.trunk.blocks.7.norm2.weight', 'image_encoder.trunk.blocks.43.norm1.bias', 'image_encoder.trunk.blocks.3.norm2.bias', 'memory_attention.layers.2.norm2.bias', 'image_encoder.trunk.blocks.44.norm2.weight', 'image_encoder.trunk.blocks.11.norm2.bias', 'image_encoder.trunk.blocks.24.norm2.bias', 'memory_attention.layers.1.norm2.weight', 'memory_attention.layers.2.norm3.bias', 'image_encoder.trunk.blocks.3.norm2.weight', 'image_encoder.trunk.blocks.13.norm1.bias', 'image_encoder.trunk.blocks.20.norm1.bias', 'ME.norm.bias', 'image_encoder.trunk.blocks.24.norm1.weight', 'image_encoder.trunk.blocks.10.norm2.bias', 'memory_attention.layers.2.norm1.bias', 'image_encoder.trunk.blocks.8.norm2.weight', 'image_encoder.trunk.blocks.1.norm2.bias', 'image_encoder.trunk.blocks.5.norm1.weight', 'image_encoder.trunk.blocks.9.norm2.bias', 'image_encoder.trunk.blocks.21.norm1.weight', 'image_encoder.trunk.blocks.25.norm2.weight', 'sam_mask_decoder.transformer.layers.0.norm2.bias', 'image_encoder.trunk.blocks.13.norm2.weight', 'memory_attention.layers.1.norm1.weight', 'memory_attention.layers.1.norm2.bias', 'memory_attention.layers.2.norm1.weight', 'image_encoder.trunk.blocks.31.norm1.bias', 'memory_attention.layers.0.norm2.weight', 'image_encoder.trunk.blocks.35.norm2.weight', 'image_encoder.trunk.blocks.4.norm1.bias', 'image_encoder.trunk.blocks.15.norm1.bias', 'image_encoder.trunk.blocks.16.norm2.bias', 'memory_attention.layers.0.norm3.bias', 'image_encoder.trunk.blocks.8.norm1.weight', 'image_encoder.trunk.blocks.6.norm2.bias', 'image_encoder.trunk.blocks.9.norm2.weight', 'image_encoder.trunk.blocks.40.norm1.weight', 'image_encoder.trunk.blocks.40.norm1.bias', 'sam_mask_decoder.transformer.layers.0.norm3.bias', 'image_encoder.trunk.blocks.14.norm2.bias', 'image_encoder.trunk.blocks.17.norm1.bias', 'image_encoder.trunk.blocks.20.norm2.bias', 'image_encoder.trunk.blocks.27.norm1.bias', 'image_encoder.trunk.blocks.18.norm2.bias', 'image_encoder.trunk.blocks.46.norm1.bias', 'sam_mask_decoder.transformer.layers.0.norm4.bias', 'image_encoder.trunk.blocks.38.norm1.weight', 'memory_attention.layers.0.norm2.bias', 'image_encoder.trunk.blocks.12.norm1.weight', 'image_encoder.trunk.blocks.22.norm2.weight', 'image_encoder.trunk.blocks.29.norm1.weight', 'image_encoder.trunk.blocks.24.norm1.bias', 'image_encoder.trunk.blocks.20.norm1.weight', 'image_encoder.trunk.blocks.34.norm2.weight', 'image_encoder.trunk.blocks.42.norm1.bias', 'image_encoder.trunk.blocks.46.norm2.weight', 'memory_attention.layers.1.norm1.bias', 'image_encoder.trunk.blocks.13.norm1.weight', 'image_encoder.trunk.blocks.34.norm1.bias', 'image_encoder.trunk.blocks.9.norm1.bias', 'image_encoder.trunk.blocks.32.norm2.bias', 'image_encoder.trunk.blocks.43.norm2.bias', 'image_encoder.trunk.blocks.46.norm1.weight', 'image_encoder.trunk.blocks.34.norm1.weight', 'memory_attention.layers.0.norm3.weight', 'image_encoder.trunk.blocks.4.norm2.weight', 'image_encoder.trunk.blocks.25.norm2.bias', 'image_encoder.trunk.blocks.31.norm2.bias', 'image_encoder.trunk.blocks.26.norm2.bias', 'image_encoder.trunk.blocks.33.norm2.weight', 'image_encoder.trunk.blocks.37.norm2.bias', 'image_encoder.trunk.blocks.21.norm2.weight', 'image_encoder.trunk.blocks.39.norm2.bias', 'image_encoder.trunk.blocks.6.norm1.weight', 'sam_mask_decoder.transformer.layers.1.norm3.weight', 'image_encoder.trunk.blocks.23.norm1.weight', 'memory_attention.norm.weight', 'image_encoder.trunk.blocks.4.norm1.weight', 'image_encoder.trunk.blocks.10.norm1.weight', 'image_encoder.trunk.blocks.41.norm1.bias', 'memory_attention.layers.2.norm2.weight', 'sam_mask_decoder.transformer.layers.1.norm4.weight', 'image_encoder.trunk.blocks.45.norm1.weight', 'image_encoder.trunk.blocks.23.norm2.bias', 'image_encoder.trunk.blocks.10.norm1.bias', 'image_encoder.trunk.blocks.26.norm1.weight', 'sam_mask_decoder.transformer.layers.1.norm2.bias', 'image_encoder.trunk.blocks.22.norm2.bias', 'image_encoder.trunk.blocks.45.norm2.weight', 'image_encoder.trunk.blocks.19.norm2.bias', 'image_encoder.trunk.blocks.25.norm1.weight', 'image_encoder.trunk.blocks.16.norm1.weight', 'image_encoder.trunk.blocks.27.norm2.weight', 'image_encoder.trunk.blocks.5.norm2.bias', 'image_encoder.trunk.blocks.19.norm1.bias', 'image_encoder.trunk.blocks.3.norm1.bias', 'memory_attention.layers.3.norm1.weight', 'image_encoder.trunk.blocks.30.norm1.weight', 'image_encoder.trunk.blocks.37.norm2.weight', 'image_encoder.trunk.blocks.1.norm2.weight', 'image_encoder.trunk.blocks.28.norm2.bias', 'image_encoder.trunk.blocks.0.norm1.bias', 'image_encoder.trunk.blocks.18.norm1.bias', 'image_encoder.trunk.blocks.27.norm2.bias', 'image_encoder.trunk.blocks.32.norm1.bias', 'sam_mask_decoder.transformer.norm_final_attn.weight', 'memory_attention.layers.1.norm3.weight', 'image_encoder.trunk.blocks.41.norm2.weight', 'memory_attention.layers.0.norm1.bias', 'image_encoder.trunk.blocks.1.norm1.weight', 'image_encoder.trunk.blocks.29.norm2.bias', 'image_encoder.trunk.blocks.38.norm2.weight', 'image_encoder.trunk.blocks.0.norm1.weight', 'image_encoder.trunk.blocks.47.norm2.weight', 'ME.seq_modeling_block.post_norm.bias', 'image_encoder.trunk.blocks.30.norm2.bias', 'image_encoder.trunk.blocks.12.norm2.weight', 'image_encoder.trunk.blocks.41.norm2.bias', 'image_encoder.trunk.blocks.13.norm2.bias', 'image_encoder.trunk.blocks.15.norm2.weight', 'image_encoder.trunk.blocks.19.norm1.weight', 'image_encoder.trunk.blocks.43.norm1.weight', 'image_encoder.trunk.blocks.7.norm2.bias', 'sam_mask_decoder.transformer.layers.1.norm4.bias', 'image_encoder.trunk.blocks.36.norm2.bias', 'image_encoder.trunk.blocks.10.norm2.weight', 'image_encoder.trunk.blocks.38.norm2.bias', 'image_encoder.trunk.blocks.31.norm1.weight', 'image_encoder.trunk.blocks.36.norm2.weight', 'image_encoder.trunk.blocks.47.norm1.weight', 'image_encoder.trunk.blocks.16.norm1.bias', 'image_encoder.trunk.blocks.35.norm2.bias', 'image_encoder.trunk.blocks.44.norm1.weight', 'image_encoder.trunk.blocks.44.norm1.bias', 'image_encoder.trunk.blocks.27.norm1.weight', 'image_encoder.trunk.blocks.29.norm2.weight', 'image_encoder.trunk.blocks.2.norm1.bias', 'image_encoder.trunk.blocks.40.norm2.bias', 'image_encoder.trunk.blocks.23.norm1.bias', 'image_encoder.trunk.blocks.14.norm1.bias', 'image_encoder.trunk.blocks.11.norm1.bias', 'image_encoder.trunk.blocks.4.norm2.bias', 'image_encoder.trunk.blocks.14.norm2.weight', 'image_encoder.trunk.blocks.33.norm2.bias', 'image_encoder.trunk.blocks.37.norm1.bias', 'image_encoder.trunk.blocks.39.norm2.weight', 'image_encoder.trunk.blocks.0.norm2.weight', 'image_encoder.trunk.blocks.1.norm1.bias'} 
INFO 2025-12-09 22:14:41,864 sam2_datasets.py: 125: Dataset mixing probabilities: [1.0]
INFO 2025-12-09 22:14:42,341 trainer.py: 417: Loading pretrained checkpoint from {'_partial_': True, '_target_': 'training.utils.checkpoint_utils.load_state_dict_into_model', 'strict': False, 'ignore_unexpected_keys': None, 'ignore_missing_keys': ['ME*', 'routefuse*'], 'state_dict': {'_target_': 'training.utils.checkpoint_utils.load_checkpoint_and_apply_kernels', 'checkpoint_path': 'checkpoints/sam2.1_hiera_large.pt', 'ckpt_state_dict_keys': ['model']}}
INFO 2025-12-09 22:15:08,006 train_utils.py: 271: Train Epoch: [0][ 0/22] | Batch Time: 25.38 (25.38) | Data Time: 12.93 (12.93) | Mem (GB): 58.00 (58.00/58.00) | Time Elapsed: 00d 00h 00m | Losses/train_all_loss: 1.24e+00 (1.24e+00)
INFO 2025-12-09 22:15:55,361 train_utils.py: 108: MACHINE SEED: 6150
INFO 2025-12-09 22:15:55,363 train_utils.py: 154: Logging ENV_VARIABLES
INFO 2025-12-09 22:15:55,363 train_utils.py: 155: AgentHost=10.17.176.67
AutoDLContainerMonitorSetting=
AutoDLContainerUUID=c6d54aa471-2ea91646
AutoDLDataCenter=neimengDC2
AutoDLRegion=nm-A1
AutoDLService6006URL=https://u829339-a471-2ea91646.nma1.seetacloud.com:8448
AutoDLService6008URL=https://uu829339-a471-2ea91646.nma1.seetacloud.com:8448
AutoDLServiceURL=https://u829339-a471-2ea91646.nma1.seetacloud.com:8448
AutodlAutoPanelToken=jupyter-autodl-container-c69945a881-892d9774-6ddd30cef03e642fcbb23db5203d964cbcb4bbac56da548f7ba86e0aef3fc6423
BROWSER=/root/.vscode-server/cli/servers/Stable-bf9252a2fb45be6893dd8870c0bf37e2e1766d61/server/bin/helpers/browser.sh
COLORTERM=truecolor
CONDA_DEFAULT_ENV=ttt_sam
CONDA_EXE=/root/miniconda3/bin/conda
CONDA_PREFIX=/root/miniconda3/envs/ttt_sam
CONDA_PREFIX_1=/root/miniconda3
CONDA_PROMPT_MODIFIER=(ttt_sam) 
CONDA_PYTHON_EXE=/root/miniconda3/bin/python
CONDA_SHLVL=2
CUDA_MODULE_LOADING=LAZY
GIT_ASKPASS=/root/.vscode-server/cli/servers/Stable-bf9252a2fb45be6893dd8870c0bf37e2e1766d61/server/extensions/git/dist/askpass.sh
GIT_PAGER=cat
HOME=/root
HYDRA_FULL_ERROR=1
LANG=C.UTF-8
LOCAL_RANK=0
LOGNAME=root
LS_COLORS=rs=0:di=01;34:ln=01;36:mh=00:pi=40;33:so=01;35:do=01;35:bd=40;33;01:cd=40;33;01:or=40;31;01:mi=00:su=37;41:sg=30;43:ca=30;41:tw=30;42:ow=34;42:st=37;44:ex=01;32:*.tar=01;31:*.tgz=01;31:*.arc=01;31:*.arj=01;31:*.taz=01;31:*.lha=01;31:*.lz4=01;31:*.lzh=01;31:*.lzma=01;31:*.tlz=01;31:*.txz=01;31:*.tzo=01;31:*.t7z=01;31:*.zip=01;31:*.z=01;31:*.dz=01;31:*.gz=01;31:*.lrz=01;31:*.lz=01;31:*.lzo=01;31:*.xz=01;31:*.zst=01;31:*.tzst=01;31:*.bz2=01;31:*.bz=01;31:*.tbz=01;31:*.tbz2=01;31:*.tz=01;31:*.deb=01;31:*.rpm=01;31:*.jar=01;31:*.war=01;31:*.ear=01;31:*.sar=01;31:*.rar=01;31:*.alz=01;31:*.ace=01;31:*.zoo=01;31:*.cpio=01;31:*.7z=01;31:*.rz=01;31:*.cab=01;31:*.wim=01;31:*.swm=01;31:*.dwm=01;31:*.esd=01;31:*.jpg=01;35:*.jpeg=01;35:*.mjpg=01;35:*.mjpeg=01;35:*.gif=01;35:*.bmp=01;35:*.pbm=01;35:*.pgm=01;35:*.ppm=01;35:*.tga=01;35:*.xbm=01;35:*.xpm=01;35:*.tif=01;35:*.tiff=01;35:*.png=01;35:*.svg=01;35:*.svgz=01;35:*.mng=01;35:*.pcx=01;35:*.mov=01;35:*.mpg=01;35:*.mpeg=01;35:*.m2v=01;35:*.mkv=01;35:*.webm=01;35:*.webp=01;35:*.ogm=01;35:*.mp4=01;35:*.m4v=01;35:*.mp4v=01;35:*.vob=01;35:*.qt=01;35:*.nuv=01;35:*.wmv=01;35:*.asf=01;35:*.rm=01;35:*.rmvb=01;35:*.flc=01;35:*.avi=01;35:*.fli=01;35:*.flv=01;35:*.gl=01;35:*.dl=01;35:*.xcf=01;35:*.xwd=01;35:*.yuv=01;35:*.cgm=01;35:*.emf=01;35:*.ogv=01;35:*.ogx=01;35:*.aac=00;36:*.au=00;36:*.flac=00;36:*.m4a=00;36:*.mid=00;36:*.midi=00;36:*.mka=00;36:*.mp3=00;36:*.mpc=00;36:*.ogg=00;36:*.ra=00;36:*.wav=00;36:*.oga=00;36:*.opus=00;36:*.spx=00;36:*.xspf=00;36:
MASTER_ADDR=localhost
MASTER_PORT=49802
MKL_NUM_THREADS=14
MOTD_SHOWN=pam
OLDPWD=/root/autodl-tmp/ttt_rr
OMP_NUM_THREADS=14
PATH=/root/miniconda3/envs/ttt_sam/bin:/usr/local/bin:/root/.vscode-server/data/User/globalStorage/github.copilot-chat/debugCommand:/root/.vscode-server/data/User/globalStorage/github.copilot-chat/copilotCli:/root/.vscode-server/cli/servers/Stable-bf9252a2fb45be6893dd8870c0bf37e2e1766d61/server/bin/remote-cli:/root/miniconda3/bin:/root/miniconda3/condabin:/root/miniconda3/bin:/usr/local/bin:/root/miniconda3/bin:/usr/local/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin
PWD=/root/autodl-tmp/ttt_rr
PYTHONPATH=:.:.:.
RANK=0
REQUESTS_CA_BUNDLE=/etc/ssl/certs/ca-certificates.crt
SHELL=/bin/bash
SHLVL=1
SSH_CLIENT=127.0.0.1 39646 22
SSH_CONNECTION=127.0.0.1 39646 127.0.0.1 22
SSL_CERT_DIR=/usr/lib/ssl/certs
SSL_CERT_FILE=/usr/lib/ssl/certs/ca-certificates.crt
TERM=xterm-256color
TERM_PROGRAM=vscode
TERM_PROGRAM_VERSION=1.106.3
TORCH_NCCL_ASYNC_ERROR_HANDLING=1
TZ=Asia/Shanghai
USER=root
VSCODE_GIT_ASKPASS_EXTRA_ARGS=
VSCODE_GIT_ASKPASS_MAIN=/root/.vscode-server/cli/servers/Stable-bf9252a2fb45be6893dd8870c0bf37e2e1766d61/server/extensions/git/dist/askpass-main.js
VSCODE_GIT_ASKPASS_NODE=/root/.vscode-server/cli/servers/Stable-bf9252a2fb45be6893dd8870c0bf37e2e1766d61/server/node
VSCODE_GIT_IPC_HANDLE=/tmp/vscode-git-1853e26595.sock
VSCODE_IPC_HOOK_CLI=/tmp/vscode-ipc-b03f0d85-68a5-403a-9691-fb91abace89e.sock
VSCODE_PYTHON_AUTOACTIVATE_GUARD=1
WORLD_SIZE=1
_=/root/miniconda3/envs/ttt_sam/bin/python
_CE_CONDA=
_CE_M=

INFO 2025-12-09 22:15:55,363 trainer.py: 989: Setting up components: Model, loss, optim, meters etc.
INFO 2025-12-09 22:15:55,364 logger.py:  66: TensorBoard SummaryWriter instantiated. Files will be stored in: ./logs/sam_ttt_davis_run2/tensorboard
INFO 2025-12-09 22:15:56,997 sam2.py:  81: Training with points (sampled from masks) as inputs with p=0.5
INFO 2025-12-09 22:15:57,003 trainer.py:1059: ====================
INFO 2025-12-09 22:15:57,003 trainer.py:1060: Summary for model <class 'training.model.sam2.SAM2Train'>
INFO 2025-12-09 22:15:57,006 trainer.py:1061: Model is SAM2Train(
  (image_encoder): ImageEncoder(
    (trunk): Hiera(
      (patch_embed): PatchEmbed(
        (proj): Conv2d(3, 144, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))
      )
      (blocks): ModuleList(
        (0-1): 2 x MultiScaleBlock(
          (norm1): LayerNorm((144,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=144, out_features=432, bias=True)
            (proj): Linear(in_features=144, out_features=144, bias=True)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((144,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=144, out_features=576, bias=True)
              (1): Linear(in_features=576, out_features=144, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
        (2): MultiScaleBlock(
          (norm1): LayerNorm((144,), eps=1e-06, elementwise_affine=True)
          (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
          (attn): MultiScaleAttention(
            (q_pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
            (qkv): Linear(in_features=144, out_features=864, bias=True)
            (proj): Linear(in_features=288, out_features=288, bias=True)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((288,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=288, out_features=1152, bias=True)
              (1): Linear(in_features=1152, out_features=288, bias=True)
            )
            (act): GELU(approximate='none')
          )
          (proj): Linear(in_features=144, out_features=288, bias=True)
        )
        (3-7): 5 x MultiScaleBlock(
          (norm1): LayerNorm((288,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=288, out_features=864, bias=True)
            (proj): Linear(in_features=288, out_features=288, bias=True)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((288,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=288, out_features=1152, bias=True)
              (1): Linear(in_features=1152, out_features=288, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
        (8): MultiScaleBlock(
          (norm1): LayerNorm((288,), eps=1e-06, elementwise_affine=True)
          (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
          (attn): MultiScaleAttention(
            (q_pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
            (qkv): Linear(in_features=288, out_features=1728, bias=True)
            (proj): Linear(in_features=576, out_features=576, bias=True)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((576,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=576, out_features=2304, bias=True)
              (1): Linear(in_features=2304, out_features=576, bias=True)
            )
            (act): GELU(approximate='none')
          )
          (proj): Linear(in_features=288, out_features=576, bias=True)
        )
        (9-43): 35 x MultiScaleBlock(
          (norm1): LayerNorm((576,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=576, out_features=1728, bias=True)
            (proj): Linear(in_features=576, out_features=576, bias=True)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((576,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=576, out_features=2304, bias=True)
              (1): Linear(in_features=2304, out_features=576, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
        (44): MultiScaleBlock(
          (norm1): LayerNorm((576,), eps=1e-06, elementwise_affine=True)
          (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
          (attn): MultiScaleAttention(
            (q_pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
            (qkv): Linear(in_features=576, out_features=3456, bias=True)
            (proj): Linear(in_features=1152, out_features=1152, bias=True)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=1152, out_features=4608, bias=True)
              (1): Linear(in_features=4608, out_features=1152, bias=True)
            )
            (act): GELU(approximate='none')
          )
          (proj): Linear(in_features=576, out_features=1152, bias=True)
        )
        (45-47): 3 x MultiScaleBlock(
          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=1152, out_features=3456, bias=True)
            (proj): Linear(in_features=1152, out_features=1152, bias=True)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=1152, out_features=4608, bias=True)
              (1): Linear(in_features=4608, out_features=1152, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
      )
    )
    (neck): FpnNeck(
      (position_encoding): PositionEmbeddingSine()
      (convs): ModuleList(
        (0): Sequential(
          (conv): Conv2d(1152, 256, kernel_size=(1, 1), stride=(1, 1))
        )
        (1): Sequential(
          (conv): Conv2d(576, 256, kernel_size=(1, 1), stride=(1, 1))
        )
        (2): Sequential(
          (conv): Conv2d(288, 256, kernel_size=(1, 1), stride=(1, 1))
        )
        (3): Sequential(
          (conv): Conv2d(144, 256, kernel_size=(1, 1), stride=(1, 1))
        )
      )
    )
  )
  (mask_downsample): Conv2d(1, 1, kernel_size=(4, 4), stride=(4, 4))
  (memory_attention): MemoryAttention(
    (layers): ModuleList(
      (0-3): 4 x MemoryAttentionLayer(
        (self_attn): RoPEAttention(
          (q_proj): Linear(in_features=256, out_features=256, bias=True)
          (k_proj): Linear(in_features=256, out_features=256, bias=True)
          (v_proj): Linear(in_features=256, out_features=256, bias=True)
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
        )
        (cross_attn_image): RoPEAttention(
          (q_proj): Linear(in_features=256, out_features=256, bias=True)
          (k_proj): Linear(in_features=64, out_features=256, bias=True)
          (v_proj): Linear(in_features=64, out_features=256, bias=True)
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
        )
        (linear1): Linear(in_features=256, out_features=2048, bias=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (linear2): Linear(in_features=2048, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.1, inplace=False)
        (dropout3): Dropout(p=0.1, inplace=False)
      )
    )
    (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (memory_encoder): MemoryEncoder(
    (mask_downsampler): MaskDownSampler(
      (encoder): Sequential(
        (0): Conv2d(1, 4, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (1): LayerNorm2d()
        (2): GELU(approximate='none')
        (3): Conv2d(4, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (4): LayerNorm2d()
        (5): GELU(approximate='none')
        (6): Conv2d(16, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (7): LayerNorm2d()
        (8): GELU(approximate='none')
        (9): Conv2d(64, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (10): LayerNorm2d()
        (11): GELU(approximate='none')
        (12): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (pix_feat_proj): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fuser): Fuser(
      (proj): Identity()
      (layers): ModuleList(
        (0-1): 2 x CXBlock(
          (dwconv): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)
          (norm): LayerNorm2d()
          (pwconv1): Linear(in_features=256, out_features=1024, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1024, out_features=256, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (position_encoding): PositionEmbeddingSine()
    (out_proj): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
  )
  (sam_prompt_encoder): PromptEncoder(
    (pe_layer): PositionEmbeddingRandom()
    (point_embeddings): ModuleList(
      (0-3): 4 x Embedding(1, 256)
    )
    (not_a_point_embed): Embedding(1, 256)
    (mask_downscaling): Sequential(
      (0): Conv2d(1, 4, kernel_size=(2, 2), stride=(2, 2))
      (1): LayerNorm2d()
      (2): GELU(approximate='none')
      (3): Conv2d(4, 16, kernel_size=(2, 2), stride=(2, 2))
      (4): LayerNorm2d()
      (5): GELU(approximate='none')
      (6): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))
    )
    (no_mask_embed): Embedding(1, 256)
  )
  (sam_mask_decoder): MaskDecoder(
    (transformer): TwoWayTransformer(
      (layers): ModuleList(
        (0-1): 2 x TwoWayAttentionBlock(
          (self_attn): Attention(
            (q_proj): Linear(in_features=256, out_features=256, bias=True)
            (k_proj): Linear(in_features=256, out_features=256, bias=True)
            (v_proj): Linear(in_features=256, out_features=256, bias=True)
            (out_proj): Linear(in_features=256, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (cross_attn_token_to_image): Attention(
            (q_proj): Linear(in_features=256, out_features=128, bias=True)
            (k_proj): Linear(in_features=256, out_features=128, bias=True)
            (v_proj): Linear(in_features=256, out_features=128, bias=True)
            (out_proj): Linear(in_features=128, out_features=256, bias=True)
          )
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=256, out_features=2048, bias=True)
              (1): Linear(in_features=2048, out_features=256, bias=True)
            )
            (act): ReLU()
          )
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (cross_attn_image_to_token): Attention(
            (q_proj): Linear(in_features=256, out_features=128, bias=True)
            (k_proj): Linear(in_features=256, out_features=128, bias=True)
            (v_proj): Linear(in_features=256, out_features=128, bias=True)
            (out_proj): Linear(in_features=128, out_features=256, bias=True)
          )
        )
      )
      (final_attn_token_to_image): Attention(
        (q_proj): Linear(in_features=256, out_features=128, bias=True)
        (k_proj): Linear(in_features=256, out_features=128, bias=True)
        (v_proj): Linear(in_features=256, out_features=128, bias=True)
        (out_proj): Linear(in_features=128, out_features=256, bias=True)
      )
      (norm_final_attn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (iou_token): Embedding(1, 256)
    (mask_tokens): Embedding(4, 256)
    (obj_score_token): Embedding(1, 256)
    (output_upscaling): Sequential(
      (0): ConvTranspose2d(256, 64, kernel_size=(2, 2), stride=(2, 2))
      (1): LayerNorm2d()
      (2): GELU(approximate='none')
      (3): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2))
      (4): GELU(approximate='none')
    )
    (conv_s0): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
    (conv_s1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
    (output_hypernetworks_mlps): ModuleList(
      (0-3): 4 x MLP(
        (layers): ModuleList(
          (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=32, bias=True)
        )
        (act): ReLU()
      )
    )
    (iou_prediction_head): MLP(
      (layers): ModuleList(
        (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=4, bias=True)
      )
      (act): ReLU()
    )
    (pred_obj_score_head): MLP(
      (layers): ModuleList(
        (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=1, bias=True)
      )
      (act): ReLU()
    )
  )
  (obj_ptr_proj): MLP(
    (layers): ModuleList(
      (0-2): 3 x Linear(in_features=256, out_features=256, bias=True)
    )
    (act): ReLU()
  )
  (obj_ptr_tpos_proj): Linear(in_features=256, out_features=64, bias=True)
  (DWT): extract_high_frequency(
    (dwt): DWT()
  )
  (ME): ME(
    (depthwise_conv_reduce_channels_in): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), groups=32)
    (depthwise_conv_reduce_channels_out1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), groups=32)
    (depthwise_conv_reduce_channels_out2): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), groups=32)
    (relu): ReLU(inplace=True)
    (branch1): Sequential(
      (0): BasicConv2d(
        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): GroupNorm(32, 256, eps=1e-05, affine=True)
        (relu): ReLU()
      )
      (1): BasicConv2d(
        (conv): Conv2d(256, 256, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
        (bn): GroupNorm(32, 256, eps=1e-05, affine=True)
        (relu): ReLU()
      )
      (2): BasicConv2d(
        (conv): Conv2d(256, 256, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
        (bn): GroupNorm(32, 256, eps=1e-05, affine=True)
        (relu): ReLU()
      )
      (3): BasicConv2d(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3), dilation=(3, 3), bias=False)
        (bn): GroupNorm(32, 256, eps=1e-05, affine=True)
        (relu): ReLU()
      )
    )
    (seq_modeling_block): TTTLinear(
      (q_proj): Linear(in_features=256, out_features=256, bias=False)
      (v_proj): Linear(in_features=256, out_features=256, bias=False)
      (o_proj): Linear(in_features=256, out_features=256, bias=False)
      (conv_q): Conv1d(256, 256, kernel_size=(4,), stride=(1,), padding=(3,), groups=256)
      (conv_k): Conv1d(256, 256, kernel_size=(4,), stride=(1,), padding=(3,), groups=256)
      (rotary_emb): RotaryEmbedding()
      (post_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
    )
    (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (embed_tokens): Embedding(256, 256)
  )
  (routefuse): routefuse(
    (conv_dense): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
  )
)
INFO 2025-12-09 22:15:57,006 trainer.py:1062: 	Total parameters 226 M
INFO 2025-12-09 22:15:57,006 trainer.py:1063: 	Trainable parameters 13.7 M
INFO 2025-12-09 22:15:57,006 trainer.py:1066: 	Non-Trainable parameters 212 M
INFO 2025-12-09 22:15:57,006 trainer.py:1069: ====================
INFO 2025-12-09 22:15:57,009 trainer.py:1023: Finished setting up components: Model, loss, optim, meters etc.
INFO 2025-12-09 22:15:57,009 trainer.py: 314: Moving components to device cuda:0 and local rank 0.
INFO 2025-12-09 22:15:57,220 trainer.py: 320: Done moving components to device cuda:0 and local rank 0.
INFO 2025-12-09 22:15:57,234 optimizer.py: 248: Matches for param_name [image_encoder.*]: {'image_encoder.trunk.blocks.21.norm1.weight', 'image_encoder.trunk.blocks.22.attn.qkv.weight', 'image_encoder.trunk.blocks.37.mlp.layers.0.bias', 'image_encoder.trunk.blocks.10.norm2.weight', 'image_encoder.trunk.blocks.31.norm1.bias', 'image_encoder.trunk.blocks.20.mlp.layers.1.bias', 'image_encoder.trunk.blocks.44.mlp.layers.0.weight', 'image_encoder.trunk.blocks.28.norm2.bias', 'image_encoder.trunk.blocks.40.norm1.bias', 'image_encoder.trunk.blocks.12.attn.proj.bias', 'image_encoder.trunk.blocks.28.attn.qkv.bias', 'image_encoder.trunk.blocks.16.mlp.layers.1.bias', 'image_encoder.trunk.blocks.18.mlp.layers.1.weight', 'image_encoder.trunk.blocks.44.attn.qkv.bias', 'image_encoder.trunk.blocks.18.mlp.layers.0.weight', 'image_encoder.trunk.blocks.41.attn.qkv.weight', 'image_encoder.trunk.blocks.28.mlp.layers.1.bias', 'image_encoder.trunk.blocks.6.mlp.layers.1.weight', 'image_encoder.trunk.blocks.38.norm2.weight', 'image_encoder.trunk.blocks.17.mlp.layers.0.bias', 'image_encoder.trunk.blocks.17.mlp.layers.1.bias', 'image_encoder.trunk.blocks.20.mlp.layers.0.bias', 'image_encoder.trunk.blocks.42.attn.qkv.bias', 'image_encoder.trunk.blocks.7.norm1.bias', 'image_encoder.trunk.blocks.10.attn.proj.bias', 'image_encoder.trunk.blocks.12.attn.qkv.weight', 'image_encoder.trunk.blocks.19.mlp.layers.0.weight', 'image_encoder.trunk.blocks.29.mlp.layers.1.weight', 'image_encoder.trunk.blocks.18.attn.qkv.bias', 'image_encoder.trunk.blocks.37.norm2.bias', 'image_encoder.trunk.blocks.41.norm1.bias', 'image_encoder.trunk.blocks.6.norm1.bias', 'image_encoder.trunk.blocks.4.attn.proj.weight', 'image_encoder.trunk.blocks.21.attn.qkv.bias', 'image_encoder.trunk.blocks.38.attn.qkv.bias', 'image_encoder.trunk.blocks.24.attn.qkv.bias', 'image_encoder.trunk.blocks.24.mlp.layers.0.bias', 'image_encoder.trunk.blocks.22.norm2.bias', 'image_encoder.trunk.blocks.44.attn.qkv.weight', 'image_encoder.trunk.blocks.27.norm1.bias', 'image_encoder.trunk.blocks.16.norm1.bias', 'image_encoder.trunk.blocks.11.norm1.bias', 'image_encoder.trunk.blocks.38.mlp.layers.0.bias', 'image_encoder.trunk.blocks.4.norm2.bias', 'image_encoder.trunk.blocks.22.mlp.layers.1.bias', 'image_encoder.trunk.blocks.35.mlp.layers.1.weight', 'image_encoder.trunk.blocks.4.mlp.layers.1.weight', 'image_encoder.trunk.blocks.18.norm2.weight', 'image_encoder.trunk.blocks.35.mlp.layers.1.bias', 'image_encoder.trunk.blocks.9.attn.proj.bias', 'image_encoder.trunk.blocks.25.norm2.bias', 'image_encoder.trunk.blocks.39.norm1.weight', 'image_encoder.trunk.blocks.47.attn.qkv.bias', 'image_encoder.trunk.blocks.8.attn.qkv.bias', 'image_encoder.trunk.blocks.12.attn.proj.weight', 'image_encoder.trunk.blocks.47.norm2.weight', 'image_encoder.trunk.blocks.35.attn.proj.bias', 'image_encoder.trunk.blocks.2.attn.qkv.weight', 'image_encoder.trunk.blocks.20.norm1.bias', 'image_encoder.trunk.blocks.43.norm1.bias', 'image_encoder.trunk.blocks.10.attn.qkv.weight', 'image_encoder.trunk.blocks.4.mlp.layers.1.bias', 'image_encoder.trunk.blocks.15.attn.proj.bias', 'image_encoder.trunk.blocks.21.mlp.layers.1.bias', 'image_encoder.trunk.blocks.10.attn.qkv.bias', 'image_encoder.trunk.blocks.6.norm2.bias', 'image_encoder.trunk.blocks.12.norm2.bias', 'image_encoder.trunk.blocks.13.mlp.layers.1.weight', 'image_encoder.trunk.blocks.28.mlp.layers.0.bias', 'image_encoder.trunk.blocks.0.attn.proj.weight', 'image_encoder.trunk.blocks.24.norm2.weight', 'image_encoder.trunk.blocks.19.mlp.layers.1.weight', 'image_encoder.trunk.blocks.36.mlp.layers.0.bias', 'image_encoder.trunk.blocks.20.attn.qkv.bias', 'image_encoder.trunk.blocks.32.mlp.layers.0.bias', 'image_encoder.trunk.blocks.23.mlp.layers.0.bias', 'image_encoder.trunk.blocks.22.norm1.weight', 'image_encoder.trunk.blocks.32.mlp.layers.0.weight', 'image_encoder.trunk.blocks.5.norm1.bias', 'image_encoder.trunk.blocks.3.mlp.layers.0.weight', 'image_encoder.neck.convs.3.conv.bias', 'image_encoder.trunk.blocks.40.attn.qkv.weight', 'image_encoder.trunk.blocks.19.mlp.layers.0.bias', 'image_encoder.trunk.blocks.44.norm1.bias', 'image_encoder.trunk.blocks.44.norm2.bias', 'image_encoder.trunk.blocks.8.attn.proj.bias', 'image_encoder.trunk.blocks.21.norm2.weight', 'image_encoder.trunk.blocks.14.attn.proj.bias', 'image_encoder.trunk.blocks.10.mlp.layers.0.bias', 'image_encoder.trunk.blocks.14.mlp.layers.1.weight', 'image_encoder.trunk.blocks.20.attn.qkv.weight', 'image_encoder.trunk.blocks.31.mlp.layers.0.bias', 'image_encoder.trunk.blocks.41.mlp.layers.0.weight', 'image_encoder.trunk.blocks.3.attn.proj.bias', 'image_encoder.trunk.blocks.33.attn.qkv.bias', 'image_encoder.trunk.blocks.1.attn.proj.weight', 'image_encoder.trunk.blocks.6.attn.proj.bias', 'image_encoder.trunk.blocks.25.attn.proj.bias', 'image_encoder.trunk.blocks.0.norm1.weight', 'image_encoder.trunk.blocks.26.mlp.layers.0.bias', 'image_encoder.trunk.blocks.47.mlp.layers.0.bias', 'image_encoder.trunk.blocks.15.norm2.bias', 'image_encoder.trunk.blocks.17.mlp.layers.1.weight', 'image_encoder.trunk.blocks.23.attn.proj.bias', 'image_encoder.trunk.blocks.18.mlp.layers.1.bias', 'image_encoder.trunk.blocks.23.norm1.weight', 'image_encoder.trunk.blocks.8.attn.qkv.weight', 'image_encoder.trunk.blocks.13.mlp.layers.1.bias', 'image_encoder.trunk.blocks.29.mlp.layers.0.bias', 'image_encoder.trunk.blocks.17.attn.proj.bias', 'image_encoder.trunk.blocks.20.norm1.weight', 'image_encoder.trunk.blocks.16.attn.proj.bias', 'image_encoder.trunk.blocks.37.norm1.bias', 'image_encoder.trunk.blocks.27.attn.qkv.weight', 'image_encoder.trunk.blocks.44.attn.proj.bias', 'image_encoder.neck.convs.2.conv.bias', 'image_encoder.trunk.blocks.31.attn.proj.weight', 'image_encoder.trunk.blocks.3.mlp.layers.0.bias', 'image_encoder.trunk.blocks.25.attn.qkv.weight', 'image_encoder.trunk.blocks.5.mlp.layers.0.weight', 'image_encoder.trunk.blocks.46.attn.qkv.weight', 'image_encoder.trunk.blocks.10.norm1.bias', 'image_encoder.trunk.blocks.8.norm2.bias', 'image_encoder.trunk.blocks.2.attn.proj.bias', 'image_encoder.trunk.blocks.42.norm1.bias', 'image_encoder.trunk.blocks.26.attn.qkv.weight', 'image_encoder.neck.convs.2.conv.weight', 'image_encoder.trunk.blocks.17.norm1.weight', 'image_encoder.trunk.blocks.9.norm1.bias', 'image_encoder.trunk.blocks.38.mlp.layers.1.weight', 'image_encoder.trunk.blocks.45.mlp.layers.0.weight', 'image_encoder.trunk.blocks.15.mlp.layers.0.bias', 'image_encoder.trunk.blocks.23.mlp.layers.1.weight', 'image_encoder.trunk.blocks.0.norm1.bias', 'image_encoder.trunk.blocks.4.mlp.layers.0.bias', 'image_encoder.trunk.blocks.27.mlp.layers.1.weight', 'image_encoder.trunk.blocks.19.norm2.bias', 'image_encoder.trunk.blocks.12.mlp.layers.1.weight', 'image_encoder.trunk.blocks.40.attn.proj.weight', 'image_encoder.trunk.blocks.14.mlp.layers.0.bias', 'image_encoder.trunk.blocks.33.attn.qkv.weight', 'image_encoder.trunk.blocks.10.attn.proj.weight', 'image_encoder.trunk.blocks.3.attn.qkv.weight', 'image_encoder.trunk.blocks.11.norm1.weight', 'image_encoder.trunk.blocks.43.attn.proj.bias', 'image_encoder.trunk.blocks.18.norm1.bias', 'image_encoder.trunk.blocks.36.norm2.weight', 'image_encoder.trunk.blocks.1.norm1.weight', 'image_encoder.trunk.blocks.7.mlp.layers.0.weight', 'image_encoder.trunk.blocks.9.norm2.bias', 'image_encoder.trunk.blocks.29.attn.proj.weight', 'image_encoder.trunk.blocks.31.norm2.bias', 'image_encoder.trunk.blocks.25.mlp.layers.1.weight', 'image_encoder.trunk.blocks.14.mlp.layers.1.bias', 'image_encoder.trunk.blocks.26.mlp.layers.1.bias', 'image_encoder.trunk.blocks.37.norm2.weight', 'image_encoder.trunk.blocks.14.mlp.layers.0.weight', 'image_encoder.trunk.pos_embed', 'image_encoder.trunk.blocks.10.norm2.bias', 'image_encoder.trunk.blocks.39.mlp.layers.0.bias', 'image_encoder.trunk.blocks.11.norm2.weight', 'image_encoder.trunk.blocks.24.norm1.bias', 'image_encoder.trunk.blocks.40.mlp.layers.1.weight', 'image_encoder.trunk.blocks.5.attn.proj.weight', 'image_encoder.trunk.blocks.41.mlp.layers.0.bias', 'image_encoder.trunk.blocks.1.norm1.bias', 'image_encoder.trunk.blocks.33.norm2.weight', 'image_encoder.trunk.blocks.38.mlp.layers.1.bias', 'image_encoder.trunk.blocks.12.mlp.layers.0.bias', 'image_encoder.trunk.blocks.22.attn.proj.weight', 'image_encoder.trunk.blocks.45.mlp.layers.1.weight', 'image_encoder.trunk.blocks.26.attn.proj.bias', 'image_encoder.trunk.blocks.8.mlp.layers.1.bias', 'image_encoder.neck.convs.1.conv.bias', 'image_encoder.trunk.blocks.47.norm1.weight', 'image_encoder.trunk.blocks.34.norm1.weight', 'image_encoder.trunk.blocks.4.norm1.bias', 'image_encoder.trunk.blocks.15.norm1.bias', 'image_encoder.trunk.blocks.43.mlp.layers.1.bias', 'image_encoder.trunk.blocks.12.mlp.layers.0.weight', 'image_encoder.trunk.blocks.19.norm1.bias', 'image_encoder.trunk.blocks.26.attn.qkv.bias', 'image_encoder.trunk.blocks.28.mlp.layers.1.weight', 'image_encoder.trunk.blocks.27.attn.proj.weight', 'image_encoder.trunk.blocks.18.mlp.layers.0.bias', 'image_encoder.trunk.blocks.27.mlp.layers.0.bias', 'image_encoder.trunk.blocks.19.mlp.layers.1.bias', 'image_encoder.trunk.blocks.0.attn.proj.bias', 'image_encoder.trunk.blocks.36.mlp.layers.1.weight', 'image_encoder.trunk.blocks.22.mlp.layers.0.bias', 'image_encoder.trunk.blocks.39.attn.proj.bias', 'image_encoder.trunk.blocks.13.attn.qkv.weight', 'image_encoder.trunk.blocks.0.attn.qkv.weight', 'image_encoder.trunk.blocks.39.attn.qkv.weight', 'image_encoder.trunk.blocks.41.attn.qkv.bias', 'image_encoder.trunk.blocks.45.mlp.layers.0.bias', 'image_encoder.trunk.blocks.6.norm2.weight', 'image_encoder.trunk.blocks.42.attn.proj.weight', 'image_encoder.trunk.blocks.34.attn.proj.weight', 'image_encoder.trunk.blocks.40.mlp.layers.1.bias', 'image_encoder.trunk.blocks.38.norm1.bias', 'image_encoder.trunk.blocks.7.mlp.layers.1.bias', 'image_encoder.trunk.blocks.11.mlp.layers.1.weight', 'image_encoder.trunk.blocks.9.mlp.layers.0.weight', 'image_encoder.trunk.blocks.33.norm1.bias', 'image_encoder.trunk.blocks.45.mlp.layers.1.bias', 'image_encoder.trunk.blocks.36.norm1.bias', 'image_encoder.trunk.blocks.13.attn.proj.bias', 'image_encoder.trunk.blocks.19.norm2.weight', 'image_encoder.trunk.blocks.8.norm1.weight', 'image_encoder.trunk.blocks.17.norm1.bias', 'image_encoder.trunk.blocks.46.mlp.layers.1.bias', 'image_encoder.trunk.blocks.31.mlp.layers.1.bias', 'image_encoder.trunk.blocks.33.mlp.layers.0.weight', 'image_encoder.trunk.blocks.40.attn.proj.bias', 'image_encoder.trunk.blocks.21.attn.qkv.weight', 'image_encoder.trunk.blocks.24.norm1.weight', 'image_encoder.trunk.blocks.30.attn.proj.bias', 'image_encoder.trunk.blocks.0.norm2.weight', 'image_encoder.trunk.blocks.13.norm1.bias', 'image_encoder.trunk.blocks.37.mlp.layers.1.bias', 'image_encoder.trunk.blocks.42.norm2.bias', 'image_encoder.trunk.blocks.15.attn.proj.weight', 'image_encoder.trunk.blocks.22.attn.proj.bias', 'image_encoder.trunk.blocks.11.attn.qkv.bias', 'image_encoder.trunk.blocks.14.norm2.bias', 'image_encoder.trunk.blocks.5.attn.proj.bias', 'image_encoder.trunk.blocks.6.mlp.layers.1.bias', 'image_encoder.trunk.blocks.39.mlp.layers.0.weight', 'image_encoder.trunk.blocks.2.norm1.bias', 'image_encoder.trunk.blocks.31.attn.qkv.bias', 'image_encoder.trunk.blocks.46.mlp.layers.0.weight', 'image_encoder.trunk.blocks.35.norm1.bias', 'image_encoder.trunk.blocks.22.attn.qkv.bias', 'image_encoder.trunk.blocks.28.mlp.layers.0.weight', 'image_encoder.trunk.blocks.18.attn.qkv.weight', 'image_encoder.trunk.blocks.8.attn.proj.weight', 'image_encoder.trunk.blocks.31.mlp.layers.0.weight', 'image_encoder.trunk.blocks.38.norm2.bias', 'image_encoder.trunk.blocks.43.norm2.bias', 'image_encoder.trunk.blocks.35.attn.proj.weight', 'image_encoder.trunk.blocks.40.norm1.weight', 'image_encoder.trunk.blocks.19.norm1.weight', 'image_encoder.trunk.blocks.44.attn.proj.weight', 'image_encoder.trunk.blocks.32.norm2.weight', 'image_encoder.trunk.blocks.27.norm1.weight', 'image_encoder.trunk.blocks.34.mlp.layers.1.weight', 'image_encoder.trunk.blocks.27.attn.qkv.bias', 'image_encoder.trunk.blocks.23.norm1.bias', 'image_encoder.trunk.blocks.23.attn.qkv.weight', 'image_encoder.trunk.blocks.46.attn.proj.weight', 'image_encoder.trunk.blocks.36.attn.proj.weight', 'image_encoder.trunk.blocks.46.mlp.layers.1.weight', 'image_encoder.trunk.blocks.9.norm2.weight', 'image_encoder.trunk.blocks.0.mlp.layers.0.weight', 'image_encoder.trunk.blocks.27.attn.proj.bias', 'image_encoder.trunk.blocks.0.mlp.layers.0.bias', 'image_encoder.trunk.blocks.33.attn.proj.weight', 'image_encoder.trunk.blocks.32.norm2.bias', 'image_encoder.trunk.blocks.3.attn.qkv.bias', 'image_encoder.trunk.blocks.32.attn.qkv.weight', 'image_encoder.trunk.blocks.38.norm1.weight', 'image_encoder.trunk.blocks.27.norm2.weight', 'image_encoder.trunk.blocks.8.mlp.layers.1.weight', 'image_encoder.trunk.blocks.22.norm2.weight', 'image_encoder.trunk.blocks.33.attn.proj.bias', 'image_encoder.trunk.blocks.42.norm1.weight', 'image_encoder.trunk.blocks.14.norm2.weight', 'image_encoder.trunk.blocks.5.attn.qkv.weight', 'image_encoder.trunk.blocks.25.norm1.weight', 'image_encoder.trunk.blocks.19.attn.proj.bias', 'image_encoder.trunk.blocks.46.norm2.weight', 'image_encoder.trunk.blocks.24.norm2.bias', 'image_encoder.trunk.blocks.16.norm2.bias', 'image_encoder.trunk.blocks.5.attn.qkv.bias', 'image_encoder.trunk.pos_embed_window', 'image_encoder.trunk.blocks.0.norm2.bias', 'image_encoder.trunk.blocks.29.norm2.bias', 'image_encoder.trunk.blocks.31.attn.proj.bias', 'image_encoder.trunk.blocks.3.attn.proj.weight', 'image_encoder.trunk.blocks.7.mlp.layers.0.bias', 'image_encoder.trunk.blocks.15.mlp.layers.0.weight', 'image_encoder.trunk.blocks.13.mlp.layers.0.bias', 'image_encoder.trunk.patch_embed.proj.weight', 'image_encoder.trunk.blocks.19.attn.qkv.bias', 'image_encoder.trunk.blocks.43.mlp.layers.0.weight', 'image_encoder.trunk.blocks.2.mlp.layers.0.bias', 'image_encoder.trunk.blocks.37.mlp.layers.0.weight', 'image_encoder.trunk.blocks.47.attn.qkv.weight', 'image_encoder.trunk.blocks.30.mlp.layers.1.weight', 'image_encoder.trunk.blocks.39.norm1.bias', 'image_encoder.trunk.blocks.44.norm1.weight', 'image_encoder.trunk.blocks.12.norm1.bias', 'image_encoder.trunk.blocks.41.mlp.layers.1.bias', 'image_encoder.trunk.blocks.8.norm1.bias', 'image_encoder.trunk.blocks.16.attn.proj.weight', 'image_encoder.trunk.blocks.36.norm1.weight', 'image_encoder.trunk.blocks.38.attn.qkv.weight', 'image_encoder.trunk.blocks.13.mlp.layers.0.weight', 'image_encoder.trunk.blocks.9.mlp.layers.0.bias', 'image_encoder.trunk.blocks.9.mlp.layers.1.weight', 'image_encoder.trunk.blocks.35.mlp.layers.0.bias', 'image_encoder.trunk.blocks.45.norm1.bias', 'image_encoder.trunk.blocks.0.mlp.layers.1.weight', 'image_encoder.trunk.blocks.23.attn.qkv.bias', 'image_encoder.trunk.blocks.46.norm1.bias', 'image_encoder.trunk.blocks.11.attn.qkv.weight', 'image_encoder.trunk.blocks.17.norm2.weight', 'image_encoder.trunk.blocks.42.mlp.layers.1.bias', 'image_encoder.trunk.blocks.10.norm1.weight', 'image_encoder.trunk.blocks.29.norm1.bias', 'image_encoder.trunk.blocks.16.mlp.layers.0.bias', 'image_encoder.trunk.blocks.4.attn.qkv.weight', 'image_encoder.trunk.blocks.40.mlp.layers.0.weight', 'image_encoder.trunk.blocks.2.attn.proj.weight', 'image_encoder.trunk.blocks.27.mlp.layers.1.bias', 'image_encoder.trunk.blocks.1.mlp.layers.1.bias', 'image_encoder.trunk.blocks.28.norm1.weight', 'image_encoder.trunk.blocks.21.attn.proj.bias', 'image_encoder.trunk.blocks.11.attn.proj.bias', 'image_encoder.trunk.blocks.7.norm2.weight', 'image_encoder.trunk.blocks.47.norm1.bias', 'image_encoder.trunk.blocks.22.norm1.bias', 'image_encoder.trunk.blocks.30.norm1.bias', 'image_encoder.trunk.blocks.38.mlp.layers.0.weight', 'image_encoder.trunk.blocks.23.mlp.layers.1.bias', 'image_encoder.trunk.blocks.32.norm1.weight', 'image_encoder.trunk.blocks.39.attn.proj.weight', 'image_encoder.trunk.blocks.39.mlp.layers.1.bias', 'image_encoder.trunk.blocks.33.mlp.layers.0.bias', 'image_encoder.trunk.blocks.4.norm2.weight', 'image_encoder.trunk.blocks.45.norm2.weight', 'image_encoder.trunk.blocks.35.attn.qkv.weight', 'image_encoder.trunk.blocks.14.attn.qkv.weight', 'image_encoder.trunk.blocks.43.attn.proj.weight', 'image_encoder.trunk.blocks.44.norm2.weight', 'image_encoder.trunk.blocks.44.proj.bias', 'image_encoder.trunk.blocks.2.attn.qkv.bias', 'image_encoder.trunk.blocks.28.norm2.weight', 'image_encoder.trunk.blocks.34.norm2.bias', 'image_encoder.trunk.blocks.16.mlp.layers.1.weight', 'image_encoder.trunk.blocks.24.attn.proj.bias', 'image_encoder.trunk.blocks.32.attn.proj.weight', 'image_encoder.trunk.blocks.2.mlp.layers.1.bias', 'image_encoder.trunk.blocks.20.attn.proj.weight', 'image_encoder.trunk.blocks.26.norm2.weight', 'image_encoder.trunk.blocks.18.attn.proj.weight', 'image_encoder.trunk.blocks.9.attn.qkv.bias', 'image_encoder.trunk.blocks.15.norm2.weight', 'image_encoder.trunk.blocks.42.attn.proj.bias', 'image_encoder.trunk.patch_embed.proj.bias', 'image_encoder.trunk.blocks.37.attn.qkv.bias', 'image_encoder.trunk.blocks.21.mlp.layers.1.weight', 'image_encoder.trunk.blocks.10.mlp.layers.1.bias', 'image_encoder.trunk.blocks.43.mlp.layers.0.bias', 'image_encoder.trunk.blocks.6.mlp.layers.0.weight', 'image_encoder.trunk.blocks.12.norm1.weight', 'image_encoder.trunk.blocks.34.mlp.layers.0.bias', 'image_encoder.trunk.blocks.47.mlp.layers.0.weight', 'image_encoder.trunk.blocks.31.mlp.layers.1.weight', 'image_encoder.trunk.blocks.16.mlp.layers.0.weight', 'image_encoder.trunk.blocks.1.norm2.bias', 'image_encoder.trunk.blocks.25.mlp.layers.0.weight', 'image_encoder.trunk.blocks.45.attn.qkv.weight', 'image_encoder.trunk.blocks.45.norm2.bias', 'image_encoder.trunk.blocks.30.attn.proj.weight', 'image_encoder.trunk.blocks.0.mlp.layers.1.bias', 'image_encoder.trunk.blocks.10.mlp.layers.0.weight', 'image_encoder.trunk.blocks.46.norm1.weight', 'image_encoder.trunk.blocks.40.mlp.layers.0.bias', 'image_encoder.trunk.blocks.11.mlp.layers.0.weight', 'image_encoder.trunk.blocks.34.attn.qkv.bias', 'image_encoder.trunk.blocks.4.mlp.layers.0.weight', 'image_encoder.trunk.blocks.34.mlp.layers.0.weight', 'image_encoder.trunk.blocks.43.norm1.weight', 'image_encoder.trunk.blocks.9.attn.proj.weight', 'image_encoder.trunk.blocks.26.mlp.layers.0.weight', 'image_encoder.trunk.blocks.18.norm2.bias', 'image_encoder.trunk.blocks.28.attn.proj.weight', 'image_encoder.trunk.blocks.41.norm2.weight', 'image_encoder.trunk.blocks.11.mlp.layers.1.bias', 'image_encoder.trunk.blocks.42.mlp.layers.0.weight', 'image_encoder.trunk.blocks.42.norm2.weight', 'image_encoder.trunk.blocks.2.proj.weight', 'image_encoder.trunk.blocks.19.attn.proj.weight', 'image_encoder.neck.convs.0.conv.bias', 'image_encoder.trunk.blocks.2.norm2.bias', 'image_encoder.trunk.blocks.6.attn.qkv.weight', 'image_encoder.trunk.blocks.3.norm1.weight', 'image_encoder.trunk.blocks.46.attn.qkv.bias', 'image_encoder.trunk.blocks.3.mlp.layers.1.bias', 'image_encoder.trunk.blocks.23.norm2.weight', 'image_encoder.trunk.blocks.34.attn.proj.bias', 'image_encoder.trunk.blocks.6.attn.proj.weight', 'image_encoder.trunk.blocks.42.mlp.layers.0.bias', 'image_encoder.trunk.blocks.7.attn.qkv.bias', 'image_encoder.trunk.blocks.8.proj.bias', 'image_encoder.trunk.blocks.34.norm2.weight', 'image_encoder.trunk.blocks.17.attn.qkv.bias', 'image_encoder.trunk.blocks.27.mlp.layers.0.weight', 'image_encoder.trunk.blocks.22.mlp.layers.0.weight', 'image_encoder.trunk.blocks.42.attn.qkv.weight', 'image_encoder.trunk.blocks.1.attn.proj.bias', 'image_encoder.trunk.blocks.8.mlp.layers.0.bias', 'image_encoder.trunk.blocks.33.mlp.layers.1.weight', 'image_encoder.trunk.blocks.40.norm2.bias', 'image_encoder.trunk.blocks.11.mlp.layers.0.bias', 'image_encoder.trunk.blocks.16.attn.qkv.weight', 'image_encoder.trunk.blocks.45.norm1.weight', 'image_encoder.trunk.blocks.9.mlp.layers.1.bias', 'image_encoder.trunk.blocks.12.mlp.layers.1.bias', 'image_encoder.trunk.blocks.1.norm2.weight', 'image_encoder.trunk.blocks.32.mlp.layers.1.bias', 'image_encoder.trunk.blocks.34.norm1.bias', 'image_encoder.trunk.blocks.45.attn.proj.weight', 'image_encoder.trunk.blocks.38.attn.proj.bias', 'image_encoder.trunk.blocks.29.mlp.layers.0.weight', 'image_encoder.trunk.blocks.44.mlp.layers.1.bias', 'image_encoder.trunk.blocks.24.mlp.layers.1.weight', 'image_encoder.trunk.blocks.6.attn.qkv.bias', 'image_encoder.trunk.blocks.14.norm1.weight', 'image_encoder.trunk.blocks.5.norm1.weight', 'image_encoder.trunk.blocks.28.norm1.bias', 'image_encoder.trunk.blocks.1.attn.qkv.bias', 'image_encoder.trunk.blocks.21.mlp.layers.0.weight', 'image_encoder.trunk.blocks.29.norm1.weight', 'image_encoder.trunk.blocks.25.attn.proj.weight', 'image_encoder.trunk.blocks.24.mlp.layers.1.bias', 'image_encoder.trunk.blocks.25.norm1.bias', 'image_encoder.trunk.blocks.15.attn.qkv.bias', 'image_encoder.trunk.blocks.33.mlp.layers.1.bias', 'image_encoder.trunk.blocks.5.mlp.layers.1.bias', 'image_encoder.trunk.blocks.30.attn.qkv.bias', 'image_encoder.trunk.blocks.39.attn.qkv.bias', 'image_encoder.trunk.blocks.43.attn.qkv.bias', 'image_encoder.trunk.blocks.15.mlp.layers.1.weight', 'image_encoder.trunk.blocks.13.norm1.weight', 'image_encoder.trunk.blocks.11.attn.proj.weight', 'image_encoder.trunk.blocks.30.norm1.weight', 'image_encoder.trunk.blocks.8.mlp.layers.0.weight', 'image_encoder.trunk.blocks.1.mlp.layers.0.bias', 'image_encoder.trunk.blocks.44.mlp.layers.1.weight', 'image_encoder.trunk.blocks.18.norm1.weight', 'image_encoder.trunk.blocks.30.norm2.weight', 'image_encoder.trunk.blocks.2.norm1.weight', 'image_encoder.trunk.blocks.5.norm2.bias', 'image_encoder.trunk.blocks.43.mlp.layers.1.weight', 'image_encoder.trunk.blocks.26.norm1.bias', 'image_encoder.trunk.blocks.39.mlp.layers.1.weight', 'image_encoder.trunk.blocks.16.attn.qkv.bias', 'image_encoder.trunk.blocks.36.attn.proj.bias', 'image_encoder.trunk.blocks.2.norm2.weight', 'image_encoder.trunk.blocks.6.norm1.weight', 'image_encoder.trunk.blocks.45.attn.qkv.bias', 'image_encoder.trunk.blocks.41.mlp.layers.1.weight', 'image_encoder.trunk.blocks.26.mlp.layers.1.weight', 'image_encoder.trunk.blocks.28.attn.proj.bias', 'image_encoder.trunk.blocks.35.norm2.weight', 'image_encoder.trunk.blocks.40.norm2.weight', 'image_encoder.trunk.blocks.43.attn.qkv.weight', 'image_encoder.trunk.blocks.21.mlp.layers.0.bias', 'image_encoder.trunk.blocks.40.attn.qkv.bias', 'image_encoder.trunk.blocks.2.mlp.layers.1.weight', 'image_encoder.trunk.blocks.36.attn.qkv.bias', 'image_encoder.trunk.blocks.24.attn.qkv.weight', 'image_encoder.trunk.blocks.37.attn.proj.weight', 'image_encoder.trunk.blocks.41.attn.proj.weight', 'image_encoder.trunk.blocks.20.attn.proj.bias', 'image_encoder.trunk.blocks.21.norm1.bias', 'image_encoder.trunk.blocks.30.norm2.bias', 'image_encoder.trunk.blocks.36.mlp.layers.0.weight', 'image_encoder.trunk.blocks.32.attn.proj.bias', 'image_encoder.trunk.blocks.5.mlp.layers.1.weight', 'image_encoder.trunk.blocks.47.attn.proj.bias', 'image_encoder.trunk.blocks.47.norm2.bias', 'image_encoder.trunk.blocks.30.attn.qkv.weight', 'image_encoder.trunk.blocks.14.norm1.bias', 'image_encoder.trunk.blocks.28.attn.qkv.weight', 'image_encoder.trunk.blocks.13.norm2.weight', 'image_encoder.trunk.blocks.39.norm2.bias', 'image_encoder.trunk.blocks.7.norm1.weight', 'image_encoder.trunk.blocks.26.attn.proj.weight', 'image_encoder.trunk.blocks.4.norm1.weight', 'image_encoder.trunk.blocks.13.attn.qkv.bias', 'image_encoder.trunk.blocks.10.mlp.layers.1.weight', 'image_encoder.trunk.blocks.8.norm2.weight', 'image_encoder.trunk.blocks.1.mlp.layers.1.weight', 'image_encoder.trunk.blocks.29.attn.qkv.weight', 'image_encoder.trunk.blocks.4.attn.qkv.bias', 'image_encoder.trunk.blocks.2.proj.bias', 'image_encoder.trunk.blocks.27.norm2.bias', 'image_encoder.trunk.blocks.29.mlp.layers.1.bias', 'image_encoder.trunk.blocks.1.attn.qkv.weight', 'image_encoder.trunk.blocks.13.attn.proj.weight', 'image_encoder.trunk.blocks.15.attn.qkv.weight', 'image_encoder.trunk.blocks.35.attn.qkv.bias', 'image_encoder.trunk.blocks.2.mlp.layers.0.weight', 'image_encoder.trunk.blocks.45.attn.proj.bias', 'image_encoder.neck.convs.3.conv.weight', 'image_encoder.trunk.blocks.31.attn.qkv.weight', 'image_encoder.trunk.blocks.44.mlp.layers.0.bias', 'image_encoder.trunk.blocks.46.mlp.layers.0.bias', 'image_encoder.trunk.blocks.41.norm1.weight', 'image_encoder.trunk.blocks.14.attn.proj.weight', 'image_encoder.trunk.blocks.18.attn.proj.bias', 'image_encoder.trunk.blocks.17.norm2.bias', 'image_encoder.trunk.blocks.7.attn.proj.weight', 'image_encoder.trunk.blocks.29.attn.proj.bias', 'image_encoder.trunk.blocks.7.attn.proj.bias', 'image_encoder.trunk.blocks.15.mlp.layers.1.bias', 'image_encoder.trunk.blocks.36.mlp.layers.1.bias', 'image_encoder.trunk.blocks.30.mlp.layers.1.bias', 'image_encoder.trunk.blocks.11.norm2.bias', 'image_encoder.trunk.blocks.32.mlp.layers.1.weight', 'image_encoder.trunk.blocks.35.mlp.layers.0.weight', 'image_encoder.trunk.blocks.30.mlp.layers.0.weight', 'image_encoder.trunk.blocks.33.norm2.bias', 'image_encoder.trunk.blocks.20.mlp.layers.1.weight', 'image_encoder.trunk.blocks.36.attn.qkv.weight', 'image_encoder.trunk.blocks.1.mlp.layers.0.weight', 'image_encoder.trunk.blocks.17.attn.proj.weight', 'image_encoder.trunk.blocks.7.attn.qkv.weight', 'image_encoder.neck.convs.0.conv.weight', 'image_encoder.trunk.blocks.32.norm1.bias', 'image_encoder.trunk.blocks.26.norm1.weight', 'image_encoder.trunk.blocks.23.norm2.bias', 'image_encoder.trunk.blocks.23.attn.proj.weight', 'image_encoder.trunk.blocks.26.norm2.bias', 'image_encoder.trunk.blocks.21.attn.proj.weight', 'image_encoder.trunk.blocks.39.norm2.weight', 'image_encoder.trunk.blocks.30.mlp.layers.0.bias', 'image_encoder.trunk.blocks.16.norm1.weight', 'image_encoder.trunk.blocks.13.norm2.bias', 'image_encoder.trunk.blocks.6.mlp.layers.0.bias', 'image_encoder.trunk.blocks.35.norm2.bias', 'image_encoder.trunk.blocks.5.mlp.layers.0.bias', 'image_encoder.trunk.blocks.24.attn.proj.weight', 'image_encoder.trunk.blocks.31.norm2.weight', 'image_encoder.trunk.blocks.22.mlp.layers.1.weight', 'image_encoder.trunk.blocks.20.norm2.weight', 'image_encoder.trunk.blocks.35.norm1.weight', 'image_encoder.trunk.blocks.15.norm1.weight', 'image_encoder.trunk.blocks.3.mlp.layers.1.weight', 'image_encoder.trunk.blocks.17.attn.qkv.weight', 'image_encoder.trunk.blocks.31.norm1.weight', 'image_encoder.trunk.blocks.25.mlp.layers.0.bias', 'image_encoder.trunk.blocks.3.norm2.weight', 'image_encoder.trunk.blocks.19.attn.qkv.weight', 'image_encoder.trunk.blocks.37.norm1.weight', 'image_encoder.trunk.blocks.47.mlp.layers.1.weight', 'image_encoder.trunk.blocks.41.attn.proj.bias', 'image_encoder.trunk.blocks.33.norm1.weight', 'image_encoder.trunk.blocks.9.attn.qkv.weight', 'image_encoder.trunk.blocks.29.norm2.weight', 'image_encoder.trunk.blocks.5.norm2.weight', 'image_encoder.trunk.blocks.25.mlp.layers.1.bias', 'image_encoder.trunk.blocks.32.attn.qkv.bias', 'image_encoder.trunk.blocks.8.proj.weight', 'image_encoder.trunk.blocks.38.attn.proj.weight', 'image_encoder.neck.convs.1.conv.weight', 'image_encoder.trunk.blocks.42.mlp.layers.1.weight', 'image_encoder.trunk.blocks.41.norm2.bias', 'image_encoder.trunk.blocks.34.attn.qkv.weight', 'image_encoder.trunk.blocks.36.norm2.bias', 'image_encoder.trunk.blocks.29.attn.qkv.bias', 'image_encoder.trunk.blocks.37.attn.proj.bias', 'image_encoder.trunk.blocks.47.attn.proj.weight', 'image_encoder.trunk.blocks.0.attn.qkv.bias', 'image_encoder.trunk.blocks.20.norm2.bias', 'image_encoder.trunk.blocks.37.attn.qkv.weight', 'image_encoder.trunk.blocks.16.norm2.weight', 'image_encoder.trunk.blocks.7.norm2.bias', 'image_encoder.trunk.blocks.21.norm2.bias', 'image_encoder.trunk.blocks.12.norm2.weight', 'image_encoder.trunk.blocks.7.mlp.layers.1.weight', 'image_encoder.trunk.blocks.4.attn.proj.bias', 'image_encoder.trunk.blocks.3.norm2.bias', 'image_encoder.trunk.blocks.14.attn.qkv.bias', 'image_encoder.trunk.blocks.46.attn.proj.bias', 'image_encoder.trunk.blocks.37.mlp.layers.1.weight', 'image_encoder.trunk.blocks.43.norm2.weight', 'image_encoder.trunk.blocks.34.mlp.layers.1.bias', 'image_encoder.trunk.blocks.20.mlp.layers.0.weight', 'image_encoder.trunk.blocks.9.norm1.weight', 'image_encoder.trunk.blocks.47.mlp.layers.1.bias', 'image_encoder.trunk.blocks.25.attn.qkv.bias', 'image_encoder.trunk.blocks.17.mlp.layers.0.weight', 'image_encoder.trunk.blocks.44.proj.weight', 'image_encoder.trunk.blocks.24.mlp.layers.0.weight', 'image_encoder.trunk.blocks.25.norm2.weight', 'image_encoder.trunk.blocks.3.norm1.bias', 'image_encoder.trunk.blocks.23.mlp.layers.0.weight', 'image_encoder.trunk.blocks.46.norm2.bias', 'image_encoder.trunk.blocks.12.attn.qkv.bias'}
INFO 2025-12-09 22:15:57,236 optimizer.py: 248: Matches for param_name [*bias*]: {'memory_encoder.fuser.layers.0.norm.bias', 'image_encoder.trunk.blocks.37.mlp.layers.0.bias', 'image_encoder.trunk.blocks.31.norm1.bias', 'image_encoder.trunk.blocks.20.mlp.layers.1.bias', 'image_encoder.trunk.blocks.28.norm2.bias', 'memory_encoder.mask_downsampler.encoder.7.bias', 'image_encoder.trunk.blocks.40.norm1.bias', 'image_encoder.trunk.blocks.12.attn.proj.bias', 'image_encoder.trunk.blocks.28.attn.qkv.bias', 'image_encoder.trunk.blocks.16.mlp.layers.1.bias', 'memory_attention.layers.3.cross_attn_image.q_proj.bias', 'sam_mask_decoder.transformer.layers.1.self_attn.k_proj.bias', 'sam_mask_decoder.transformer.layers.1.cross_attn_token_to_image.v_proj.bias', 'image_encoder.trunk.blocks.44.attn.qkv.bias', 'routefuse.conv_dense.bias', 'memory_attention.layers.1.self_attn.out_proj.bias', 'image_encoder.trunk.blocks.28.mlp.layers.1.bias', 'memory_attention.layers.2.norm3.bias', 'image_encoder.trunk.blocks.17.mlp.layers.0.bias', 'image_encoder.trunk.blocks.17.mlp.layers.1.bias', 'image_encoder.trunk.blocks.20.mlp.layers.0.bias', 'image_encoder.trunk.blocks.42.attn.qkv.bias', 'image_encoder.trunk.blocks.7.norm1.bias', 'image_encoder.trunk.blocks.10.attn.proj.bias', 'memory_attention.layers.2.norm2.bias', 'image_encoder.trunk.blocks.18.attn.qkv.bias', 'image_encoder.trunk.blocks.37.norm2.bias', 'sam_mask_decoder.transformer.layers.1.cross_attn_token_to_image.k_proj.bias', 'image_encoder.trunk.blocks.41.norm1.bias', 'ME.branch1.0.bn.bias', 'image_encoder.trunk.blocks.6.norm1.bias', 'sam_mask_decoder.transformer.layers.1.self_attn.out_proj.bias', 'image_encoder.trunk.blocks.21.attn.qkv.bias', 'image_encoder.trunk.blocks.38.attn.qkv.bias', 'memory_attention.layers.3.self_attn.q_proj.bias', 'memory_attention.layers.3.linear1.bias', 'image_encoder.trunk.blocks.24.attn.qkv.bias', 'image_encoder.trunk.blocks.24.mlp.layers.0.bias', 'memory_attention.layers.2.cross_attn_image.k_proj.bias', 'sam_mask_decoder.transformer.layers.0.cross_attn_token_to_image.v_proj.bias', 'sam_mask_decoder.transformer.layers.0.cross_attn_image_to_token.out_proj.bias', 'image_encoder.trunk.blocks.22.norm2.bias', 'image_encoder.trunk.blocks.27.norm1.bias', 'image_encoder.trunk.blocks.16.norm1.bias', 'image_encoder.trunk.blocks.11.norm1.bias', 'image_encoder.trunk.blocks.38.mlp.layers.0.bias', 'image_encoder.trunk.blocks.4.norm2.bias', 'image_encoder.trunk.blocks.22.mlp.layers.1.bias', 'memory_attention.layers.2.self_attn.k_proj.bias', 'image_encoder.trunk.blocks.35.mlp.layers.1.bias', 'image_encoder.trunk.blocks.9.attn.proj.bias', 'sam_prompt_encoder.mask_downscaling.0.bias', 'image_encoder.trunk.blocks.25.norm2.bias', 'image_encoder.trunk.blocks.47.attn.qkv.bias', 'image_encoder.trunk.blocks.8.attn.qkv.bias', 'image_encoder.trunk.blocks.35.attn.proj.bias', 'memory_encoder.mask_downsampler.encoder.3.bias', 'image_encoder.trunk.blocks.20.norm1.bias', 'image_encoder.trunk.blocks.43.norm1.bias', 'sam_mask_decoder.transformer.layers.1.norm3.bias', 'image_encoder.trunk.blocks.4.mlp.layers.1.bias', 'memory_encoder.mask_downsampler.encoder.10.bias', 'sam_mask_decoder.transformer.norm_final_attn.bias', 'image_encoder.trunk.blocks.15.attn.proj.bias', 'image_encoder.trunk.blocks.21.mlp.layers.1.bias', 'memory_encoder.fuser.layers.0.pwconv1.bias', 'image_encoder.trunk.blocks.10.attn.qkv.bias', 'image_encoder.trunk.blocks.6.norm2.bias', 'image_encoder.trunk.blocks.12.norm2.bias', 'memory_attention.layers.1.norm3.bias', 'sam_mask_decoder.iou_prediction_head.layers.1.bias', 'sam_mask_decoder.transformer.layers.0.self_attn.q_proj.bias', 'image_encoder.trunk.blocks.28.mlp.layers.0.bias', 'image_encoder.trunk.blocks.36.mlp.layers.0.bias', 'image_encoder.trunk.blocks.20.attn.qkv.bias', 'image_encoder.trunk.blocks.32.mlp.layers.0.bias', 'image_encoder.trunk.blocks.23.mlp.layers.0.bias', 'ME.seq_modeling_block.conv_k.bias', 'image_encoder.trunk.blocks.5.norm1.bias', 'memory_encoder.fuser.layers.1.dwconv.bias', 'sam_mask_decoder.transformer.layers.1.cross_attn_token_to_image.q_proj.bias', 'memory_attention.layers.1.norm1.bias', 'image_encoder.neck.convs.3.conv.bias', 'image_encoder.trunk.blocks.19.mlp.layers.0.bias', 'image_encoder.trunk.blocks.44.norm1.bias', 'memory_attention.layers.2.linear1.bias', 'image_encoder.trunk.blocks.44.norm2.bias', 'image_encoder.trunk.blocks.8.attn.proj.bias', 'memory_attention.norm.bias', 'memory_attention.layers.0.cross_attn_image.out_proj.bias', 'image_encoder.trunk.blocks.14.attn.proj.bias', 'image_encoder.trunk.blocks.10.mlp.layers.0.bias', 'memory_attention.layers.2.self_attn.v_proj.bias', 'image_encoder.trunk.blocks.31.mlp.layers.0.bias', 'image_encoder.trunk.blocks.3.attn.proj.bias', 'image_encoder.trunk.blocks.33.attn.qkv.bias', 'image_encoder.trunk.blocks.6.attn.proj.bias', 'sam_prompt_encoder.mask_downscaling.1.bias', 'image_encoder.trunk.blocks.25.attn.proj.bias', 'memory_attention.layers.1.linear2.bias', 'sam_mask_decoder.conv_s1.bias', 'image_encoder.trunk.blocks.26.mlp.layers.0.bias', 'image_encoder.trunk.blocks.47.mlp.layers.0.bias', 'memory_attention.layers.2.norm1.bias', 'image_encoder.trunk.blocks.15.norm2.bias', 'image_encoder.trunk.blocks.23.attn.proj.bias', 'image_encoder.trunk.blocks.18.mlp.layers.1.bias', 'image_encoder.trunk.blocks.29.mlp.layers.0.bias', 'image_encoder.trunk.blocks.13.mlp.layers.1.bias', 'image_encoder.trunk.blocks.17.attn.proj.bias', 'image_encoder.trunk.blocks.37.norm1.bias', 'image_encoder.trunk.blocks.16.attn.proj.bias', 'image_encoder.trunk.blocks.44.attn.proj.bias', 'image_encoder.neck.convs.2.conv.bias', 'ME.branch1.3.bn.bias', 'image_encoder.trunk.blocks.3.mlp.layers.0.bias', 'memory_encoder.out_proj.bias', 'image_encoder.trunk.blocks.10.norm1.bias', 'image_encoder.trunk.blocks.8.norm2.bias', 'image_encoder.trunk.blocks.2.attn.proj.bias', 'image_encoder.trunk.blocks.42.norm1.bias', 'memory_attention.layers.3.cross_attn_image.v_proj.bias', 'image_encoder.trunk.blocks.9.norm1.bias', 'memory_attention.layers.1.cross_attn_image.q_proj.bias', 'memory_attention.layers.3.norm3.bias', 'image_encoder.trunk.blocks.15.mlp.layers.0.bias', 'obj_ptr_proj.layers.0.bias', 'image_encoder.trunk.blocks.0.norm1.bias', 'image_encoder.trunk.blocks.4.mlp.layers.0.bias', 'image_encoder.trunk.blocks.19.norm2.bias', 'image_encoder.trunk.blocks.14.mlp.layers.0.bias', 'memory_encoder.pix_feat_proj.bias', 'image_encoder.trunk.blocks.43.attn.proj.bias', 'image_encoder.trunk.blocks.18.norm1.bias', 'image_encoder.trunk.blocks.9.norm2.bias', 'sam_mask_decoder.transformer.layers.0.cross_attn_image_to_token.v_proj.bias', 'image_encoder.trunk.blocks.31.norm2.bias', 'memory_attention.layers.2.linear2.bias', 'image_encoder.trunk.blocks.14.mlp.layers.1.bias', 'image_encoder.trunk.blocks.26.mlp.layers.1.bias', 'memory_attention.layers.3.cross_attn_image.k_proj.bias', 'sam_mask_decoder.pred_obj_score_head.layers.0.bias', 'image_encoder.trunk.blocks.10.norm2.bias', 'image_encoder.trunk.blocks.39.mlp.layers.0.bias', 'memory_attention.layers.0.norm2.bias', 'image_encoder.trunk.blocks.24.norm1.bias', 'sam_mask_decoder.transformer.final_attn_token_to_image.q_proj.bias', 'image_encoder.trunk.blocks.41.mlp.layers.0.bias', 'image_encoder.trunk.blocks.1.norm1.bias', 'image_encoder.trunk.blocks.38.mlp.layers.1.bias', 'memory_attention.layers.0.self_attn.out_proj.bias', 'image_encoder.trunk.blocks.12.mlp.layers.0.bias', 'image_encoder.trunk.blocks.26.attn.proj.bias', 'image_encoder.trunk.blocks.8.mlp.layers.1.bias', 'image_encoder.neck.convs.1.conv.bias', 'memory_attention.layers.1.norm2.bias', 'sam_mask_decoder.output_hypernetworks_mlps.2.layers.1.bias', 'image_encoder.trunk.blocks.4.norm1.bias', 'image_encoder.trunk.blocks.15.norm1.bias', 'image_encoder.trunk.blocks.43.mlp.layers.1.bias', 'sam_mask_decoder.output_hypernetworks_mlps.3.layers.1.bias', 'image_encoder.trunk.blocks.19.norm1.bias', 'memory_encoder.mask_downsampler.encoder.1.bias', 'image_encoder.trunk.blocks.26.attn.qkv.bias', 'image_encoder.trunk.blocks.18.mlp.layers.0.bias', 'image_encoder.trunk.blocks.27.mlp.layers.0.bias', 'image_encoder.trunk.blocks.19.mlp.layers.1.bias', 'sam_mask_decoder.transformer.layers.0.self_attn.v_proj.bias', 'image_encoder.trunk.blocks.0.attn.proj.bias', 'image_encoder.trunk.blocks.22.mlp.layers.0.bias', 'image_encoder.trunk.blocks.39.attn.proj.bias', 'image_encoder.trunk.blocks.41.attn.qkv.bias', 'image_encoder.trunk.blocks.45.mlp.layers.0.bias', 'image_encoder.trunk.blocks.40.mlp.layers.1.bias', 'image_encoder.trunk.blocks.38.norm1.bias', 'image_encoder.trunk.blocks.7.mlp.layers.1.bias', 'sam_mask_decoder.transformer.layers.0.norm3.bias', 'image_encoder.trunk.blocks.33.norm1.bias', 'image_encoder.trunk.blocks.45.mlp.layers.1.bias', 'memory_encoder.fuser.layers.1.norm.bias', 'sam_prompt_encoder.mask_downscaling.4.bias', 'image_encoder.trunk.blocks.36.norm1.bias', 'image_encoder.trunk.blocks.13.attn.proj.bias', 'image_encoder.trunk.blocks.17.norm1.bias', 'image_encoder.trunk.blocks.46.mlp.layers.1.bias', 'image_encoder.trunk.blocks.31.mlp.layers.1.bias', 'image_encoder.trunk.blocks.40.attn.proj.bias', 'image_encoder.trunk.blocks.30.attn.proj.bias', 'image_encoder.trunk.blocks.13.norm1.bias', 'memory_attention.layers.3.norm2.bias', 'image_encoder.trunk.blocks.37.mlp.layers.1.bias', 'image_encoder.trunk.blocks.42.norm2.bias', 'sam_mask_decoder.transformer.layers.0.mlp.layers.1.bias', 'sam_mask_decoder.transformer.layers.1.norm1.bias', 'image_encoder.trunk.blocks.22.attn.proj.bias', 'image_encoder.trunk.blocks.11.attn.qkv.bias', 'image_encoder.trunk.blocks.14.norm2.bias', 'image_encoder.trunk.blocks.5.attn.proj.bias', 'ME.norm.bias', 'image_encoder.trunk.blocks.6.mlp.layers.1.bias', 'memory_attention.layers.3.self_attn.v_proj.bias', 'image_encoder.trunk.blocks.2.norm1.bias', 'image_encoder.trunk.blocks.31.attn.qkv.bias', 'sam_mask_decoder.output_hypernetworks_mlps.3.layers.2.bias', 'image_encoder.trunk.blocks.35.norm1.bias', 'image_encoder.trunk.blocks.22.attn.qkv.bias', 'ME.seq_modeling_block.learnable_ttt_lr_bias', 'image_encoder.trunk.blocks.38.norm2.bias', 'image_encoder.trunk.blocks.43.norm2.bias', 'memory_attention.layers.0.self_attn.q_proj.bias', 'sam_mask_decoder.conv_s0.bias', 'memory_attention.layers.2.cross_attn_image.q_proj.bias', 'sam_mask_decoder.pred_obj_score_head.layers.1.bias', 'sam_mask_decoder.output_hypernetworks_mlps.1.layers.2.bias', 'image_encoder.trunk.blocks.27.attn.qkv.bias', 'image_encoder.trunk.blocks.23.norm1.bias', 'memory_encoder.mask_downsampler.encoder.0.bias', 'sam_mask_decoder.transformer.final_attn_token_to_image.k_proj.bias', 'image_encoder.trunk.blocks.27.attn.proj.bias', 'memory_attention.layers.0.linear2.bias', 'image_encoder.trunk.blocks.0.mlp.layers.0.bias', 'image_encoder.trunk.blocks.32.norm2.bias', 'image_encoder.trunk.blocks.3.attn.qkv.bias', 'sam_mask_decoder.transformer.layers.1.norm4.bias', 'sam_mask_decoder.output_hypernetworks_mlps.0.layers.0.bias', 'sam_mask_decoder.transformer.final_attn_token_to_image.v_proj.bias', 'sam_mask_decoder.pred_obj_score_head.layers.2.bias', 'sam_mask_decoder.output_hypernetworks_mlps.2.layers.0.bias', 'sam_mask_decoder.output_hypernetworks_mlps.1.layers.0.bias', 'image_encoder.trunk.blocks.33.attn.proj.bias', 'memory_attention.layers.3.cross_attn_image.out_proj.bias', 'memory_attention.layers.1.cross_attn_image.out_proj.bias', 'image_encoder.trunk.blocks.19.attn.proj.bias', 'sam_mask_decoder.transformer.layers.0.norm2.bias', 'ME.branch1.2.bn.bias', 'image_encoder.trunk.blocks.24.norm2.bias', 'obj_ptr_proj.layers.2.bias', 'image_encoder.trunk.blocks.16.norm2.bias', 'image_encoder.trunk.blocks.5.attn.qkv.bias', 'image_encoder.trunk.blocks.0.norm2.bias', 'image_encoder.trunk.blocks.29.norm2.bias', 'image_encoder.trunk.blocks.31.attn.proj.bias', 'obj_ptr_proj.layers.1.bias', 'mask_downsample.bias', 'image_encoder.trunk.blocks.7.mlp.layers.0.bias', 'memory_attention.layers.3.self_attn.out_proj.bias', 'sam_mask_decoder.transformer.layers.1.norm2.bias', 'image_encoder.trunk.blocks.13.mlp.layers.0.bias', 'sam_mask_decoder.transformer.layers.1.self_attn.q_proj.bias', 'image_encoder.trunk.blocks.19.attn.qkv.bias', 'memory_attention.layers.0.cross_attn_image.q_proj.bias', 'ME.branch1.1.bn.bias', 'image_encoder.trunk.blocks.2.mlp.layers.0.bias', 'image_encoder.trunk.blocks.39.norm1.bias', 'image_encoder.trunk.blocks.12.norm1.bias', 'image_encoder.trunk.blocks.41.mlp.layers.1.bias', 'image_encoder.trunk.blocks.8.norm1.bias', 'sam_mask_decoder.output_hypernetworks_mlps.1.layers.1.bias', 'image_encoder.trunk.blocks.9.mlp.layers.0.bias', 'image_encoder.trunk.blocks.35.mlp.layers.0.bias', 'image_encoder.trunk.blocks.45.norm1.bias', 'image_encoder.trunk.blocks.46.norm1.bias', 'image_encoder.trunk.blocks.23.attn.qkv.bias', 'image_encoder.trunk.blocks.42.mlp.layers.1.bias', 'image_encoder.trunk.blocks.29.norm1.bias', 'image_encoder.trunk.blocks.16.mlp.layers.0.bias', 'sam_mask_decoder.transformer.layers.0.self_attn.out_proj.bias', 'image_encoder.trunk.blocks.27.mlp.layers.1.bias', 'image_encoder.trunk.blocks.1.mlp.layers.1.bias', 'image_encoder.trunk.blocks.21.attn.proj.bias', 'image_encoder.trunk.blocks.11.attn.proj.bias', 'image_encoder.trunk.blocks.47.norm1.bias', 'image_encoder.trunk.blocks.22.norm1.bias', 'image_encoder.trunk.blocks.30.norm1.bias', 'image_encoder.trunk.blocks.23.mlp.layers.1.bias', 'image_encoder.trunk.blocks.39.mlp.layers.1.bias', 'image_encoder.trunk.blocks.33.mlp.layers.0.bias', 'memory_encoder.fuser.layers.1.pwconv1.bias', 'sam_mask_decoder.transformer.layers.1.cross_attn_image_to_token.k_proj.bias', 'sam_mask_decoder.transformer.layers.0.norm4.bias', 'image_encoder.trunk.blocks.44.proj.bias', 'image_encoder.trunk.blocks.2.attn.qkv.bias', 'image_encoder.trunk.blocks.34.norm2.bias', 'image_encoder.trunk.blocks.24.attn.proj.bias', 'image_encoder.trunk.blocks.2.mlp.layers.1.bias', 'image_encoder.trunk.blocks.9.attn.qkv.bias', 'image_encoder.trunk.blocks.42.attn.proj.bias', 'image_encoder.trunk.patch_embed.proj.bias', 'image_encoder.trunk.blocks.37.attn.qkv.bias', 'memory_attention.layers.0.self_attn.k_proj.bias', 'image_encoder.trunk.blocks.10.mlp.layers.1.bias', 'ME.depthwise_conv_reduce_channels_out2.bias', 'image_encoder.trunk.blocks.43.mlp.layers.0.bias', 'sam_mask_decoder.output_upscaling.1.bias', 'memory_attention.layers.3.self_attn.k_proj.bias', 'sam_mask_decoder.iou_prediction_head.layers.2.bias', 'memory_encoder.mask_downsampler.encoder.12.bias', 'image_encoder.trunk.blocks.34.mlp.layers.0.bias', 'memory_attention.layers.2.self_attn.out_proj.bias', 'image_encoder.trunk.blocks.1.norm2.bias', 'sam_mask_decoder.output_upscaling.0.bias', 'image_encoder.trunk.blocks.45.norm2.bias', 'image_encoder.trunk.blocks.0.mlp.layers.1.bias', 'sam_mask_decoder.iou_prediction_head.layers.0.bias', 'image_encoder.trunk.blocks.40.mlp.layers.0.bias', 'image_encoder.trunk.blocks.34.attn.qkv.bias', 'memory_attention.layers.1.linear1.bias', 'sam_mask_decoder.transformer.layers.0.mlp.layers.0.bias', 'image_encoder.trunk.blocks.18.norm2.bias', 'memory_attention.layers.0.linear1.bias', 'image_encoder.trunk.blocks.11.mlp.layers.1.bias', 'sam_mask_decoder.transformer.final_attn_token_to_image.out_proj.bias', 'image_encoder.neck.convs.0.conv.bias', 'sam_mask_decoder.transformer.layers.0.cross_attn_token_to_image.out_proj.bias', 'image_encoder.trunk.blocks.2.norm2.bias', 'image_encoder.trunk.blocks.46.attn.qkv.bias', 'image_encoder.trunk.blocks.3.mlp.layers.1.bias', 'image_encoder.trunk.blocks.34.attn.proj.bias', 'ME.depthwise_conv_reduce_channels_in.bias', 'image_encoder.trunk.blocks.42.mlp.layers.0.bias', 'image_encoder.trunk.blocks.7.attn.qkv.bias', 'image_encoder.trunk.blocks.8.proj.bias', 'image_encoder.trunk.blocks.17.attn.qkv.bias', 'sam_mask_decoder.transformer.layers.0.cross_attn_token_to_image.k_proj.bias', 'image_encoder.trunk.blocks.1.attn.proj.bias', 'image_encoder.trunk.blocks.8.mlp.layers.0.bias', 'image_encoder.trunk.blocks.40.norm2.bias', 'image_encoder.trunk.blocks.11.mlp.layers.0.bias', 'image_encoder.trunk.blocks.9.mlp.layers.1.bias', 'image_encoder.trunk.blocks.12.mlp.layers.1.bias', 'image_encoder.trunk.blocks.32.mlp.layers.1.bias', 'image_encoder.trunk.blocks.34.norm1.bias', 'memory_attention.layers.0.cross_attn_image.k_proj.bias', 'image_encoder.trunk.blocks.38.attn.proj.bias', 'image_encoder.trunk.blocks.44.mlp.layers.1.bias', 'sam_mask_decoder.transformer.layers.1.self_attn.v_proj.bias', 'image_encoder.trunk.blocks.6.attn.qkv.bias', 'memory_attention.layers.2.self_attn.q_proj.bias', 'image_encoder.trunk.blocks.28.norm1.bias', 'memory_attention.layers.0.cross_attn_image.v_proj.bias', 'image_encoder.trunk.blocks.1.attn.qkv.bias', 'image_encoder.trunk.blocks.24.mlp.layers.1.bias', 'image_encoder.trunk.blocks.25.norm1.bias', 'image_encoder.trunk.blocks.15.attn.qkv.bias', 'image_encoder.trunk.blocks.33.mlp.layers.1.bias', 'image_encoder.trunk.blocks.5.mlp.layers.1.bias', 'image_encoder.trunk.blocks.30.attn.qkv.bias', 'image_encoder.trunk.blocks.39.attn.qkv.bias', 'image_encoder.trunk.blocks.43.attn.qkv.bias', 'image_encoder.trunk.blocks.1.mlp.layers.0.bias', 'ME.seq_modeling_block.ttt_norm_bias', 'sam_mask_decoder.transformer.layers.0.cross_attn_image_to_token.q_proj.bias', 'image_encoder.trunk.blocks.5.norm2.bias', 'image_encoder.trunk.blocks.26.norm1.bias', 'image_encoder.trunk.blocks.16.attn.qkv.bias', 'image_encoder.trunk.blocks.36.attn.proj.bias', 'image_encoder.trunk.blocks.45.attn.qkv.bias', 'image_encoder.trunk.blocks.28.attn.proj.bias', 'obj_ptr_tpos_proj.bias', 'memory_attention.layers.3.linear2.bias', 'image_encoder.trunk.blocks.21.mlp.layers.0.bias', 'image_encoder.trunk.blocks.40.attn.qkv.bias', 'sam_mask_decoder.transformer.layers.1.mlp.layers.1.bias', 'memory_encoder.fuser.layers.1.pwconv2.bias', 'image_encoder.trunk.blocks.36.attn.qkv.bias', 'memory_attention.layers.1.self_attn.k_proj.bias', 'sam_prompt_encoder.mask_downscaling.6.bias', 'memory_attention.layers.1.self_attn.q_proj.bias', 'sam_mask_decoder.output_hypernetworks_mlps.0.layers.1.bias', 'memory_attention.layers.2.cross_attn_image.v_proj.bias', 'ME.seq_modeling_block.post_norm.bias', 'image_encoder.trunk.blocks.20.attn.proj.bias', 'image_encoder.trunk.blocks.21.norm1.bias', 'image_encoder.trunk.blocks.30.norm2.bias', 'image_encoder.trunk.blocks.32.attn.proj.bias', 'image_encoder.trunk.blocks.47.attn.proj.bias', 'image_encoder.trunk.blocks.47.norm2.bias', 'image_encoder.trunk.blocks.14.norm1.bias', 'image_encoder.trunk.blocks.39.norm2.bias', 'image_encoder.trunk.blocks.13.attn.qkv.bias', 'image_encoder.trunk.blocks.29.mlp.layers.1.bias', 'image_encoder.trunk.blocks.4.attn.qkv.bias', 'image_encoder.trunk.blocks.2.proj.bias', 'image_encoder.trunk.blocks.27.norm2.bias', 'memory_attention.layers.2.cross_attn_image.out_proj.bias', 'image_encoder.trunk.blocks.35.attn.qkv.bias', 'image_encoder.trunk.blocks.45.attn.proj.bias', 'memory_attention.layers.0.self_attn.v_proj.bias', 'image_encoder.trunk.blocks.44.mlp.layers.0.bias', 'image_encoder.trunk.blocks.46.mlp.layers.0.bias', 'image_encoder.trunk.blocks.18.attn.proj.bias', 'image_encoder.trunk.blocks.17.norm2.bias', 'image_encoder.trunk.blocks.29.attn.proj.bias', 'image_encoder.trunk.blocks.7.attn.proj.bias', 'image_encoder.trunk.blocks.15.mlp.layers.1.bias', 'image_encoder.trunk.blocks.36.mlp.layers.1.bias', 'image_encoder.trunk.blocks.30.mlp.layers.1.bias', 'image_encoder.trunk.blocks.11.norm2.bias', 'image_encoder.trunk.blocks.33.norm2.bias', 'memory_encoder.mask_downsampler.encoder.6.bias', 'image_encoder.trunk.blocks.32.norm1.bias', 'image_encoder.trunk.blocks.23.norm2.bias', 'sam_mask_decoder.transformer.layers.1.cross_attn_image_to_token.out_proj.bias', 'memory_attention.layers.1.cross_attn_image.v_proj.bias', 'sam_mask_decoder.transformer.layers.1.cross_attn_image_to_token.q_proj.bias', 'image_encoder.trunk.blocks.26.norm2.bias', 'image_encoder.trunk.blocks.30.mlp.layers.0.bias', 'memory_encoder.fuser.layers.0.dwconv.bias', 'image_encoder.trunk.blocks.13.norm2.bias', 'sam_mask_decoder.transformer.layers.1.cross_attn_image_to_token.v_proj.bias', 'image_encoder.trunk.blocks.6.mlp.layers.0.bias', 'ME.depthwise_conv_reduce_channels_out1.bias', 'image_encoder.trunk.blocks.35.norm2.bias', 'image_encoder.trunk.blocks.5.mlp.layers.0.bias', 'sam_mask_decoder.output_upscaling.3.bias', 'sam_mask_decoder.transformer.layers.0.cross_attn_image_to_token.k_proj.bias', 'memory_encoder.mask_downsampler.encoder.9.bias', 'memory_encoder.mask_downsampler.encoder.4.bias', 'image_encoder.trunk.blocks.25.mlp.layers.0.bias', 'image_encoder.trunk.blocks.41.attn.proj.bias', 'sam_prompt_encoder.mask_downscaling.3.bias', 'sam_mask_decoder.transformer.layers.1.mlp.layers.0.bias', 'image_encoder.trunk.blocks.25.mlp.layers.1.bias', 'sam_mask_decoder.transformer.layers.1.cross_attn_token_to_image.out_proj.bias', 'image_encoder.trunk.blocks.32.attn.qkv.bias', 'image_encoder.trunk.blocks.41.norm2.bias', 'ME.seq_modeling_block.conv_q.bias', 'memory_attention.layers.1.cross_attn_image.k_proj.bias', 'image_encoder.trunk.blocks.36.norm2.bias', 'memory_attention.layers.1.self_attn.v_proj.bias', 'image_encoder.trunk.blocks.29.attn.qkv.bias', 'image_encoder.trunk.blocks.37.attn.proj.bias', 'memory_attention.layers.0.norm1.bias', 'image_encoder.trunk.blocks.0.attn.qkv.bias', 'image_encoder.trunk.blocks.20.norm2.bias', 'image_encoder.trunk.blocks.7.norm2.bias', 'image_encoder.trunk.blocks.21.norm2.bias', 'image_encoder.trunk.blocks.4.attn.proj.bias', 'image_encoder.trunk.blocks.3.norm2.bias', 'image_encoder.trunk.blocks.14.attn.qkv.bias', 'sam_mask_decoder.transformer.layers.0.norm1.bias', 'sam_mask_decoder.transformer.layers.0.self_attn.k_proj.bias', 'image_encoder.trunk.blocks.46.attn.proj.bias', 'memory_attention.layers.3.norm1.bias', 'image_encoder.trunk.blocks.34.mlp.layers.1.bias', 'sam_mask_decoder.output_hypernetworks_mlps.3.layers.0.bias', 'image_encoder.trunk.blocks.47.mlp.layers.1.bias', 'image_encoder.trunk.blocks.25.attn.qkv.bias', 'sam_mask_decoder.output_hypernetworks_mlps.0.layers.2.bias', 'memory_attention.layers.0.norm3.bias', 'sam_mask_decoder.output_hypernetworks_mlps.2.layers.2.bias', 'image_encoder.trunk.blocks.3.norm1.bias', 'sam_mask_decoder.transformer.layers.0.cross_attn_token_to_image.q_proj.bias', 'memory_encoder.fuser.layers.0.pwconv2.bias', 'image_encoder.trunk.blocks.46.norm2.bias', 'image_encoder.trunk.blocks.12.attn.qkv.bias'}
INFO 2025-12-09 22:15:57,236 optimizer.py: 220: Matches for module_cls_name [torch.nn.LayerNorm]: {'image_encoder.trunk.blocks.9.norm2.bias', 'image_encoder.trunk.blocks.21.norm1.weight', 'image_encoder.trunk.blocks.18.norm1.weight', 'image_encoder.trunk.blocks.30.norm2.weight', 'memory_attention.layers.2.norm3.weight', 'image_encoder.trunk.blocks.2.norm1.weight', 'image_encoder.trunk.blocks.10.norm2.weight', 'image_encoder.trunk.blocks.5.norm2.bias', 'image_encoder.trunk.blocks.31.norm1.bias', 'image_encoder.trunk.blocks.39.norm1.bias', 'image_encoder.trunk.blocks.31.norm2.bias', 'image_encoder.trunk.blocks.12.norm1.bias', 'image_encoder.trunk.blocks.28.norm2.bias', 'image_encoder.trunk.blocks.44.norm1.weight', 'image_encoder.trunk.blocks.40.norm1.bias', 'image_encoder.trunk.blocks.26.norm1.bias', 'image_encoder.trunk.blocks.8.norm1.bias', 'sam_mask_decoder.transformer.norm_final_attn.weight', 'memory_attention.layers.3.norm2.weight', 'memory_attention.norm.weight', 'image_encoder.trunk.blocks.2.norm2.weight', 'image_encoder.trunk.blocks.6.norm1.weight', 'memory_attention.layers.0.norm3.weight', 'image_encoder.trunk.blocks.37.norm2.weight', 'image_encoder.trunk.blocks.36.norm1.weight', 'image_encoder.trunk.blocks.10.norm2.bias', 'image_encoder.trunk.blocks.35.norm2.weight', 'image_encoder.trunk.blocks.40.norm2.weight', 'memory_attention.layers.0.norm2.bias', 'memory_attention.layers.2.norm3.bias', 'image_encoder.trunk.blocks.11.norm2.weight', 'image_encoder.trunk.blocks.38.norm2.weight', 'image_encoder.trunk.blocks.24.norm1.bias', 'image_encoder.trunk.blocks.7.norm1.bias', 'image_encoder.trunk.blocks.1.norm1.bias', 'image_encoder.trunk.blocks.33.norm2.weight', 'image_encoder.trunk.blocks.45.norm1.bias', 'memory_attention.layers.2.norm1.weight', 'ME.seq_modeling_block.post_norm.bias', 'memory_attention.layers.2.norm2.bias', 'image_encoder.trunk.blocks.21.norm1.bias', 'image_encoder.trunk.blocks.30.norm2.bias', 'image_encoder.trunk.blocks.37.norm2.bias', 'image_encoder.trunk.blocks.41.norm1.bias', 'image_encoder.trunk.blocks.46.norm1.bias', 'memory_attention.layers.1.norm2.bias', 'image_encoder.trunk.blocks.47.norm2.bias', 'image_encoder.trunk.blocks.6.norm1.bias', 'image_encoder.trunk.blocks.17.norm2.weight', 'image_encoder.trunk.blocks.47.norm1.weight', 'image_encoder.trunk.blocks.10.norm1.weight', 'image_encoder.trunk.blocks.14.norm1.bias', 'image_encoder.trunk.blocks.34.norm1.weight', 'image_encoder.trunk.blocks.29.norm1.bias', 'image_encoder.trunk.blocks.4.norm1.bias', 'image_encoder.trunk.blocks.13.norm2.weight', 'image_encoder.trunk.blocks.15.norm1.bias', 'image_encoder.trunk.blocks.39.norm2.bias', 'image_encoder.trunk.blocks.22.norm2.bias', 'image_encoder.trunk.blocks.7.norm1.weight', 'image_encoder.trunk.blocks.4.norm1.weight', 'image_encoder.trunk.blocks.19.norm1.bias', 'image_encoder.trunk.blocks.27.norm1.bias', 'image_encoder.trunk.blocks.16.norm1.bias', 'image_encoder.trunk.blocks.8.norm2.weight', 'image_encoder.trunk.blocks.11.norm1.bias', 'image_encoder.trunk.blocks.4.norm2.bias', 'memory_attention.layers.3.norm3.weight', 'image_encoder.trunk.blocks.28.norm1.weight', 'image_encoder.trunk.blocks.18.norm2.weight', 'image_encoder.trunk.blocks.27.norm2.bias', 'ME.seq_modeling_block.post_norm.weight', 'image_encoder.trunk.blocks.7.norm2.weight', 'sam_mask_decoder.transformer.layers.0.norm2.weight', 'image_encoder.trunk.blocks.25.norm2.bias', 'image_encoder.trunk.blocks.39.norm1.weight', 'image_encoder.trunk.blocks.47.norm1.bias', 'image_encoder.trunk.blocks.47.norm2.weight', 'image_encoder.trunk.blocks.22.norm1.bias', 'image_encoder.trunk.blocks.30.norm1.bias', 'image_encoder.trunk.blocks.41.norm1.weight', 'image_encoder.trunk.blocks.32.norm1.weight', 'image_encoder.trunk.blocks.20.norm1.bias', 'image_encoder.trunk.blocks.43.norm1.bias', 'image_encoder.trunk.blocks.6.norm2.weight', 'image_encoder.trunk.blocks.17.norm2.bias', 'sam_mask_decoder.transformer.layers.1.norm3.bias', 'image_encoder.trunk.blocks.4.norm2.weight', 'image_encoder.trunk.blocks.45.norm2.weight', 'sam_mask_decoder.transformer.norm_final_attn.bias', 'image_encoder.trunk.blocks.38.norm1.bias', 'image_encoder.trunk.blocks.6.norm2.bias', 'image_encoder.trunk.blocks.12.norm2.bias', 'image_encoder.trunk.blocks.44.norm2.weight', 'memory_attention.layers.1.norm3.bias', 'image_encoder.trunk.blocks.11.norm2.bias', 'sam_mask_decoder.transformer.layers.0.norm4.bias', 'image_encoder.trunk.blocks.33.norm2.bias', 'image_encoder.trunk.blocks.28.norm2.weight', 'image_encoder.trunk.blocks.34.norm2.bias', 'sam_mask_decoder.transformer.layers.0.norm3.bias', 'image_encoder.trunk.blocks.24.norm2.weight', 'image_encoder.trunk.blocks.33.norm1.bias', 'image_encoder.trunk.blocks.32.norm1.bias', 'image_encoder.trunk.blocks.26.norm1.weight', 'image_encoder.trunk.blocks.23.norm2.bias', 'image_encoder.trunk.blocks.36.norm1.bias', 'image_encoder.trunk.blocks.26.norm2.weight', 'sam_mask_decoder.transformer.layers.0.norm3.weight', 'image_encoder.trunk.blocks.26.norm2.bias', 'image_encoder.trunk.blocks.19.norm2.weight', 'image_encoder.trunk.blocks.8.norm1.weight', 'image_encoder.trunk.blocks.15.norm2.weight', 'image_encoder.trunk.blocks.17.norm1.bias', 'image_encoder.trunk.blocks.39.norm2.weight', 'memory_attention.layers.1.norm3.weight', 'memory_attention.layers.0.norm1.weight', 'ME.norm.weight', 'image_encoder.trunk.blocks.16.norm1.weight', 'image_encoder.trunk.blocks.22.norm1.weight', 'image_encoder.trunk.blocks.13.norm2.bias', 'image_encoder.trunk.blocks.24.norm1.weight', 'image_encoder.trunk.blocks.5.norm1.bias', 'image_encoder.trunk.blocks.13.norm1.bias', 'image_encoder.trunk.blocks.12.norm1.weight', 'image_encoder.trunk.blocks.0.norm2.weight', 'image_encoder.trunk.blocks.42.norm2.bias', 'memory_attention.layers.1.norm1.weight', 'memory_attention.layers.1.norm1.bias', 'memory_attention.layers.3.norm2.bias', 'image_encoder.trunk.blocks.35.norm2.bias', 'image_encoder.trunk.blocks.44.norm1.bias', 'image_encoder.trunk.blocks.1.norm2.bias', 'sam_mask_decoder.transformer.layers.1.norm1.bias', 'image_encoder.trunk.blocks.45.norm2.bias', 'image_encoder.trunk.blocks.14.norm2.bias', 'ME.norm.bias', 'image_encoder.trunk.blocks.44.norm2.bias', 'image_encoder.trunk.blocks.31.norm2.weight', 'memory_attention.norm.bias', 'image_encoder.trunk.blocks.21.norm2.weight', 'image_encoder.trunk.blocks.46.norm1.weight', 'image_encoder.trunk.blocks.20.norm2.weight', 'image_encoder.trunk.blocks.2.norm1.bias', 'image_encoder.trunk.blocks.43.norm1.weight', 'image_encoder.trunk.blocks.35.norm1.weight', 'image_encoder.trunk.blocks.15.norm1.weight', 'image_encoder.trunk.blocks.35.norm1.bias', 'image_encoder.trunk.blocks.18.norm2.bias', 'image_encoder.trunk.blocks.41.norm2.weight', 'image_encoder.trunk.blocks.31.norm1.weight', 'image_encoder.trunk.blocks.0.norm1.weight', 'image_encoder.trunk.blocks.3.norm2.weight', 'image_encoder.trunk.blocks.37.norm1.weight', 'image_encoder.trunk.blocks.42.norm2.weight', 'memory_attention.layers.2.norm1.bias', 'sam_mask_decoder.transformer.layers.1.norm2.weight', 'image_encoder.trunk.blocks.38.norm2.bias', 'image_encoder.trunk.blocks.43.norm2.bias', 'image_encoder.trunk.blocks.33.norm1.weight', 'image_encoder.trunk.blocks.15.norm2.bias', 'image_encoder.trunk.blocks.29.norm2.weight', 'image_encoder.trunk.blocks.2.norm2.bias', 'image_encoder.trunk.blocks.3.norm1.weight', 'image_encoder.trunk.blocks.5.norm2.weight', 'image_encoder.trunk.blocks.19.norm1.weight', 'image_encoder.trunk.blocks.40.norm1.weight', 'image_encoder.trunk.blocks.23.norm2.weight', 'image_encoder.trunk.blocks.23.norm1.weight', 'image_encoder.trunk.blocks.32.norm2.weight', 'image_encoder.trunk.blocks.27.norm1.weight', 'image_encoder.trunk.blocks.37.norm1.bias', 'image_encoder.trunk.blocks.20.norm1.weight', 'image_encoder.trunk.blocks.34.norm2.weight', 'image_encoder.trunk.blocks.23.norm1.bias', 'image_encoder.trunk.blocks.41.norm2.bias', 'sam_mask_decoder.transformer.layers.0.norm1.weight', 'image_encoder.trunk.blocks.9.norm2.weight', 'image_encoder.trunk.blocks.10.norm1.bias', 'image_encoder.trunk.blocks.8.norm2.bias', 'image_encoder.trunk.blocks.42.norm1.bias', 'image_encoder.trunk.blocks.36.norm2.bias', 'sam_mask_decoder.transformer.layers.0.norm4.weight', 'image_encoder.trunk.blocks.40.norm2.bias', 'memory_attention.layers.0.norm1.bias', 'image_encoder.trunk.blocks.32.norm2.bias', 'image_encoder.trunk.blocks.38.norm1.weight', 'image_encoder.trunk.blocks.45.norm1.weight', 'image_encoder.trunk.blocks.17.norm1.weight', 'image_encoder.trunk.blocks.20.norm2.bias', 'sam_mask_decoder.transformer.layers.1.norm3.weight', 'image_encoder.trunk.blocks.9.norm1.bias', 'sam_mask_decoder.transformer.layers.1.norm4.weight', 'image_encoder.trunk.blocks.16.norm2.weight', 'memory_attention.layers.0.norm2.weight', 'image_encoder.trunk.blocks.7.norm2.bias', 'image_encoder.trunk.blocks.1.norm2.weight', 'image_encoder.trunk.blocks.21.norm2.bias', 'image_encoder.trunk.blocks.27.norm2.weight', 'image_encoder.trunk.blocks.12.norm2.weight', 'image_encoder.trunk.blocks.22.norm2.weight', 'image_encoder.trunk.blocks.34.norm1.bias', 'image_encoder.trunk.blocks.42.norm1.weight', 'image_encoder.trunk.blocks.14.norm2.weight', 'memory_attention.layers.3.norm3.bias', 'image_encoder.trunk.blocks.3.norm2.bias', 'sam_mask_decoder.transformer.layers.0.norm1.bias', 'image_encoder.trunk.blocks.25.norm1.weight', 'memory_attention.layers.3.norm1.bias', 'image_encoder.trunk.blocks.43.norm2.weight', 'image_encoder.trunk.blocks.14.norm1.weight', 'sam_mask_decoder.transformer.layers.0.norm2.bias', 'image_encoder.trunk.blocks.5.norm1.weight', 'image_encoder.trunk.blocks.28.norm1.bias', 'image_encoder.trunk.blocks.46.norm2.weight', 'image_encoder.trunk.blocks.24.norm2.bias', 'image_encoder.trunk.blocks.9.norm1.weight', 'image_encoder.trunk.blocks.0.norm1.bias', 'sam_mask_decoder.transformer.layers.1.norm1.weight', 'image_encoder.trunk.blocks.29.norm1.weight', 'image_encoder.trunk.blocks.16.norm2.bias', 'sam_mask_decoder.transformer.layers.1.norm4.bias', 'image_encoder.trunk.blocks.0.norm2.bias', 'image_encoder.trunk.blocks.29.norm2.bias', 'image_encoder.trunk.blocks.25.norm1.bias', 'memory_attention.layers.2.norm2.weight', 'image_encoder.trunk.blocks.19.norm2.bias', 'memory_attention.layers.0.norm3.bias', 'image_encoder.trunk.blocks.25.norm2.weight', 'memory_attention.layers.3.norm1.weight', 'image_encoder.trunk.blocks.3.norm1.bias', 'sam_mask_decoder.transformer.layers.1.norm2.bias', 'image_encoder.trunk.blocks.11.norm1.weight', 'image_encoder.trunk.blocks.13.norm1.weight', 'image_encoder.trunk.blocks.30.norm1.weight', 'image_encoder.trunk.blocks.18.norm1.bias', 'image_encoder.trunk.blocks.36.norm2.weight', 'image_encoder.trunk.blocks.46.norm2.bias', 'memory_attention.layers.1.norm2.weight', 'image_encoder.trunk.blocks.1.norm1.weight'} 
INFO 2025-12-09 22:15:57,574 sam2_datasets.py: 125: Dataset mixing probabilities: [1.0]
INFO 2025-12-09 22:15:58,279 trainer.py: 417: Loading pretrained checkpoint from {'_partial_': True, '_target_': 'training.utils.checkpoint_utils.load_state_dict_into_model', 'strict': False, 'ignore_unexpected_keys': None, 'ignore_missing_keys': ['ME*', 'routefuse*'], 'state_dict': {'_target_': 'training.utils.checkpoint_utils.load_checkpoint_and_apply_kernels', 'checkpoint_path': 'checkpoints/sam2.1_hiera_large.pt', 'ckpt_state_dict_keys': ['model']}}
INFO 2025-12-09 22:16:17,975 train_utils.py: 271: Train Epoch: [0][ 0/45] | Batch Time: 19.33 (19.33) | Data Time: 8.69 (8.69) | Mem (GB): 33.00 (33.00/33.00) | Time Elapsed: 00d 00h 00m | Losses/train_all_loss: 1.10e+00 (1.10e+00)
INFO 2025-12-09 22:18:14,391 train_utils.py: 271: Train Epoch: [0][10/45] | Batch Time: 13.91 (12.34) | Data Time: 0.00 (0.79) | Mem (GB): 45.00 (30.82/45.00) | Time Elapsed: 00d 00h 02m | Losses/train_all_loss: 3.72e+00 (2.17e+00)
INFO 2025-12-09 22:19:00,191 train_utils.py: 108: MACHINE SEED: 6150
INFO 2025-12-09 22:19:00,192 train_utils.py: 154: Logging ENV_VARIABLES
INFO 2025-12-09 22:19:00,192 train_utils.py: 155: AgentHost=10.17.176.67
AutoDLContainerMonitorSetting=
AutoDLContainerUUID=c6d54aa471-2ea91646
AutoDLDataCenter=neimengDC2
AutoDLRegion=nm-A1
AutoDLService6006URL=https://u829339-a471-2ea91646.nma1.seetacloud.com:8448
AutoDLService6008URL=https://uu829339-a471-2ea91646.nma1.seetacloud.com:8448
AutoDLServiceURL=https://u829339-a471-2ea91646.nma1.seetacloud.com:8448
AutodlAutoPanelToken=jupyter-autodl-container-c69945a881-892d9774-6ddd30cef03e642fcbb23db5203d964cbcb4bbac56da548f7ba86e0aef3fc6423
BROWSER=/root/.vscode-server/cli/servers/Stable-bf9252a2fb45be6893dd8870c0bf37e2e1766d61/server/bin/helpers/browser.sh
COLORTERM=truecolor
CONDA_DEFAULT_ENV=ttt_sam
CONDA_EXE=/root/miniconda3/bin/conda
CONDA_PREFIX=/root/miniconda3/envs/ttt_sam
CONDA_PREFIX_1=/root/miniconda3
CONDA_PREFIX_2=/root/miniconda3/envs/sam3
CONDA_PROMPT_MODIFIER=(ttt_sam) 
CONDA_PYTHON_EXE=/root/miniconda3/bin/python
CONDA_SHLVL=3
CUDA_MODULE_LOADING=LAZY
GIT_ASKPASS=/root/.vscode-server/cli/servers/Stable-bf9252a2fb45be6893dd8870c0bf37e2e1766d61/server/extensions/git/dist/askpass.sh
HOME=/root
HYDRA_FULL_ERROR=1
LANG=C.UTF-8
LOCAL_RANK=0
LOGNAME=root
LS_COLORS=rs=0:di=01;34:ln=01;36:mh=00:pi=40;33:so=01;35:do=01;35:bd=40;33;01:cd=40;33;01:or=40;31;01:mi=00:su=37;41:sg=30;43:ca=30;41:tw=30;42:ow=34;42:st=37;44:ex=01;32:*.tar=01;31:*.tgz=01;31:*.arc=01;31:*.arj=01;31:*.taz=01;31:*.lha=01;31:*.lz4=01;31:*.lzh=01;31:*.lzma=01;31:*.tlz=01;31:*.txz=01;31:*.tzo=01;31:*.t7z=01;31:*.zip=01;31:*.z=01;31:*.dz=01;31:*.gz=01;31:*.lrz=01;31:*.lz=01;31:*.lzo=01;31:*.xz=01;31:*.zst=01;31:*.tzst=01;31:*.bz2=01;31:*.bz=01;31:*.tbz=01;31:*.tbz2=01;31:*.tz=01;31:*.deb=01;31:*.rpm=01;31:*.jar=01;31:*.war=01;31:*.ear=01;31:*.sar=01;31:*.rar=01;31:*.alz=01;31:*.ace=01;31:*.zoo=01;31:*.cpio=01;31:*.7z=01;31:*.rz=01;31:*.cab=01;31:*.wim=01;31:*.swm=01;31:*.dwm=01;31:*.esd=01;31:*.jpg=01;35:*.jpeg=01;35:*.mjpg=01;35:*.mjpeg=01;35:*.gif=01;35:*.bmp=01;35:*.pbm=01;35:*.pgm=01;35:*.ppm=01;35:*.tga=01;35:*.xbm=01;35:*.xpm=01;35:*.tif=01;35:*.tiff=01;35:*.png=01;35:*.svg=01;35:*.svgz=01;35:*.mng=01;35:*.pcx=01;35:*.mov=01;35:*.mpg=01;35:*.mpeg=01;35:*.m2v=01;35:*.mkv=01;35:*.webm=01;35:*.webp=01;35:*.ogm=01;35:*.mp4=01;35:*.m4v=01;35:*.mp4v=01;35:*.vob=01;35:*.qt=01;35:*.nuv=01;35:*.wmv=01;35:*.asf=01;35:*.rm=01;35:*.rmvb=01;35:*.flc=01;35:*.avi=01;35:*.fli=01;35:*.flv=01;35:*.gl=01;35:*.dl=01;35:*.xcf=01;35:*.xwd=01;35:*.yuv=01;35:*.cgm=01;35:*.emf=01;35:*.ogv=01;35:*.ogx=01;35:*.aac=00;36:*.au=00;36:*.flac=00;36:*.m4a=00;36:*.mid=00;36:*.midi=00;36:*.mka=00;36:*.mp3=00;36:*.mpc=00;36:*.ogg=00;36:*.ra=00;36:*.wav=00;36:*.oga=00;36:*.opus=00;36:*.spx=00;36:*.xspf=00;36:
MASTER_ADDR=localhost
MASTER_PORT=11592
MKL_NUM_THREADS=14
MOTD_SHOWN=pam
OLDPWD=/root/autodl-tmp
OMP_NUM_THREADS=14
PATH=/root/miniconda3/envs/ttt_sam/bin:/usr/local/bin:/root/.vscode-server/data/User/globalStorage/github.copilot-chat/debugCommand:/root/.vscode-server/data/User/globalStorage/github.copilot-chat/copilotCli:/root/.vscode-server/cli/servers/Stable-bf9252a2fb45be6893dd8870c0bf37e2e1766d61/server/bin/remote-cli:/root/miniconda3/bin:/root/miniconda3/condabin:/root/miniconda3/bin:/usr/local/bin:/root/miniconda3/bin:/usr/local/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin
PWD=/root/autodl-tmp/ttt_rr
PYTHONPATH=:/root/autodl-tmp/ttt_rr
RANK=0
REQUESTS_CA_BUNDLE=/etc/ssl/certs/ca-certificates.crt
SHELL=/bin/bash
SHLVL=1
SSH_CLIENT=127.0.0.1 39646 22
SSH_CONNECTION=127.0.0.1 39646 127.0.0.1 22
SSL_CERT_DIR=/usr/lib/ssl/certs
SSL_CERT_FILE=/usr/lib/ssl/certs/ca-certificates.crt
TERM=xterm-256color
TERM_PROGRAM=vscode
TERM_PROGRAM_VERSION=1.106.3
TORCH_NCCL_ASYNC_ERROR_HANDLING=1
TZ=Asia/Shanghai
USER=root
VSCODE_GIT_ASKPASS_EXTRA_ARGS=
VSCODE_GIT_ASKPASS_MAIN=/root/.vscode-server/cli/servers/Stable-bf9252a2fb45be6893dd8870c0bf37e2e1766d61/server/extensions/git/dist/askpass-main.js
VSCODE_GIT_ASKPASS_NODE=/root/.vscode-server/cli/servers/Stable-bf9252a2fb45be6893dd8870c0bf37e2e1766d61/server/node
VSCODE_GIT_IPC_HANDLE=/tmp/vscode-git-1853e26595.sock
VSCODE_IPC_HOOK_CLI=/tmp/vscode-ipc-1bcb9607-959c-45d3-98fd-c60247c03c91.sock
VSCODE_PYTHON_AUTOACTIVATE_GUARD=1
WORLD_SIZE=1
_=/root/miniconda3/envs/ttt_sam/bin/python
_CE_CONDA=
_CE_M=

INFO 2025-12-09 22:19:00,193 trainer.py: 989: Setting up components: Model, loss, optim, meters etc.
INFO 2025-12-09 22:19:00,193 logger.py:  66: TensorBoard SummaryWriter instantiated. Files will be stored in: ./logs/sam_ttt_davis_run2/tensorboard
INFO 2025-12-09 22:19:01,695 sam2.py:  81: Training with points (sampled from masks) as inputs with p=0.5
INFO 2025-12-09 22:19:01,701 trainer.py:1059: ====================
INFO 2025-12-09 22:19:01,701 trainer.py:1060: Summary for model <class 'training.model.sam2.SAM2Train'>
INFO 2025-12-09 22:19:01,704 trainer.py:1061: Model is SAM2Train(
  (image_encoder): ImageEncoder(
    (trunk): Hiera(
      (patch_embed): PatchEmbed(
        (proj): Conv2d(3, 144, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))
      )
      (blocks): ModuleList(
        (0-1): 2 x MultiScaleBlock(
          (norm1): LayerNorm((144,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=144, out_features=432, bias=True)
            (proj): Linear(in_features=144, out_features=144, bias=True)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((144,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=144, out_features=576, bias=True)
              (1): Linear(in_features=576, out_features=144, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
        (2): MultiScaleBlock(
          (norm1): LayerNorm((144,), eps=1e-06, elementwise_affine=True)
          (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
          (attn): MultiScaleAttention(
            (q_pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
            (qkv): Linear(in_features=144, out_features=864, bias=True)
            (proj): Linear(in_features=288, out_features=288, bias=True)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((288,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=288, out_features=1152, bias=True)
              (1): Linear(in_features=1152, out_features=288, bias=True)
            )
            (act): GELU(approximate='none')
          )
          (proj): Linear(in_features=144, out_features=288, bias=True)
        )
        (3-7): 5 x MultiScaleBlock(
          (norm1): LayerNorm((288,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=288, out_features=864, bias=True)
            (proj): Linear(in_features=288, out_features=288, bias=True)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((288,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=288, out_features=1152, bias=True)
              (1): Linear(in_features=1152, out_features=288, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
        (8): MultiScaleBlock(
          (norm1): LayerNorm((288,), eps=1e-06, elementwise_affine=True)
          (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
          (attn): MultiScaleAttention(
            (q_pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
            (qkv): Linear(in_features=288, out_features=1728, bias=True)
            (proj): Linear(in_features=576, out_features=576, bias=True)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((576,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=576, out_features=2304, bias=True)
              (1): Linear(in_features=2304, out_features=576, bias=True)
            )
            (act): GELU(approximate='none')
          )
          (proj): Linear(in_features=288, out_features=576, bias=True)
        )
        (9-43): 35 x MultiScaleBlock(
          (norm1): LayerNorm((576,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=576, out_features=1728, bias=True)
            (proj): Linear(in_features=576, out_features=576, bias=True)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((576,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=576, out_features=2304, bias=True)
              (1): Linear(in_features=2304, out_features=576, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
        (44): MultiScaleBlock(
          (norm1): LayerNorm((576,), eps=1e-06, elementwise_affine=True)
          (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
          (attn): MultiScaleAttention(
            (q_pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
            (qkv): Linear(in_features=576, out_features=3456, bias=True)
            (proj): Linear(in_features=1152, out_features=1152, bias=True)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=1152, out_features=4608, bias=True)
              (1): Linear(in_features=4608, out_features=1152, bias=True)
            )
            (act): GELU(approximate='none')
          )
          (proj): Linear(in_features=576, out_features=1152, bias=True)
        )
        (45-47): 3 x MultiScaleBlock(
          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
          (attn): MultiScaleAttention(
            (qkv): Linear(in_features=1152, out_features=3456, bias=True)
            (proj): Linear(in_features=1152, out_features=1152, bias=True)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=1152, out_features=4608, bias=True)
              (1): Linear(in_features=4608, out_features=1152, bias=True)
            )
            (act): GELU(approximate='none')
          )
        )
      )
    )
    (neck): FpnNeck(
      (position_encoding): PositionEmbeddingSine()
      (convs): ModuleList(
        (0): Sequential(
          (conv): Conv2d(1152, 256, kernel_size=(1, 1), stride=(1, 1))
        )
        (1): Sequential(
          (conv): Conv2d(576, 256, kernel_size=(1, 1), stride=(1, 1))
        )
        (2): Sequential(
          (conv): Conv2d(288, 256, kernel_size=(1, 1), stride=(1, 1))
        )
        (3): Sequential(
          (conv): Conv2d(144, 256, kernel_size=(1, 1), stride=(1, 1))
        )
      )
    )
  )
  (mask_downsample): Conv2d(1, 1, kernel_size=(4, 4), stride=(4, 4))
  (memory_attention): MemoryAttention(
    (layers): ModuleList(
      (0-3): 4 x MemoryAttentionLayer(
        (self_attn): RoPEAttention(
          (q_proj): Linear(in_features=256, out_features=256, bias=True)
          (k_proj): Linear(in_features=256, out_features=256, bias=True)
          (v_proj): Linear(in_features=256, out_features=256, bias=True)
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
        )
        (cross_attn_image): RoPEAttention(
          (q_proj): Linear(in_features=256, out_features=256, bias=True)
          (k_proj): Linear(in_features=64, out_features=256, bias=True)
          (v_proj): Linear(in_features=64, out_features=256, bias=True)
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
        )
        (linear1): Linear(in_features=256, out_features=2048, bias=True)
        (dropout): Dropout(p=0.1, inplace=False)
        (linear2): Linear(in_features=2048, out_features=256, bias=True)
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.1, inplace=False)
        (dropout3): Dropout(p=0.1, inplace=False)
      )
    )
    (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
  )
  (memory_encoder): MemoryEncoder(
    (mask_downsampler): MaskDownSampler(
      (encoder): Sequential(
        (0): Conv2d(1, 4, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (1): LayerNorm2d()
        (2): GELU(approximate='none')
        (3): Conv2d(4, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (4): LayerNorm2d()
        (5): GELU(approximate='none')
        (6): Conv2d(16, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (7): LayerNorm2d()
        (8): GELU(approximate='none')
        (9): Conv2d(64, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (10): LayerNorm2d()
        (11): GELU(approximate='none')
        (12): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (pix_feat_proj): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fuser): Fuser(
      (proj): Identity()
      (layers): ModuleList(
        (0-1): 2 x CXBlock(
          (dwconv): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)
          (norm): LayerNorm2d()
          (pwconv1): Linear(in_features=256, out_features=1024, bias=True)
          (act): GELU(approximate='none')
          (pwconv2): Linear(in_features=1024, out_features=256, bias=True)
          (drop_path): Identity()
        )
      )
    )
    (position_encoding): PositionEmbeddingSine()
    (out_proj): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
  )
  (sam_prompt_encoder): PromptEncoder(
    (pe_layer): PositionEmbeddingRandom()
    (point_embeddings): ModuleList(
      (0-3): 4 x Embedding(1, 256)
    )
    (not_a_point_embed): Embedding(1, 256)
    (mask_downscaling): Sequential(
      (0): Conv2d(1, 4, kernel_size=(2, 2), stride=(2, 2))
      (1): LayerNorm2d()
      (2): GELU(approximate='none')
      (3): Conv2d(4, 16, kernel_size=(2, 2), stride=(2, 2))
      (4): LayerNorm2d()
      (5): GELU(approximate='none')
      (6): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))
    )
    (no_mask_embed): Embedding(1, 256)
  )
  (sam_mask_decoder): MaskDecoder(
    (transformer): TwoWayTransformer(
      (layers): ModuleList(
        (0-1): 2 x TwoWayAttentionBlock(
          (self_attn): Attention(
            (q_proj): Linear(in_features=256, out_features=256, bias=True)
            (k_proj): Linear(in_features=256, out_features=256, bias=True)
            (v_proj): Linear(in_features=256, out_features=256, bias=True)
            (out_proj): Linear(in_features=256, out_features=256, bias=True)
          )
          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (cross_attn_token_to_image): Attention(
            (q_proj): Linear(in_features=256, out_features=128, bias=True)
            (k_proj): Linear(in_features=256, out_features=128, bias=True)
            (v_proj): Linear(in_features=256, out_features=128, bias=True)
            (out_proj): Linear(in_features=128, out_features=256, bias=True)
          )
          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (mlp): MLP(
            (layers): ModuleList(
              (0): Linear(in_features=256, out_features=2048, bias=True)
              (1): Linear(in_features=2048, out_features=256, bias=True)
            )
            (act): ReLU()
          )
          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (norm4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (cross_attn_image_to_token): Attention(
            (q_proj): Linear(in_features=256, out_features=128, bias=True)
            (k_proj): Linear(in_features=256, out_features=128, bias=True)
            (v_proj): Linear(in_features=256, out_features=128, bias=True)
            (out_proj): Linear(in_features=128, out_features=256, bias=True)
          )
        )
      )
      (final_attn_token_to_image): Attention(
        (q_proj): Linear(in_features=256, out_features=128, bias=True)
        (k_proj): Linear(in_features=256, out_features=128, bias=True)
        (v_proj): Linear(in_features=256, out_features=128, bias=True)
        (out_proj): Linear(in_features=128, out_features=256, bias=True)
      )
      (norm_final_attn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
    (iou_token): Embedding(1, 256)
    (mask_tokens): Embedding(4, 256)
    (obj_score_token): Embedding(1, 256)
    (output_upscaling): Sequential(
      (0): ConvTranspose2d(256, 64, kernel_size=(2, 2), stride=(2, 2))
      (1): LayerNorm2d()
      (2): GELU(approximate='none')
      (3): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2))
      (4): GELU(approximate='none')
    )
    (conv_s0): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
    (conv_s1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
    (output_hypernetworks_mlps): ModuleList(
      (0-3): 4 x MLP(
        (layers): ModuleList(
          (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=32, bias=True)
        )
        (act): ReLU()
      )
    )
    (iou_prediction_head): MLP(
      (layers): ModuleList(
        (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=4, bias=True)
      )
      (act): ReLU()
    )
    (pred_obj_score_head): MLP(
      (layers): ModuleList(
        (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=1, bias=True)
      )
      (act): ReLU()
    )
  )
  (obj_ptr_proj): MLP(
    (layers): ModuleList(
      (0-2): 3 x Linear(in_features=256, out_features=256, bias=True)
    )
    (act): ReLU()
  )
  (obj_ptr_tpos_proj): Linear(in_features=256, out_features=64, bias=True)
  (DWT): extract_high_frequency(
    (dwt): DWT()
  )
  (ME): ME(
    (depthwise_conv_reduce_channels_in): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), groups=32)
    (depthwise_conv_reduce_channels_out1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), groups=32)
    (depthwise_conv_reduce_channels_out2): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), groups=32)
    (relu): ReLU(inplace=True)
    (branch1): Sequential(
      (0): BasicConv2d(
        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): GroupNorm(32, 256, eps=1e-05, affine=True)
        (relu): ReLU()
      )
      (1): BasicConv2d(
        (conv): Conv2d(256, 256, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)
        (bn): GroupNorm(32, 256, eps=1e-05, affine=True)
        (relu): ReLU()
      )
      (2): BasicConv2d(
        (conv): Conv2d(256, 256, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)
        (bn): GroupNorm(32, 256, eps=1e-05, affine=True)
        (relu): ReLU()
      )
      (3): BasicConv2d(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(3, 3), dilation=(3, 3), bias=False)
        (bn): GroupNorm(32, 256, eps=1e-05, affine=True)
        (relu): ReLU()
      )
    )
    (seq_modeling_block): TTTLinear(
      (q_proj): Linear(in_features=256, out_features=256, bias=False)
      (v_proj): Linear(in_features=256, out_features=256, bias=False)
      (o_proj): Linear(in_features=256, out_features=256, bias=False)
      (conv_q): Conv1d(256, 256, kernel_size=(4,), stride=(1,), padding=(3,), groups=256)
      (conv_k): Conv1d(256, 256, kernel_size=(4,), stride=(1,), padding=(3,), groups=256)
      (rotary_emb): RotaryEmbedding()
      (post_norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)
    )
    (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (embed_tokens): Embedding(256, 256)
  )
  (routefuse): routefuse(
    (conv_dense): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))
  )
)
INFO 2025-12-09 22:19:01,704 trainer.py:1062: 	Total parameters 226 M
INFO 2025-12-09 22:19:01,704 trainer.py:1063: 	Trainable parameters 13.7 M
INFO 2025-12-09 22:19:01,704 trainer.py:1066: 	Non-Trainable parameters 212 M
INFO 2025-12-09 22:19:01,704 trainer.py:1069: ====================
INFO 2025-12-09 22:19:01,707 trainer.py:1023: Finished setting up components: Model, loss, optim, meters etc.
INFO 2025-12-09 22:19:01,707 trainer.py: 314: Moving components to device cuda:0 and local rank 0.
INFO 2025-12-09 22:19:01,869 trainer.py: 320: Done moving components to device cuda:0 and local rank 0.
INFO 2025-12-09 22:19:01,883 optimizer.py: 248: Matches for param_name [image_encoder.*]: {'image_encoder.trunk.blocks.37.norm2.weight', 'image_encoder.trunk.blocks.34.norm1.weight', 'image_encoder.trunk.blocks.23.mlp.layers.0.weight', 'image_encoder.trunk.blocks.47.mlp.layers.0.weight', 'image_encoder.trunk.blocks.42.norm2.bias', 'image_encoder.trunk.blocks.46.norm1.weight', 'image_encoder.trunk.blocks.27.mlp.layers.1.bias', 'image_encoder.trunk.blocks.6.mlp.layers.1.weight', 'image_encoder.trunk.blocks.28.norm1.bias', 'image_encoder.trunk.blocks.18.mlp.layers.0.bias', 'image_encoder.trunk.blocks.21.attn.qkv.bias', 'image_encoder.trunk.blocks.5.attn.proj.bias', 'image_encoder.trunk.blocks.3.mlp.layers.0.bias', 'image_encoder.trunk.blocks.7.norm1.bias', 'image_encoder.trunk.blocks.39.attn.proj.bias', 'image_encoder.trunk.blocks.4.mlp.layers.1.bias', 'image_encoder.trunk.blocks.21.mlp.layers.1.bias', 'image_encoder.trunk.blocks.7.norm1.weight', 'image_encoder.trunk.blocks.16.attn.qkv.weight', 'image_encoder.trunk.blocks.6.norm1.bias', 'image_encoder.trunk.blocks.33.mlp.layers.1.weight', 'image_encoder.trunk.blocks.41.mlp.layers.1.bias', 'image_encoder.trunk.blocks.20.norm1.bias', 'image_encoder.trunk.blocks.24.attn.proj.weight', 'image_encoder.trunk.blocks.38.mlp.layers.1.weight', 'image_encoder.trunk.blocks.43.mlp.layers.1.bias', 'image_encoder.trunk.blocks.47.attn.proj.bias', 'image_encoder.trunk.blocks.47.attn.qkv.weight', 'image_encoder.trunk.blocks.38.mlp.layers.0.weight', 'image_encoder.trunk.blocks.25.attn.qkv.bias', 'image_encoder.trunk.blocks.30.attn.qkv.weight', 'image_encoder.trunk.blocks.43.norm1.weight', 'image_encoder.trunk.blocks.32.norm2.bias', 'image_encoder.trunk.blocks.36.mlp.layers.1.weight', 'image_encoder.trunk.blocks.19.norm2.weight', 'image_encoder.trunk.blocks.11.mlp.layers.1.weight', 'image_encoder.trunk.blocks.16.attn.qkv.bias', 'image_encoder.trunk.blocks.47.norm2.bias', 'image_encoder.trunk.blocks.46.attn.proj.bias', 'image_encoder.trunk.blocks.19.norm1.weight', 'image_encoder.trunk.blocks.28.mlp.layers.1.weight', 'image_encoder.trunk.blocks.17.attn.qkv.weight', 'image_encoder.trunk.blocks.44.mlp.layers.0.weight', 'image_encoder.trunk.blocks.26.mlp.layers.0.weight', 'image_encoder.trunk.blocks.37.attn.qkv.bias', 'image_encoder.trunk.blocks.38.norm2.weight', 'image_encoder.trunk.blocks.1.mlp.layers.1.weight', 'image_encoder.trunk.blocks.2.proj.bias', 'image_encoder.trunk.blocks.30.mlp.layers.1.weight', 'image_encoder.trunk.blocks.32.mlp.layers.0.bias', 'image_encoder.trunk.blocks.35.attn.qkv.bias', 'image_encoder.trunk.blocks.24.mlp.layers.0.bias', 'image_encoder.trunk.blocks.13.attn.qkv.weight', 'image_encoder.trunk.blocks.24.norm2.weight', 'image_encoder.trunk.blocks.5.attn.qkv.bias', 'image_encoder.trunk.blocks.20.attn.proj.weight', 'image_encoder.trunk.blocks.33.mlp.layers.0.weight', 'image_encoder.trunk.blocks.44.attn.proj.bias', 'image_encoder.trunk.blocks.8.attn.qkv.weight', 'image_encoder.trunk.blocks.45.attn.qkv.weight', 'image_encoder.trunk.blocks.39.mlp.layers.1.weight', 'image_encoder.neck.convs.0.conv.weight', 'image_encoder.trunk.blocks.7.mlp.layers.1.bias', 'image_encoder.trunk.blocks.17.attn.proj.weight', 'image_encoder.trunk.blocks.5.norm2.bias', 'image_encoder.trunk.blocks.47.mlp.layers.0.bias', 'image_encoder.trunk.blocks.30.attn.qkv.bias', 'image_encoder.trunk.blocks.29.attn.qkv.bias', 'image_encoder.trunk.blocks.28.mlp.layers.0.bias', 'image_encoder.trunk.blocks.34.norm1.bias', 'image_encoder.trunk.blocks.3.norm1.bias', 'image_encoder.trunk.blocks.33.norm1.bias', 'image_encoder.trunk.blocks.20.mlp.layers.0.weight', 'image_encoder.trunk.blocks.22.attn.qkv.bias', 'image_encoder.trunk.blocks.16.mlp.layers.1.weight', 'image_encoder.trunk.blocks.22.attn.proj.weight', 'image_encoder.trunk.blocks.39.attn.proj.weight', 'image_encoder.trunk.blocks.30.norm1.weight', 'image_encoder.trunk.blocks.18.mlp.layers.0.weight', 'image_encoder.trunk.blocks.12.norm1.bias', 'image_encoder.trunk.blocks.29.mlp.layers.1.bias', 'image_encoder.trunk.blocks.20.mlp.layers.0.bias', 'image_encoder.trunk.blocks.42.attn.proj.bias', 'image_encoder.trunk.blocks.28.mlp.layers.0.weight', 'image_encoder.trunk.blocks.44.norm2.weight', 'image_encoder.trunk.blocks.3.norm1.weight', 'image_encoder.trunk.blocks.16.attn.proj.bias', 'image_encoder.trunk.blocks.33.attn.qkv.weight', 'image_encoder.trunk.blocks.26.norm2.weight', 'image_encoder.trunk.blocks.25.attn.qkv.weight', 'image_encoder.trunk.blocks.18.attn.proj.weight', 'image_encoder.trunk.blocks.24.mlp.layers.1.bias', 'image_encoder.trunk.blocks.22.attn.proj.bias', 'image_encoder.trunk.blocks.22.norm1.bias', 'image_encoder.trunk.blocks.26.attn.proj.weight', 'image_encoder.trunk.blocks.32.attn.proj.weight', 'image_encoder.trunk.blocks.46.mlp.layers.0.weight', 'image_encoder.trunk.blocks.38.attn.qkv.bias', 'image_encoder.trunk.blocks.7.norm2.weight', 'image_encoder.trunk.blocks.2.mlp.layers.0.weight', 'image_encoder.trunk.blocks.33.attn.proj.bias', 'image_encoder.trunk.blocks.45.mlp.layers.0.bias', 'image_encoder.trunk.blocks.7.mlp.layers.0.bias', 'image_encoder.trunk.blocks.11.attn.proj.weight', 'image_encoder.trunk.blocks.47.mlp.layers.1.bias', 'image_encoder.trunk.blocks.2.norm1.weight', 'image_encoder.trunk.blocks.44.norm1.bias', 'image_encoder.trunk.blocks.4.mlp.layers.1.weight', 'image_encoder.trunk.blocks.1.attn.qkv.bias', 'image_encoder.trunk.blocks.24.mlp.layers.0.weight', 'image_encoder.trunk.blocks.31.mlp.layers.1.weight', 'image_encoder.trunk.blocks.43.attn.qkv.bias', 'image_encoder.trunk.blocks.43.norm2.weight', 'image_encoder.trunk.blocks.45.norm2.bias', 'image_encoder.trunk.blocks.23.attn.proj.weight', 'image_encoder.trunk.blocks.35.mlp.layers.1.bias', 'image_encoder.trunk.blocks.3.norm2.bias', 'image_encoder.trunk.blocks.47.norm2.weight', 'image_encoder.trunk.blocks.39.norm2.bias', 'image_encoder.trunk.blocks.6.norm1.weight', 'image_encoder.trunk.blocks.37.attn.qkv.weight', 'image_encoder.trunk.blocks.45.norm2.weight', 'image_encoder.trunk.blocks.0.mlp.layers.0.bias', 'image_encoder.trunk.blocks.1.mlp.layers.0.weight', 'image_encoder.trunk.blocks.9.norm2.weight', 'image_encoder.trunk.blocks.11.mlp.layers.1.bias', 'image_encoder.trunk.blocks.29.norm1.bias', 'image_encoder.trunk.blocks.6.attn.qkv.bias', 'image_encoder.trunk.blocks.11.norm1.weight', 'image_encoder.trunk.blocks.41.attn.qkv.bias', 'image_encoder.trunk.blocks.9.norm2.bias', 'image_encoder.trunk.blocks.41.attn.proj.weight', 'image_encoder.trunk.blocks.25.mlp.layers.0.bias', 'image_encoder.trunk.blocks.34.mlp.layers.0.weight', 'image_encoder.trunk.blocks.2.attn.qkv.weight', 'image_encoder.trunk.blocks.9.attn.qkv.weight', 'image_encoder.trunk.blocks.15.mlp.layers.1.bias', 'image_encoder.neck.convs.3.conv.weight', 'image_encoder.trunk.blocks.27.norm2.weight', 'image_encoder.trunk.blocks.45.norm1.bias', 'image_encoder.trunk.blocks.45.attn.proj.bias', 'image_encoder.trunk.blocks.37.mlp.layers.0.bias', 'image_encoder.trunk.blocks.3.attn.proj.weight', 'image_encoder.trunk.blocks.5.mlp.layers.0.bias', 'image_encoder.trunk.blocks.8.norm2.weight', 'image_encoder.trunk.blocks.7.attn.qkv.weight', 'image_encoder.trunk.blocks.39.attn.qkv.weight', 'image_encoder.trunk.blocks.21.norm2.bias', 'image_encoder.trunk.blocks.25.norm2.weight', 'image_encoder.trunk.blocks.23.attn.qkv.weight', 'image_encoder.trunk.blocks.12.attn.qkv.bias', 'image_encoder.trunk.blocks.15.norm2.bias', 'image_encoder.trunk.blocks.25.norm1.bias', 'image_encoder.trunk.blocks.5.mlp.layers.1.bias', 'image_encoder.trunk.blocks.39.norm2.weight', 'image_encoder.trunk.blocks.11.norm2.weight', 'image_encoder.trunk.blocks.12.norm1.weight', 'image_encoder.trunk.blocks.13.mlp.layers.0.weight', 'image_encoder.trunk.blocks.14.norm2.bias', 'image_encoder.trunk.blocks.21.norm1.bias', 'image_encoder.trunk.blocks.26.mlp.layers.1.bias', 'image_encoder.trunk.blocks.0.attn.proj.bias', 'image_encoder.trunk.blocks.26.attn.qkv.weight', 'image_encoder.trunk.blocks.30.attn.proj.bias', 'image_encoder.trunk.blocks.28.norm2.bias', 'image_encoder.trunk.blocks.27.mlp.layers.1.weight', 'image_encoder.trunk.blocks.32.norm1.bias', 'image_encoder.trunk.blocks.29.norm2.weight', 'image_encoder.trunk.blocks.35.mlp.layers.0.bias', 'image_encoder.trunk.blocks.44.mlp.layers.0.bias', 'image_encoder.trunk.blocks.27.norm2.bias', 'image_encoder.trunk.blocks.17.norm2.bias', 'image_encoder.trunk.blocks.47.norm1.bias', 'image_encoder.trunk.blocks.26.mlp.layers.0.bias', 'image_encoder.trunk.blocks.6.norm2.bias', 'image_encoder.trunk.blocks.2.proj.weight', 'image_encoder.trunk.blocks.13.mlp.layers.1.weight', 'image_encoder.trunk.blocks.1.norm1.weight', 'image_encoder.trunk.blocks.31.norm2.bias', 'image_encoder.trunk.blocks.43.norm2.bias', 'image_encoder.trunk.blocks.37.mlp.layers.1.weight', 'image_encoder.trunk.blocks.6.mlp.layers.1.bias', 'image_encoder.trunk.blocks.2.attn.proj.weight', 'image_encoder.trunk.blocks.29.norm2.bias', 'image_encoder.trunk.blocks.29.mlp.layers.1.weight', 'image_encoder.trunk.blocks.36.norm2.bias', 'image_encoder.trunk.blocks.38.norm1.bias', 'image_encoder.trunk.blocks.31.norm2.weight', 'image_encoder.trunk.blocks.27.mlp.layers.0.bias', 'image_encoder.trunk.blocks.16.mlp.layers.0.weight', 'image_encoder.trunk.blocks.8.proj.weight', 'image_encoder.trunk.blocks.13.attn.proj.weight', 'image_encoder.trunk.blocks.3.mlp.layers.1.weight', 'image_encoder.trunk.blocks.37.mlp.layers.1.bias', 'image_encoder.trunk.blocks.11.mlp.layers.0.weight', 'image_encoder.trunk.blocks.17.norm1.weight', 'image_encoder.trunk.blocks.5.attn.proj.weight', 'image_encoder.trunk.blocks.46.mlp.layers.1.weight', 'image_encoder.trunk.blocks.28.attn.qkv.weight', 'image_encoder.trunk.blocks.0.mlp.layers.0.weight', 'image_encoder.trunk.blocks.22.mlp.layers.0.weight', 'image_encoder.trunk.blocks.6.attn.proj.bias', 'image_encoder.trunk.blocks.29.attn.proj.bias', 'image_encoder.trunk.blocks.40.norm2.bias', 'image_encoder.trunk.blocks.31.norm1.weight', 'image_encoder.trunk.blocks.32.mlp.layers.0.weight', 'image_encoder.trunk.blocks.15.attn.qkv.weight', 'image_encoder.trunk.blocks.35.norm1.weight', 'image_encoder.trunk.blocks.32.attn.qkv.weight', 'image_encoder.trunk.blocks.27.attn.proj.weight', 'image_encoder.trunk.blocks.35.mlp.layers.0.weight', 'image_encoder.trunk.blocks.20.mlp.layers.1.bias', 'image_encoder.trunk.blocks.24.norm1.bias', 'image_encoder.trunk.blocks.19.attn.proj.weight', 'image_encoder.trunk.blocks.10.attn.proj.weight', 'image_encoder.trunk.blocks.24.mlp.layers.1.weight', 'image_encoder.trunk.blocks.35.mlp.layers.1.weight', 'image_encoder.trunk.blocks.15.mlp.layers.1.weight', 'image_encoder.trunk.blocks.12.norm2.bias', 'image_encoder.neck.convs.1.conv.bias', 'image_encoder.trunk.blocks.18.attn.proj.bias', 'image_encoder.trunk.blocks.23.norm2.bias', 'image_encoder.trunk.blocks.33.mlp.layers.0.bias', 'image_encoder.trunk.blocks.43.mlp.layers.0.weight', 'image_encoder.trunk.blocks.23.norm1.bias', 'image_encoder.trunk.blocks.37.attn.proj.bias', 'image_encoder.trunk.blocks.25.norm2.bias', 'image_encoder.trunk.blocks.22.mlp.layers.0.bias', 'image_encoder.trunk.blocks.4.mlp.layers.0.bias', 'image_encoder.trunk.blocks.5.mlp.layers.0.weight', 'image_encoder.trunk.blocks.46.norm2.bias', 'image_encoder.trunk.blocks.8.attn.proj.bias', 'image_encoder.trunk.blocks.4.norm2.weight', 'image_encoder.trunk.blocks.38.mlp.layers.0.bias', 'image_encoder.trunk.blocks.1.mlp.layers.1.bias', 'image_encoder.trunk.blocks.3.attn.qkv.bias', 'image_encoder.trunk.blocks.23.norm1.weight', 'image_encoder.trunk.blocks.3.mlp.layers.1.bias', 'image_encoder.trunk.blocks.13.mlp.layers.1.bias', 'image_encoder.trunk.pos_embed_window', 'image_encoder.trunk.blocks.20.norm2.weight', 'image_encoder.trunk.blocks.25.norm1.weight', 'image_encoder.trunk.blocks.42.attn.qkv.weight', 'image_encoder.trunk.blocks.35.norm2.weight', 'image_encoder.trunk.blocks.3.attn.proj.bias', 'image_encoder.trunk.blocks.9.attn.proj.weight', 'image_encoder.trunk.blocks.2.norm2.weight', 'image_encoder.trunk.blocks.34.norm2.weight', 'image_encoder.trunk.blocks.10.mlp.layers.1.weight', 'image_encoder.trunk.blocks.47.mlp.layers.1.weight', 'image_encoder.trunk.pos_embed', 'image_encoder.trunk.blocks.16.norm2.weight', 'image_encoder.trunk.blocks.43.attn.proj.weight', 'image_encoder.trunk.blocks.41.mlp.layers.1.weight', 'image_encoder.trunk.blocks.9.mlp.layers.1.weight', 'image_encoder.trunk.blocks.42.attn.proj.weight', 'image_encoder.trunk.blocks.4.attn.qkv.bias', 'image_encoder.trunk.blocks.36.attn.proj.weight', 'image_encoder.trunk.blocks.39.norm1.bias', 'image_encoder.trunk.blocks.8.attn.qkv.bias', 'image_encoder.trunk.blocks.2.norm2.bias', 'image_encoder.neck.convs.1.conv.weight', 'image_encoder.trunk.blocks.27.norm1.weight', 'image_encoder.trunk.blocks.42.mlp.layers.0.bias', 'image_encoder.trunk.blocks.19.attn.qkv.weight', 'image_encoder.trunk.blocks.6.mlp.layers.0.weight', 'image_encoder.trunk.blocks.31.attn.qkv.bias', 'image_encoder.trunk.blocks.11.attn.qkv.weight', 'image_encoder.trunk.blocks.26.norm1.bias', 'image_encoder.trunk.blocks.32.mlp.layers.1.bias', 'image_encoder.trunk.blocks.24.attn.qkv.bias', 'image_encoder.trunk.blocks.7.attn.proj.bias', 'image_encoder.trunk.blocks.20.attn.qkv.bias', 'image_encoder.trunk.blocks.40.attn.proj.weight', 'image_encoder.trunk.blocks.12.norm2.weight', 'image_encoder.trunk.blocks.19.attn.qkv.bias', 'image_encoder.trunk.blocks.29.attn.proj.weight', 'image_encoder.trunk.blocks.41.mlp.layers.0.bias', 'image_encoder.trunk.blocks.0.norm2.weight', 'image_encoder.trunk.blocks.17.attn.qkv.bias', 'image_encoder.trunk.blocks.22.attn.qkv.weight', 'image_encoder.trunk.blocks.46.norm1.bias', 'image_encoder.trunk.blocks.17.attn.proj.bias', 'image_encoder.trunk.blocks.25.mlp.layers.1.bias', 'image_encoder.trunk.blocks.14.mlp.layers.0.weight', 'image_encoder.trunk.blocks.40.mlp.layers.1.bias', 'image_encoder.trunk.blocks.45.mlp.layers.1.weight', 'image_encoder.trunk.blocks.40.mlp.layers.1.weight', 'image_encoder.trunk.blocks.21.norm1.weight', 'image_encoder.trunk.blocks.29.norm1.weight', 'image_encoder.trunk.blocks.10.mlp.layers.0.bias', 'image_encoder.trunk.blocks.5.norm2.weight', 'image_encoder.trunk.blocks.26.norm2.bias', 'image_encoder.trunk.blocks.14.mlp.layers.0.bias', 'image_encoder.trunk.blocks.14.norm1.weight', 'image_encoder.trunk.blocks.32.norm2.weight', 'image_encoder.trunk.blocks.2.mlp.layers.0.bias', 'image_encoder.trunk.blocks.30.norm2.weight', 'image_encoder.trunk.blocks.26.attn.qkv.bias', 'image_encoder.trunk.patch_embed.proj.bias', 'image_encoder.trunk.blocks.10.attn.qkv.bias', 'image_encoder.trunk.blocks.6.norm2.weight', 'image_encoder.trunk.blocks.13.attn.qkv.bias', 'image_encoder.trunk.patch_embed.proj.weight', 'image_encoder.trunk.blocks.7.attn.qkv.bias', 'image_encoder.trunk.blocks.36.attn.qkv.bias', 'image_encoder.trunk.blocks.8.proj.bias', 'image_encoder.trunk.blocks.12.attn.proj.weight', 'image_encoder.trunk.blocks.22.mlp.layers.1.weight', 'image_encoder.trunk.blocks.15.attn.qkv.bias', 'image_encoder.trunk.blocks.31.mlp.layers.1.bias', 'image_encoder.trunk.blocks.19.attn.proj.bias', 'image_encoder.trunk.blocks.37.attn.proj.weight', 'image_encoder.trunk.blocks.24.attn.qkv.weight', 'image_encoder.trunk.blocks.10.norm1.weight', 'image_encoder.trunk.blocks.29.mlp.layers.0.bias', 'image_encoder.trunk.blocks.11.mlp.layers.0.bias', 'image_encoder.trunk.blocks.34.mlp.layers.1.bias', 'image_encoder.trunk.blocks.2.mlp.layers.1.bias', 'image_encoder.trunk.blocks.19.mlp.layers.0.weight', 'image_encoder.trunk.blocks.3.mlp.layers.0.weight', 'image_encoder.trunk.blocks.30.norm2.bias', 'image_encoder.trunk.blocks.37.norm2.bias', 'image_encoder.trunk.blocks.21.mlp.layers.0.bias', 'image_encoder.trunk.blocks.44.attn.qkv.bias', 'image_encoder.trunk.blocks.4.norm1.weight', 'image_encoder.trunk.blocks.12.mlp.layers.1.weight', 'image_encoder.trunk.blocks.0.attn.proj.weight', 'image_encoder.trunk.blocks.16.mlp.layers.1.bias', 'image_encoder.trunk.blocks.44.attn.proj.weight', 'image_encoder.trunk.blocks.40.norm1.bias', 'image_encoder.trunk.blocks.20.norm1.weight', 'image_encoder.trunk.blocks.43.norm1.bias', 'image_encoder.trunk.blocks.9.norm1.bias', 'image_encoder.trunk.blocks.20.norm2.bias', 'image_encoder.trunk.blocks.1.mlp.layers.0.bias', 'image_encoder.trunk.blocks.20.attn.qkv.weight', 'image_encoder.trunk.blocks.44.proj.weight', 'image_encoder.trunk.blocks.4.attn.qkv.weight', 'image_encoder.trunk.blocks.23.mlp.layers.0.bias', 'image_encoder.trunk.blocks.3.attn.qkv.weight', 'image_encoder.trunk.blocks.6.mlp.layers.0.bias', 'image_encoder.trunk.blocks.38.mlp.layers.1.bias', 'image_encoder.trunk.blocks.9.attn.qkv.bias', 'image_encoder.trunk.blocks.17.mlp.layers.0.bias', 'image_encoder.trunk.blocks.26.attn.proj.bias', 'image_encoder.trunk.blocks.20.attn.proj.bias', 'image_encoder.trunk.blocks.38.attn.qkv.weight', 'image_encoder.trunk.blocks.21.attn.proj.bias', 'image_encoder.trunk.blocks.15.norm2.weight', 'image_encoder.trunk.blocks.4.mlp.layers.0.weight', 'image_encoder.trunk.blocks.6.attn.qkv.weight', 'image_encoder.trunk.blocks.34.attn.proj.bias', 'image_encoder.trunk.blocks.39.mlp.layers.1.bias', 'image_encoder.trunk.blocks.32.attn.proj.bias', 'image_encoder.trunk.blocks.31.attn.proj.weight', 'image_encoder.neck.convs.2.conv.weight', 'image_encoder.trunk.blocks.16.norm1.weight', 'image_encoder.trunk.blocks.31.attn.proj.bias', 'image_encoder.trunk.blocks.12.attn.qkv.weight', 'image_encoder.trunk.blocks.4.norm2.bias', 'image_encoder.trunk.blocks.13.norm2.bias', 'image_encoder.trunk.blocks.8.norm2.bias', 'image_encoder.trunk.blocks.31.mlp.layers.0.bias', 'image_encoder.trunk.blocks.2.attn.proj.bias', 'image_encoder.trunk.blocks.11.norm2.bias', 'image_encoder.trunk.blocks.34.mlp.layers.1.weight', 'image_encoder.trunk.blocks.26.norm1.weight', 'image_encoder.trunk.blocks.29.attn.qkv.weight', 'image_encoder.trunk.blocks.8.mlp.layers.1.bias', 'image_encoder.trunk.blocks.25.mlp.layers.1.weight', 'image_encoder.trunk.blocks.39.mlp.layers.0.weight', 'image_encoder.trunk.blocks.5.norm1.weight', 'image_encoder.trunk.blocks.9.mlp.layers.0.weight', 'image_encoder.trunk.blocks.3.norm2.weight', 'image_encoder.trunk.blocks.15.mlp.layers.0.weight', 'image_encoder.trunk.blocks.40.mlp.layers.0.bias', 'image_encoder.trunk.blocks.44.attn.qkv.weight', 'image_encoder.trunk.blocks.15.attn.proj.weight', 'image_encoder.trunk.blocks.28.attn.proj.bias', 'image_encoder.trunk.blocks.40.attn.qkv.bias', 'image_encoder.trunk.blocks.10.mlp.layers.0.weight', 'image_encoder.trunk.blocks.8.norm1.bias', 'image_encoder.trunk.blocks.27.mlp.layers.0.weight', 'image_encoder.trunk.blocks.36.norm2.weight', 'image_encoder.trunk.blocks.14.norm1.bias', 'image_encoder.trunk.blocks.42.norm2.weight', 'image_encoder.trunk.blocks.43.mlp.layers.0.bias', 'image_encoder.trunk.blocks.26.mlp.layers.1.weight', 'image_encoder.trunk.blocks.39.mlp.layers.0.bias', 'image_encoder.trunk.blocks.14.attn.proj.bias', 'image_encoder.trunk.blocks.0.norm2.bias', 'image_encoder.trunk.blocks.45.norm1.weight', 'image_encoder.trunk.blocks.28.attn.qkv.bias', 'image_encoder.trunk.blocks.9.norm1.weight', 'image_encoder.trunk.blocks.16.norm2.bias', 'image_encoder.trunk.blocks.1.norm1.bias', 'image_encoder.trunk.blocks.0.attn.qkv.bias', 'image_encoder.trunk.blocks.45.mlp.layers.1.bias', 'image_encoder.trunk.blocks.4.attn.proj.weight', 'image_encoder.trunk.blocks.0.attn.qkv.weight', 'image_encoder.trunk.blocks.29.mlp.layers.0.weight', 'image_encoder.trunk.blocks.30.mlp.layers.0.bias', 'image_encoder.trunk.blocks.37.norm1.bias', 'image_encoder.trunk.blocks.13.norm2.weight', 'image_encoder.trunk.blocks.45.mlp.layers.0.weight', 'image_encoder.trunk.blocks.42.mlp.layers.1.bias', 'image_encoder.trunk.blocks.11.norm1.bias', 'image_encoder.trunk.blocks.18.attn.qkv.weight', 'image_encoder.trunk.blocks.16.attn.proj.weight', 'image_encoder.trunk.blocks.4.norm1.bias', 'image_encoder.trunk.blocks.24.norm1.weight', 'image_encoder.trunk.blocks.46.attn.qkv.bias', 'image_encoder.trunk.blocks.27.attn.proj.bias', 'image_encoder.trunk.blocks.17.mlp.layers.0.weight', 'image_encoder.trunk.blocks.36.mlp.layers.0.weight', 'image_encoder.trunk.blocks.0.norm1.bias', 'image_encoder.trunk.blocks.41.norm1.bias', 'image_encoder.trunk.blocks.6.attn.proj.weight', 'image_encoder.trunk.blocks.35.attn.proj.bias', 'image_encoder.trunk.blocks.15.attn.proj.bias', 'image_encoder.trunk.blocks.22.norm1.weight', 'image_encoder.trunk.blocks.35.norm2.bias', 'image_encoder.trunk.blocks.19.mlp.layers.1.bias', 'image_encoder.trunk.blocks.37.norm1.weight', 'image_encoder.trunk.blocks.14.mlp.layers.1.bias', 'image_encoder.trunk.blocks.28.attn.proj.weight', 'image_encoder.neck.convs.0.conv.bias', 'image_encoder.trunk.blocks.30.norm1.bias', 'image_encoder.trunk.blocks.14.norm2.weight', 'image_encoder.trunk.blocks.8.mlp.layers.1.weight', 'image_encoder.trunk.blocks.43.attn.proj.bias', 'image_encoder.trunk.blocks.30.mlp.layers.1.bias', 'image_encoder.trunk.blocks.9.mlp.layers.0.bias', 'image_encoder.trunk.blocks.44.norm2.bias', 'image_encoder.trunk.blocks.36.attn.qkv.weight', 'image_encoder.trunk.blocks.27.attn.qkv.bias', 'image_encoder.trunk.blocks.34.attn.proj.weight', 'image_encoder.trunk.blocks.27.attn.qkv.weight', 'image_encoder.trunk.blocks.0.mlp.layers.1.weight', 'image_encoder.neck.convs.3.conv.bias', 'image_encoder.trunk.blocks.44.mlp.layers.1.weight', 'image_encoder.trunk.blocks.31.mlp.layers.0.weight', 'image_encoder.trunk.blocks.36.norm1.bias', 'image_encoder.trunk.blocks.12.mlp.layers.1.bias', 'image_encoder.trunk.blocks.4.attn.proj.bias', 'image_encoder.trunk.blocks.14.attn.proj.weight', 'image_encoder.trunk.blocks.2.mlp.layers.1.weight', 'image_encoder.trunk.blocks.20.mlp.layers.1.weight', 'image_encoder.trunk.blocks.32.norm1.weight', 'image_encoder.trunk.blocks.1.attn.qkv.weight', 'image_encoder.trunk.blocks.2.attn.qkv.bias', 'image_encoder.trunk.blocks.14.attn.qkv.weight', 'image_encoder.trunk.blocks.10.norm2.weight', 'image_encoder.trunk.blocks.42.mlp.layers.1.weight', 'image_encoder.trunk.blocks.1.attn.proj.bias', 'image_encoder.trunk.blocks.5.norm1.bias', 'image_encoder.trunk.blocks.40.norm1.weight', 'image_encoder.trunk.blocks.5.mlp.layers.1.weight', 'image_encoder.trunk.blocks.23.attn.qkv.bias', 'image_encoder.trunk.blocks.39.norm1.weight', 'image_encoder.trunk.blocks.25.attn.proj.weight', 'image_encoder.trunk.blocks.25.attn.proj.bias', 'image_encoder.trunk.blocks.9.mlp.layers.1.bias', 'image_encoder.trunk.blocks.1.norm2.weight', 'image_encoder.trunk.blocks.46.attn.qkv.weight', 'image_encoder.trunk.blocks.32.mlp.layers.1.weight', 'image_encoder.trunk.blocks.21.attn.proj.weight', 'image_encoder.trunk.blocks.17.norm2.weight', 'image_encoder.trunk.blocks.15.norm1.bias', 'image_encoder.trunk.blocks.12.mlp.layers.0.bias', 'image_encoder.trunk.blocks.22.mlp.layers.1.bias', 'image_encoder.trunk.blocks.44.norm1.weight', 'image_encoder.trunk.blocks.33.attn.qkv.bias', 'image_encoder.trunk.blocks.7.attn.proj.weight', 'image_encoder.trunk.blocks.10.norm1.bias', 'image_encoder.trunk.blocks.1.attn.proj.weight', 'image_encoder.trunk.blocks.16.norm1.bias', 'image_encoder.trunk.blocks.40.attn.proj.bias', 'image_encoder.trunk.blocks.8.mlp.layers.0.weight', 'image_encoder.trunk.blocks.41.norm2.bias', 'image_encoder.trunk.blocks.44.proj.bias', 'image_encoder.trunk.blocks.18.norm2.weight', 'image_encoder.trunk.blocks.41.norm1.weight', 'image_encoder.trunk.blocks.38.attn.proj.weight', 'image_encoder.trunk.blocks.15.norm1.weight', 'image_encoder.trunk.blocks.18.norm1.weight', 'image_encoder.trunk.blocks.7.mlp.layers.1.weight', 'image_encoder.trunk.blocks.33.attn.proj.weight', 'image_encoder.trunk.blocks.35.attn.proj.weight', 'image_encoder.trunk.blocks.33.norm2.weight', 'image_encoder.trunk.blocks.0.mlp.layers.1.bias', 'image_encoder.trunk.blocks.36.mlp.layers.1.bias', 'image_encoder.trunk.blocks.43.attn.qkv.weight', 'image_encoder.trunk.blocks.28.norm2.weight', 'image_encoder.trunk.blocks.46.norm2.weight', 'image_encoder.trunk.blocks.28.mlp.layers.1.bias', 'image_encoder.trunk.blocks.34.attn.qkv.weight', 'image_encoder.trunk.blocks.25.mlp.layers.0.weight', 'image_encoder.trunk.blocks.23.mlp.layers.1.weight', 'image_encoder.trunk.blocks.18.attn.qkv.bias', 'image_encoder.trunk.blocks.40.mlp.layers.0.weight', 'image_encoder.trunk.blocks.34.mlp.layers.0.bias', 'image_encoder.trunk.blocks.11.attn.qkv.bias', 'image_encoder.trunk.blocks.35.attn.qkv.weight', 'image_encoder.trunk.blocks.47.norm1.weight', 'image_encoder.trunk.blocks.30.mlp.layers.0.weight', 'image_encoder.trunk.blocks.10.attn.qkv.weight', 'image_encoder.trunk.blocks.32.attn.qkv.bias', 'image_encoder.trunk.blocks.45.attn.proj.weight', 'image_encoder.trunk.blocks.5.attn.qkv.weight', 'image_encoder.trunk.blocks.30.attn.proj.weight', 'image_encoder.trunk.blocks.46.mlp.layers.0.bias', 'image_encoder.trunk.blocks.33.norm2.bias', 'image_encoder.trunk.blocks.39.attn.qkv.bias', 'image_encoder.trunk.blocks.21.norm2.weight', 'image_encoder.trunk.blocks.10.mlp.layers.1.bias', 'image_encoder.trunk.blocks.46.attn.proj.weight', 'image_encoder.trunk.blocks.13.mlp.layers.0.bias', 'image_encoder.trunk.blocks.10.norm2.bias', 'image_encoder.trunk.blocks.19.norm2.bias', 'image_encoder.trunk.blocks.21.mlp.layers.0.weight', 'image_encoder.trunk.blocks.24.attn.proj.bias', 'image_encoder.trunk.blocks.8.attn.proj.weight', 'image_encoder.trunk.blocks.27.norm1.bias', 'image_encoder.trunk.blocks.18.mlp.layers.1.weight', 'image_encoder.trunk.blocks.13.norm1.weight', 'image_encoder.trunk.blocks.16.mlp.layers.0.bias', 'image_encoder.trunk.blocks.36.mlp.layers.0.bias', 'image_encoder.trunk.blocks.33.norm1.weight', 'image_encoder.trunk.blocks.18.mlp.layers.1.bias', 'image_encoder.trunk.blocks.40.attn.qkv.weight', 'image_encoder.trunk.blocks.17.mlp.layers.1.weight', 'image_encoder.trunk.blocks.31.norm1.bias', 'image_encoder.trunk.blocks.38.norm1.weight', 'image_encoder.trunk.blocks.40.norm2.weight', 'image_encoder.trunk.blocks.42.norm1.bias', 'image_encoder.trunk.blocks.41.norm2.weight', 'image_encoder.trunk.blocks.34.norm2.bias', 'image_encoder.trunk.blocks.43.mlp.layers.1.weight', 'image_encoder.trunk.blocks.21.mlp.layers.1.weight', 'image_encoder.trunk.blocks.19.mlp.layers.1.weight', 'image_encoder.trunk.blocks.15.mlp.layers.0.bias', 'image_encoder.trunk.blocks.38.attn.proj.bias', 'image_encoder.trunk.blocks.14.mlp.layers.1.weight', 'image_encoder.trunk.blocks.19.norm1.bias', 'image_encoder.trunk.blocks.36.attn.proj.bias', 'image_encoder.trunk.blocks.45.attn.qkv.bias', 'image_encoder.trunk.blocks.41.attn.proj.bias', 'image_encoder.trunk.blocks.11.attn.proj.bias', 'image_encoder.trunk.blocks.33.mlp.layers.1.bias', 'image_encoder.trunk.blocks.23.attn.proj.bias', 'image_encoder.trunk.blocks.23.norm2.weight', 'image_encoder.trunk.blocks.12.mlp.layers.0.weight', 'image_encoder.trunk.blocks.34.attn.qkv.bias', 'image_encoder.trunk.blocks.17.norm1.bias', 'image_encoder.trunk.blocks.8.mlp.layers.0.bias', 'image_encoder.trunk.blocks.19.mlp.layers.0.bias', 'image_encoder.trunk.blocks.13.attn.proj.bias', 'image_encoder.trunk.blocks.46.mlp.layers.1.bias', 'image_encoder.trunk.blocks.9.attn.proj.bias', 'image_encoder.trunk.blocks.47.attn.proj.weight', 'image_encoder.trunk.blocks.7.mlp.layers.0.weight', 'image_encoder.trunk.blocks.10.attn.proj.bias', 'image_encoder.trunk.blocks.21.attn.qkv.weight', 'image_encoder.trunk.blocks.36.norm1.weight', 'image_encoder.trunk.blocks.35.norm1.bias', 'image_encoder.trunk.blocks.47.attn.qkv.bias', 'image_encoder.trunk.blocks.0.norm1.weight', 'image_encoder.trunk.blocks.7.norm2.bias', 'image_encoder.trunk.blocks.17.mlp.layers.1.bias', 'image_encoder.trunk.blocks.41.mlp.layers.0.weight', 'image_encoder.trunk.blocks.38.norm2.bias', 'image_encoder.neck.convs.2.conv.bias', 'image_encoder.trunk.blocks.14.attn.qkv.bias', 'image_encoder.trunk.blocks.22.norm2.weight', 'image_encoder.trunk.blocks.28.norm1.weight', 'image_encoder.trunk.blocks.18.norm2.bias', 'image_encoder.trunk.blocks.31.attn.qkv.weight', 'image_encoder.trunk.blocks.41.attn.qkv.weight', 'image_encoder.trunk.blocks.13.norm1.bias', 'image_encoder.trunk.blocks.24.norm2.bias', 'image_encoder.trunk.blocks.18.norm1.bias', 'image_encoder.trunk.blocks.37.mlp.layers.0.weight', 'image_encoder.trunk.blocks.8.norm1.weight', 'image_encoder.trunk.blocks.44.mlp.layers.1.bias', 'image_encoder.trunk.blocks.42.mlp.layers.0.weight', 'image_encoder.trunk.blocks.42.norm1.weight', 'image_encoder.trunk.blocks.23.mlp.layers.1.bias', 'image_encoder.trunk.blocks.2.norm1.bias', 'image_encoder.trunk.blocks.12.attn.proj.bias', 'image_encoder.trunk.blocks.1.norm2.bias', 'image_encoder.trunk.blocks.42.attn.qkv.bias', 'image_encoder.trunk.blocks.22.norm2.bias'}
INFO 2025-12-09 22:19:01,885 optimizer.py: 248: Matches for param_name [*bias*]: {'sam_mask_decoder.output_hypernetworks_mlps.2.layers.2.bias', 'memory_attention.layers.0.norm3.bias', 'memory_encoder.fuser.layers.0.pwconv2.bias', 'image_encoder.trunk.blocks.42.norm2.bias', 'sam_mask_decoder.transformer.final_attn_token_to_image.v_proj.bias', 'image_encoder.trunk.blocks.27.mlp.layers.1.bias', 'image_encoder.trunk.blocks.28.norm1.bias', 'image_encoder.trunk.blocks.18.mlp.layers.0.bias', 'image_encoder.trunk.blocks.21.attn.qkv.bias', 'image_encoder.trunk.blocks.5.attn.proj.bias', 'image_encoder.trunk.blocks.3.mlp.layers.0.bias', 'image_encoder.trunk.blocks.7.norm1.bias', 'routefuse.conv_dense.bias', 'image_encoder.trunk.blocks.39.attn.proj.bias', 'image_encoder.trunk.blocks.4.mlp.layers.1.bias', 'memory_attention.layers.0.cross_attn_image.q_proj.bias', 'image_encoder.trunk.blocks.21.mlp.layers.1.bias', 'sam_mask_decoder.output_hypernetworks_mlps.1.layers.2.bias', 'image_encoder.trunk.blocks.6.norm1.bias', 'image_encoder.trunk.blocks.41.mlp.layers.1.bias', 'image_encoder.trunk.blocks.20.norm1.bias', 'ME.seq_modeling_block.post_norm.bias', 'sam_mask_decoder.transformer.layers.1.cross_attn_image_to_token.k_proj.bias', 'memory_encoder.fuser.layers.1.dwconv.bias', 'sam_mask_decoder.transformer.layers.0.cross_attn_image_to_token.k_proj.bias', 'image_encoder.trunk.blocks.43.mlp.layers.1.bias', 'image_encoder.trunk.blocks.47.attn.proj.bias', 'sam_mask_decoder.output_hypernetworks_mlps.1.layers.1.bias', 'image_encoder.trunk.blocks.25.attn.qkv.bias', 'image_encoder.trunk.blocks.32.norm2.bias', 'image_encoder.trunk.blocks.16.attn.qkv.bias', 'image_encoder.trunk.blocks.47.norm2.bias', 'memory_attention.layers.1.self_attn.k_proj.bias', 'image_encoder.trunk.blocks.46.attn.proj.bias', 'memory_attention.layers.3.norm1.bias', 'memory_attention.layers.3.cross_attn_image.out_proj.bias', 'image_encoder.trunk.blocks.37.attn.qkv.bias', 'image_encoder.trunk.blocks.2.proj.bias', 'ME.branch1.1.bn.bias', 'image_encoder.trunk.blocks.32.mlp.layers.0.bias', 'memory_attention.layers.0.linear2.bias', 'memory_attention.layers.0.linear1.bias', 'image_encoder.trunk.blocks.35.attn.qkv.bias', 'image_encoder.trunk.blocks.24.mlp.layers.0.bias', 'sam_mask_decoder.output_hypernetworks_mlps.3.layers.0.bias', 'image_encoder.trunk.blocks.5.attn.qkv.bias', 'image_encoder.trunk.blocks.44.attn.proj.bias', 'sam_mask_decoder.transformer.layers.1.cross_attn_token_to_image.q_proj.bias', 'image_encoder.trunk.blocks.7.mlp.layers.1.bias', 'image_encoder.trunk.blocks.5.norm2.bias', 'sam_mask_decoder.transformer.layers.1.cross_attn_token_to_image.v_proj.bias', 'image_encoder.trunk.blocks.47.mlp.layers.0.bias', 'image_encoder.trunk.blocks.30.attn.qkv.bias', 'image_encoder.trunk.blocks.29.attn.qkv.bias', 'image_encoder.trunk.blocks.28.mlp.layers.0.bias', 'memory_encoder.mask_downsampler.encoder.12.bias', 'image_encoder.trunk.blocks.34.norm1.bias', 'image_encoder.trunk.blocks.3.norm1.bias', 'image_encoder.trunk.blocks.33.norm1.bias', 'image_encoder.trunk.blocks.22.attn.qkv.bias', 'memory_encoder.fuser.layers.0.norm.bias', 'image_encoder.trunk.blocks.12.norm1.bias', 'memory_attention.layers.2.self_attn.q_proj.bias', 'image_encoder.trunk.blocks.29.mlp.layers.1.bias', 'image_encoder.trunk.blocks.20.mlp.layers.0.bias', 'memory_encoder.fuser.layers.1.pwconv2.bias', 'sam_mask_decoder.transformer.norm_final_attn.bias', 'image_encoder.trunk.blocks.42.attn.proj.bias', 'sam_mask_decoder.output_hypernetworks_mlps.0.layers.1.bias', 'image_encoder.trunk.blocks.16.attn.proj.bias', 'image_encoder.trunk.blocks.24.mlp.layers.1.bias', 'image_encoder.trunk.blocks.22.attn.proj.bias', 'image_encoder.trunk.blocks.22.norm1.bias', 'ME.depthwise_conv_reduce_channels_in.bias', 'sam_prompt_encoder.mask_downscaling.3.bias', 'image_encoder.trunk.blocks.38.attn.qkv.bias', 'image_encoder.trunk.blocks.33.attn.proj.bias', 'image_encoder.trunk.blocks.45.mlp.layers.0.bias', 'image_encoder.trunk.blocks.7.mlp.layers.0.bias', 'image_encoder.trunk.blocks.47.mlp.layers.1.bias', 'memory_encoder.mask_downsampler.encoder.4.bias', 'image_encoder.trunk.blocks.44.norm1.bias', 'memory_attention.layers.1.self_attn.v_proj.bias', 'image_encoder.trunk.blocks.1.attn.qkv.bias', 'image_encoder.trunk.blocks.43.attn.qkv.bias', 'image_encoder.trunk.blocks.45.norm2.bias', 'memory_encoder.pix_feat_proj.bias', 'image_encoder.trunk.blocks.35.mlp.layers.1.bias', 'image_encoder.trunk.blocks.3.norm2.bias', 'image_encoder.trunk.blocks.39.norm2.bias', 'sam_mask_decoder.transformer.layers.1.norm3.bias', 'sam_mask_decoder.transformer.layers.0.self_attn.q_proj.bias', 'memory_attention.layers.3.norm3.bias', 'image_encoder.trunk.blocks.0.mlp.layers.0.bias', 'sam_mask_decoder.transformer.layers.1.norm1.bias', 'memory_attention.layers.3.self_attn.k_proj.bias', 'memory_attention.layers.1.norm1.bias', 'image_encoder.trunk.blocks.11.mlp.layers.1.bias', 'image_encoder.trunk.blocks.29.norm1.bias', 'image_encoder.trunk.blocks.6.attn.qkv.bias', 'ME.norm.bias', 'image_encoder.trunk.blocks.41.attn.qkv.bias', 'image_encoder.trunk.blocks.9.norm2.bias', 'image_encoder.trunk.blocks.25.mlp.layers.0.bias', 'memory_encoder.fuser.layers.0.pwconv1.bias', 'image_encoder.trunk.blocks.15.mlp.layers.1.bias', 'sam_mask_decoder.output_upscaling.3.bias', 'memory_encoder.fuser.layers.0.dwconv.bias', 'sam_mask_decoder.transformer.layers.1.cross_attn_image_to_token.q_proj.bias', 'ME.seq_modeling_block.learnable_ttt_lr_bias', 'image_encoder.trunk.blocks.45.norm1.bias', 'image_encoder.trunk.blocks.45.attn.proj.bias', 'image_encoder.trunk.blocks.37.mlp.layers.0.bias', 'sam_mask_decoder.transformer.layers.1.cross_attn_image_to_token.out_proj.bias', 'image_encoder.trunk.blocks.5.mlp.layers.0.bias', 'memory_attention.layers.2.linear2.bias', 'memory_attention.layers.1.self_attn.q_proj.bias', 'sam_mask_decoder.transformer.layers.0.norm1.bias', 'image_encoder.trunk.blocks.21.norm2.bias', 'memory_attention.norm.bias', 'image_encoder.trunk.blocks.25.norm1.bias', 'image_encoder.trunk.blocks.12.attn.qkv.bias', 'image_encoder.trunk.blocks.15.norm2.bias', 'sam_mask_decoder.transformer.layers.0.self_attn.out_proj.bias', 'image_encoder.trunk.blocks.5.mlp.layers.1.bias', 'memory_attention.layers.2.cross_attn_image.k_proj.bias', 'image_encoder.trunk.blocks.14.norm2.bias', 'sam_mask_decoder.transformer.layers.0.mlp.layers.0.bias', 'image_encoder.trunk.blocks.21.norm1.bias', 'image_encoder.trunk.blocks.26.mlp.layers.1.bias', 'image_encoder.trunk.blocks.0.attn.proj.bias', 'ME.branch1.2.bn.bias', 'sam_mask_decoder.transformer.layers.0.self_attn.k_proj.bias', 'memory_attention.layers.0.self_attn.v_proj.bias', 'image_encoder.trunk.blocks.30.attn.proj.bias', 'image_encoder.trunk.blocks.28.norm2.bias', 'image_encoder.trunk.blocks.32.norm1.bias', 'image_encoder.trunk.blocks.35.mlp.layers.0.bias', 'image_encoder.trunk.blocks.44.mlp.layers.0.bias', 'sam_mask_decoder.output_hypernetworks_mlps.0.layers.0.bias', 'image_encoder.trunk.blocks.27.norm2.bias', 'image_encoder.trunk.blocks.17.norm2.bias', 'image_encoder.trunk.blocks.47.norm1.bias', 'image_encoder.trunk.blocks.26.mlp.layers.0.bias', 'memory_attention.layers.2.linear1.bias', 'image_encoder.trunk.blocks.6.norm2.bias', 'image_encoder.trunk.blocks.31.norm2.bias', 'image_encoder.trunk.blocks.43.norm2.bias', 'image_encoder.trunk.blocks.6.mlp.layers.1.bias', 'memory_attention.layers.0.self_attn.out_proj.bias', 'image_encoder.trunk.blocks.29.norm2.bias', 'image_encoder.trunk.blocks.36.norm2.bias', 'image_encoder.trunk.blocks.38.norm1.bias', 'image_encoder.trunk.blocks.27.mlp.layers.0.bias', 'image_encoder.trunk.blocks.37.mlp.layers.1.bias', 'sam_mask_decoder.pred_obj_score_head.layers.2.bias', 'sam_prompt_encoder.mask_downscaling.0.bias', 'memory_attention.layers.3.cross_attn_image.q_proj.bias', 'memory_attention.layers.2.norm1.bias', 'memory_attention.layers.3.self_attn.v_proj.bias', 'memory_attention.layers.1.cross_attn_image.out_proj.bias', 'image_encoder.trunk.blocks.6.attn.proj.bias', 'image_encoder.trunk.blocks.29.attn.proj.bias', 'memory_attention.layers.3.norm2.bias', 'image_encoder.trunk.blocks.40.norm2.bias', 'sam_mask_decoder.transformer.layers.0.cross_attn_image_to_token.v_proj.bias', 'image_encoder.trunk.blocks.20.mlp.layers.1.bias', 'image_encoder.trunk.blocks.24.norm1.bias', 'image_encoder.trunk.blocks.12.norm2.bias', 'image_encoder.neck.convs.1.conv.bias', 'image_encoder.trunk.blocks.18.attn.proj.bias', 'image_encoder.trunk.blocks.23.norm2.bias', 'image_encoder.trunk.blocks.33.mlp.layers.0.bias', 'image_encoder.trunk.blocks.23.norm1.bias', 'sam_prompt_encoder.mask_downscaling.1.bias', 'memory_attention.layers.1.cross_attn_image.q_proj.bias', 'image_encoder.trunk.blocks.37.attn.proj.bias', 'image_encoder.trunk.blocks.25.norm2.bias', 'image_encoder.trunk.blocks.22.mlp.layers.0.bias', 'image_encoder.trunk.blocks.4.mlp.layers.0.bias', 'image_encoder.trunk.blocks.46.norm2.bias', 'image_encoder.trunk.blocks.8.attn.proj.bias', 'image_encoder.trunk.blocks.38.mlp.layers.0.bias', 'image_encoder.trunk.blocks.1.mlp.layers.1.bias', 'image_encoder.trunk.blocks.3.attn.qkv.bias', 'image_encoder.trunk.blocks.3.mlp.layers.1.bias', 'image_encoder.trunk.blocks.13.mlp.layers.1.bias', 'image_encoder.trunk.blocks.3.attn.proj.bias', 'sam_mask_decoder.transformer.layers.1.self_attn.q_proj.bias', 'sam_mask_decoder.transformer.layers.0.norm2.bias', 'ME.branch1.0.bn.bias', 'memory_encoder.mask_downsampler.encoder.7.bias', 'memory_attention.layers.2.cross_attn_image.q_proj.bias', 'sam_prompt_encoder.mask_downscaling.6.bias', 'memory_attention.layers.2.self_attn.v_proj.bias', 'image_encoder.trunk.blocks.4.attn.qkv.bias', 'image_encoder.trunk.blocks.39.norm1.bias', 'image_encoder.trunk.blocks.8.attn.qkv.bias', 'image_encoder.trunk.blocks.2.norm2.bias', 'sam_mask_decoder.transformer.layers.0.cross_attn_token_to_image.v_proj.bias', 'image_encoder.trunk.blocks.42.mlp.layers.0.bias', 'sam_mask_decoder.transformer.layers.0.cross_attn_token_to_image.k_proj.bias', 'image_encoder.trunk.blocks.31.attn.qkv.bias', 'memory_attention.layers.0.self_attn.q_proj.bias', 'image_encoder.trunk.blocks.26.norm1.bias', 'image_encoder.trunk.blocks.32.mlp.layers.1.bias', 'image_encoder.trunk.blocks.24.attn.qkv.bias', 'image_encoder.trunk.blocks.7.attn.proj.bias', 'image_encoder.trunk.blocks.20.attn.qkv.bias', 'image_encoder.trunk.blocks.19.attn.qkv.bias', 'sam_mask_decoder.transformer.layers.0.mlp.layers.1.bias', 'image_encoder.trunk.blocks.41.mlp.layers.0.bias', 'image_encoder.trunk.blocks.17.attn.qkv.bias', 'obj_ptr_tpos_proj.bias', 'image_encoder.trunk.blocks.46.norm1.bias', 'image_encoder.trunk.blocks.17.attn.proj.bias', 'image_encoder.trunk.blocks.25.mlp.layers.1.bias', 'image_encoder.trunk.blocks.40.mlp.layers.1.bias', 'sam_mask_decoder.transformer.layers.1.cross_attn_image_to_token.v_proj.bias', 'sam_mask_decoder.output_upscaling.0.bias', 'image_encoder.trunk.blocks.10.mlp.layers.0.bias', 'ME.seq_modeling_block.conv_q.bias', 'image_encoder.trunk.blocks.26.norm2.bias', 'image_encoder.trunk.blocks.14.mlp.layers.0.bias', 'memory_attention.layers.1.cross_attn_image.k_proj.bias', 'sam_mask_decoder.conv_s0.bias', 'image_encoder.trunk.blocks.2.mlp.layers.0.bias', 'memory_attention.layers.3.linear2.bias', 'image_encoder.trunk.blocks.26.attn.qkv.bias', 'memory_encoder.mask_downsampler.encoder.0.bias', 'image_encoder.trunk.patch_embed.proj.bias', 'sam_mask_decoder.output_hypernetworks_mlps.3.layers.1.bias', 'image_encoder.trunk.blocks.10.attn.qkv.bias', 'image_encoder.trunk.blocks.13.attn.qkv.bias', 'image_encoder.trunk.blocks.7.attn.qkv.bias', 'image_encoder.trunk.blocks.36.attn.qkv.bias', 'image_encoder.trunk.blocks.8.proj.bias', 'image_encoder.trunk.blocks.15.attn.qkv.bias', 'image_encoder.trunk.blocks.31.mlp.layers.1.bias', 'image_encoder.trunk.blocks.19.attn.proj.bias', 'memory_encoder.mask_downsampler.encoder.6.bias', 'image_encoder.trunk.blocks.29.mlp.layers.0.bias', 'image_encoder.trunk.blocks.11.mlp.layers.0.bias', 'image_encoder.trunk.blocks.34.mlp.layers.1.bias', 'image_encoder.trunk.blocks.2.mlp.layers.1.bias', 'image_encoder.trunk.blocks.30.norm2.bias', 'image_encoder.trunk.blocks.37.norm2.bias', 'image_encoder.trunk.blocks.21.mlp.layers.0.bias', 'image_encoder.trunk.blocks.44.attn.qkv.bias', 'memory_attention.layers.2.self_attn.k_proj.bias', 'image_encoder.trunk.blocks.16.mlp.layers.1.bias', 'image_encoder.trunk.blocks.40.norm1.bias', 'image_encoder.trunk.blocks.43.norm1.bias', 'image_encoder.trunk.blocks.9.norm1.bias', 'image_encoder.trunk.blocks.20.norm2.bias', 'image_encoder.trunk.blocks.1.mlp.layers.0.bias', 'sam_mask_decoder.transformer.layers.0.cross_attn_token_to_image.q_proj.bias', 'image_encoder.trunk.blocks.23.mlp.layers.0.bias', 'image_encoder.trunk.blocks.6.mlp.layers.0.bias', 'image_encoder.trunk.blocks.38.mlp.layers.1.bias', 'image_encoder.trunk.blocks.9.attn.qkv.bias', 'sam_mask_decoder.output_hypernetworks_mlps.0.layers.2.bias', 'image_encoder.trunk.blocks.17.mlp.layers.0.bias', 'sam_mask_decoder.conv_s1.bias', 'image_encoder.trunk.blocks.26.attn.proj.bias', 'image_encoder.trunk.blocks.20.attn.proj.bias', 'image_encoder.trunk.blocks.21.attn.proj.bias', 'image_encoder.trunk.blocks.34.attn.proj.bias', 'image_encoder.trunk.blocks.39.mlp.layers.1.bias', 'image_encoder.trunk.blocks.32.attn.proj.bias', 'sam_mask_decoder.transformer.layers.0.cross_attn_image_to_token.q_proj.bias', 'sam_mask_decoder.transformer.layers.0.cross_attn_image_to_token.out_proj.bias', 'image_encoder.trunk.blocks.31.attn.proj.bias', 'image_encoder.trunk.blocks.4.norm2.bias', 'image_encoder.trunk.blocks.13.norm2.bias', 'image_encoder.trunk.blocks.8.norm2.bias', 'sam_mask_decoder.transformer.layers.1.cross_attn_token_to_image.k_proj.bias', 'memory_attention.layers.0.self_attn.k_proj.bias', 'image_encoder.trunk.blocks.31.mlp.layers.0.bias', 'sam_mask_decoder.output_hypernetworks_mlps.2.layers.1.bias', 'image_encoder.trunk.blocks.2.attn.proj.bias', 'image_encoder.trunk.blocks.11.norm2.bias', 'image_encoder.trunk.blocks.8.mlp.layers.1.bias', 'memory_attention.layers.1.cross_attn_image.v_proj.bias', 'image_encoder.trunk.blocks.40.mlp.layers.0.bias', 'image_encoder.trunk.blocks.40.attn.qkv.bias', 'image_encoder.trunk.blocks.28.attn.proj.bias', 'image_encoder.trunk.blocks.8.norm1.bias', 'image_encoder.trunk.blocks.14.norm1.bias', 'sam_mask_decoder.output_hypernetworks_mlps.2.layers.0.bias', 'image_encoder.trunk.blocks.43.mlp.layers.0.bias', 'image_encoder.trunk.blocks.39.mlp.layers.0.bias', 'image_encoder.trunk.blocks.14.attn.proj.bias', 'image_encoder.trunk.blocks.0.norm2.bias', 'ME.branch1.3.bn.bias', 'image_encoder.trunk.blocks.28.attn.qkv.bias', 'image_encoder.trunk.blocks.16.norm2.bias', 'image_encoder.trunk.blocks.1.norm1.bias', 'image_encoder.trunk.blocks.0.attn.qkv.bias', 'image_encoder.trunk.blocks.45.mlp.layers.1.bias', 'image_encoder.trunk.blocks.30.mlp.layers.0.bias', 'image_encoder.trunk.blocks.37.norm1.bias', 'image_encoder.trunk.blocks.42.mlp.layers.1.bias', 'image_encoder.trunk.blocks.11.norm1.bias', 'ME.depthwise_conv_reduce_channels_out1.bias', 'memory_attention.layers.1.linear1.bias', 'image_encoder.trunk.blocks.4.norm1.bias', 'memory_attention.layers.1.norm3.bias', 'image_encoder.trunk.blocks.46.attn.qkv.bias', 'image_encoder.trunk.blocks.27.attn.proj.bias', 'image_encoder.trunk.blocks.0.norm1.bias', 'memory_attention.layers.0.norm2.bias', 'sam_mask_decoder.transformer.final_attn_token_to_image.q_proj.bias', 'image_encoder.trunk.blocks.41.norm1.bias', 'image_encoder.trunk.blocks.35.attn.proj.bias', 'image_encoder.trunk.blocks.15.attn.proj.bias', 'image_encoder.trunk.blocks.35.norm2.bias', 'image_encoder.trunk.blocks.19.mlp.layers.1.bias', 'obj_ptr_proj.layers.2.bias', 'image_encoder.trunk.blocks.14.mlp.layers.1.bias', 'image_encoder.neck.convs.0.conv.bias', 'memory_attention.layers.3.self_attn.out_proj.bias', 'sam_mask_decoder.transformer.layers.0.cross_attn_token_to_image.out_proj.bias', 'image_encoder.trunk.blocks.30.norm1.bias', 'ME.seq_modeling_block.ttt_norm_bias', 'image_encoder.trunk.blocks.43.attn.proj.bias', 'memory_attention.layers.3.self_attn.q_proj.bias', 'image_encoder.trunk.blocks.30.mlp.layers.1.bias', 'image_encoder.trunk.blocks.9.mlp.layers.0.bias', 'image_encoder.trunk.blocks.44.norm2.bias', 'image_encoder.trunk.blocks.27.attn.qkv.bias', 'image_encoder.neck.convs.3.conv.bias', 'sam_mask_decoder.transformer.layers.1.self_attn.v_proj.bias', 'image_encoder.trunk.blocks.36.norm1.bias', 'sam_mask_decoder.transformer.layers.1.mlp.layers.1.bias', 'image_encoder.trunk.blocks.12.mlp.layers.1.bias', 'image_encoder.trunk.blocks.4.attn.proj.bias', 'memory_attention.layers.0.cross_attn_image.out_proj.bias', 'memory_encoder.mask_downsampler.encoder.1.bias', 'sam_mask_decoder.output_hypernetworks_mlps.1.layers.0.bias', 'image_encoder.trunk.blocks.2.attn.qkv.bias', 'memory_attention.layers.2.self_attn.out_proj.bias', 'image_encoder.trunk.blocks.1.attn.proj.bias', 'image_encoder.trunk.blocks.5.norm1.bias', 'memory_attention.layers.2.cross_attn_image.out_proj.bias', 'image_encoder.trunk.blocks.23.attn.qkv.bias', 'sam_mask_decoder.transformer.final_attn_token_to_image.k_proj.bias', 'image_encoder.trunk.blocks.25.attn.proj.bias', 'image_encoder.trunk.blocks.9.mlp.layers.1.bias', 'sam_mask_decoder.transformer.layers.0.self_attn.v_proj.bias', 'image_encoder.trunk.blocks.15.norm1.bias', 'image_encoder.trunk.blocks.12.mlp.layers.0.bias', 'image_encoder.trunk.blocks.22.mlp.layers.1.bias', 'image_encoder.trunk.blocks.33.attn.qkv.bias', 'image_encoder.trunk.blocks.10.norm1.bias', 'memory_attention.layers.2.norm3.bias', 'image_encoder.trunk.blocks.16.norm1.bias', 'image_encoder.trunk.blocks.40.attn.proj.bias', 'image_encoder.trunk.blocks.41.norm2.bias', 'image_encoder.trunk.blocks.44.proj.bias', 'memory_encoder.mask_downsampler.encoder.10.bias', 'sam_mask_decoder.output_upscaling.1.bias', 'sam_mask_decoder.transformer.layers.1.norm4.bias', 'image_encoder.trunk.blocks.0.mlp.layers.1.bias', 'sam_mask_decoder.pred_obj_score_head.layers.1.bias', 'image_encoder.trunk.blocks.36.mlp.layers.1.bias', 'image_encoder.trunk.blocks.28.mlp.layers.1.bias', 'sam_prompt_encoder.mask_downscaling.4.bias', 'image_encoder.trunk.blocks.18.attn.qkv.bias', 'sam_mask_decoder.transformer.layers.0.norm3.bias', 'image_encoder.trunk.blocks.34.mlp.layers.0.bias', 'image_encoder.trunk.blocks.11.attn.qkv.bias', 'sam_mask_decoder.transformer.layers.1.cross_attn_token_to_image.out_proj.bias', 'memory_attention.layers.3.linear1.bias', 'image_encoder.trunk.blocks.32.attn.qkv.bias', 'sam_mask_decoder.iou_prediction_head.layers.0.bias', 'sam_mask_decoder.transformer.layers.1.self_attn.k_proj.bias', 'obj_ptr_proj.layers.0.bias', 'image_encoder.trunk.blocks.46.mlp.layers.0.bias', 'sam_mask_decoder.transformer.layers.1.norm2.bias', 'sam_mask_decoder.iou_prediction_head.layers.1.bias', 'image_encoder.trunk.blocks.33.norm2.bias', 'memory_encoder.mask_downsampler.encoder.9.bias', 'image_encoder.trunk.blocks.39.attn.qkv.bias', 'obj_ptr_proj.layers.1.bias', 'image_encoder.trunk.blocks.10.mlp.layers.1.bias', 'ME.depthwise_conv_reduce_channels_out2.bias', 'image_encoder.trunk.blocks.13.mlp.layers.0.bias', 'image_encoder.trunk.blocks.10.norm2.bias', 'memory_attention.layers.3.cross_attn_image.k_proj.bias', 'sam_mask_decoder.iou_prediction_head.layers.2.bias', 'image_encoder.trunk.blocks.19.norm2.bias', 'image_encoder.trunk.blocks.24.attn.proj.bias', 'image_encoder.trunk.blocks.27.norm1.bias', 'sam_mask_decoder.pred_obj_score_head.layers.0.bias', 'image_encoder.trunk.blocks.16.mlp.layers.0.bias', 'image_encoder.trunk.blocks.36.mlp.layers.0.bias', 'memory_attention.layers.2.norm2.bias', 'image_encoder.trunk.blocks.18.mlp.layers.1.bias', 'image_encoder.trunk.blocks.31.norm1.bias', 'image_encoder.trunk.blocks.42.norm1.bias', 'memory_attention.layers.3.cross_attn_image.v_proj.bias', 'image_encoder.trunk.blocks.34.norm2.bias', 'memory_encoder.fuser.layers.1.pwconv1.bias', 'mask_downsample.bias', 'image_encoder.trunk.blocks.15.mlp.layers.0.bias', 'image_encoder.trunk.blocks.38.attn.proj.bias', 'sam_mask_decoder.transformer.layers.0.norm4.bias', 'memory_encoder.mask_downsampler.encoder.3.bias', 'image_encoder.trunk.blocks.19.norm1.bias', 'image_encoder.trunk.blocks.36.attn.proj.bias', 'image_encoder.trunk.blocks.45.attn.qkv.bias', 'image_encoder.trunk.blocks.41.attn.proj.bias', 'image_encoder.trunk.blocks.11.attn.proj.bias', 'image_encoder.trunk.blocks.33.mlp.layers.1.bias', 'image_encoder.trunk.blocks.23.attn.proj.bias', 'memory_attention.layers.1.linear2.bias', 'image_encoder.trunk.blocks.34.attn.qkv.bias', 'memory_attention.layers.1.self_attn.out_proj.bias', 'image_encoder.trunk.blocks.17.norm1.bias', 'image_encoder.trunk.blocks.8.mlp.layers.0.bias', 'image_encoder.trunk.blocks.19.mlp.layers.0.bias', 'image_encoder.trunk.blocks.13.attn.proj.bias', 'image_encoder.trunk.blocks.46.mlp.layers.1.bias', 'image_encoder.trunk.blocks.9.attn.proj.bias', 'image_encoder.trunk.blocks.10.attn.proj.bias', 'image_encoder.trunk.blocks.47.attn.qkv.bias', 'image_encoder.trunk.blocks.35.norm1.bias', 'sam_mask_decoder.transformer.layers.1.self_attn.out_proj.bias', 'memory_encoder.fuser.layers.1.norm.bias', 'sam_mask_decoder.transformer.final_attn_token_to_image.out_proj.bias', 'memory_attention.layers.0.cross_attn_image.v_proj.bias', 'memory_attention.layers.2.cross_attn_image.v_proj.bias', 'memory_attention.layers.0.cross_attn_image.k_proj.bias', 'image_encoder.trunk.blocks.7.norm2.bias', 'image_encoder.trunk.blocks.17.mlp.layers.1.bias', 'memory_attention.layers.0.norm1.bias', 'image_encoder.trunk.blocks.38.norm2.bias', 'image_encoder.neck.convs.2.conv.bias', 'image_encoder.trunk.blocks.14.attn.qkv.bias', 'image_encoder.trunk.blocks.18.norm2.bias', 'image_encoder.trunk.blocks.12.attn.proj.bias', 'image_encoder.trunk.blocks.13.norm1.bias', 'sam_mask_decoder.output_hypernetworks_mlps.3.layers.2.bias', 'image_encoder.trunk.blocks.24.norm2.bias', 'image_encoder.trunk.blocks.18.norm1.bias', 'image_encoder.trunk.blocks.44.mlp.layers.1.bias', 'image_encoder.trunk.blocks.23.mlp.layers.1.bias', 'memory_attention.layers.1.norm2.bias', 'image_encoder.trunk.blocks.2.norm1.bias', 'memory_encoder.out_proj.bias', 'image_encoder.trunk.blocks.1.norm2.bias', 'image_encoder.trunk.blocks.42.attn.qkv.bias', 'ME.seq_modeling_block.conv_k.bias', 'sam_mask_decoder.transformer.layers.1.mlp.layers.0.bias', 'image_encoder.trunk.blocks.22.norm2.bias'}
INFO 2025-12-09 22:19:01,885 optimizer.py: 220: Matches for module_cls_name [torch.nn.LayerNorm]: {'image_encoder.trunk.blocks.6.norm2.weight', 'image_encoder.trunk.blocks.37.norm2.weight', 'image_encoder.trunk.blocks.32.norm1.weight', 'image_encoder.trunk.blocks.34.norm1.weight', 'sam_mask_decoder.transformer.layers.0.norm1.bias', 'memory_attention.layers.0.norm3.bias', 'image_encoder.trunk.blocks.42.norm2.bias', 'image_encoder.trunk.blocks.21.norm2.bias', 'image_encoder.trunk.blocks.25.norm2.weight', 'memory_attention.norm.bias', 'image_encoder.trunk.blocks.25.norm1.bias', 'image_encoder.trunk.blocks.15.norm2.bias', 'image_encoder.trunk.blocks.46.norm1.weight', 'image_encoder.trunk.blocks.10.norm2.weight', 'image_encoder.trunk.blocks.28.norm1.bias', 'memory_attention.layers.0.norm1.weight', 'image_encoder.trunk.blocks.5.norm1.bias', 'image_encoder.trunk.blocks.11.norm2.weight', 'image_encoder.trunk.blocks.12.norm1.weight', 'image_encoder.trunk.blocks.10.norm1.weight', 'image_encoder.trunk.blocks.14.norm2.bias', 'image_encoder.trunk.blocks.39.norm2.weight', 'image_encoder.trunk.blocks.21.norm1.bias', 'image_encoder.trunk.blocks.40.norm1.weight', 'memory_attention.layers.2.norm2.weight', 'memory_attention.layers.0.norm2.weight', 'image_encoder.trunk.blocks.39.norm1.weight', 'image_encoder.trunk.blocks.7.norm1.bias', 'image_encoder.trunk.blocks.7.norm1.weight', 'image_encoder.trunk.blocks.1.norm2.weight', 'image_encoder.trunk.blocks.6.norm1.bias', 'image_encoder.trunk.blocks.30.norm2.bias', 'image_encoder.trunk.blocks.28.norm2.bias', 'image_encoder.trunk.blocks.17.norm2.weight', 'image_encoder.trunk.blocks.15.norm1.bias', 'image_encoder.trunk.blocks.32.norm1.bias', 'image_encoder.trunk.blocks.20.norm1.bias', 'image_encoder.trunk.blocks.29.norm2.weight', 'image_encoder.trunk.blocks.37.norm2.bias', 'ME.seq_modeling_block.post_norm.bias', 'sam_mask_decoder.transformer.layers.1.norm2.weight', 'image_encoder.trunk.blocks.4.norm1.weight', 'image_encoder.trunk.blocks.44.norm1.weight', 'memory_attention.layers.2.norm1.weight', 'image_encoder.trunk.blocks.27.norm2.bias', 'image_encoder.trunk.blocks.10.norm1.bias', 'image_encoder.trunk.blocks.17.norm2.bias', 'image_encoder.trunk.blocks.47.norm1.bias', 'memory_attention.layers.1.norm3.weight', 'image_encoder.trunk.blocks.40.norm1.bias', 'image_encoder.trunk.blocks.20.norm1.weight', 'memory_attention.layers.3.norm1.weight', 'memory_attention.layers.2.norm3.bias', 'image_encoder.trunk.blocks.6.norm2.bias', 'image_encoder.trunk.blocks.43.norm1.weight', 'image_encoder.trunk.blocks.16.norm1.bias', 'image_encoder.trunk.blocks.43.norm1.bias', 'image_encoder.trunk.blocks.9.norm1.bias', 'image_encoder.trunk.blocks.20.norm2.bias', 'image_encoder.trunk.blocks.41.norm2.bias', 'memory_attention.layers.1.norm1.weight', 'image_encoder.trunk.blocks.18.norm2.weight', 'image_encoder.trunk.blocks.32.norm2.bias', 'image_encoder.trunk.blocks.41.norm1.weight', 'image_encoder.trunk.blocks.1.norm1.weight', 'image_encoder.trunk.blocks.31.norm2.bias', 'image_encoder.trunk.blocks.43.norm2.bias', 'memory_attention.layers.3.norm2.weight', 'image_encoder.trunk.blocks.19.norm2.weight', 'image_encoder.trunk.blocks.15.norm1.weight', 'image_encoder.trunk.blocks.18.norm1.weight', 'sam_mask_decoder.transformer.layers.0.norm2.weight', 'image_encoder.trunk.blocks.29.norm2.bias', 'image_encoder.trunk.blocks.47.norm2.bias', 'image_encoder.trunk.blocks.33.norm2.weight', 'image_encoder.trunk.blocks.36.norm2.bias', 'memory_attention.layers.3.norm3.weight', 'sam_mask_decoder.transformer.layers.0.norm3.weight', 'image_encoder.trunk.blocks.38.norm1.bias', 'sam_mask_decoder.transformer.layers.1.norm4.bias', 'ME.norm.weight', 'image_encoder.trunk.blocks.31.norm2.weight', 'image_encoder.trunk.blocks.19.norm1.weight', 'memory_attention.layers.3.norm1.bias', 'image_encoder.trunk.blocks.28.norm2.weight', 'image_encoder.trunk.blocks.46.norm2.weight', 'image_encoder.trunk.blocks.38.norm2.weight', 'image_encoder.trunk.blocks.15.norm2.weight', 'image_encoder.trunk.blocks.17.norm1.weight', 'sam_mask_decoder.transformer.layers.0.norm3.bias', 'memory_attention.layers.2.norm1.bias', 'memory_attention.layers.2.norm3.weight', 'image_encoder.trunk.blocks.16.norm1.weight', 'image_encoder.trunk.blocks.47.norm1.weight', 'image_encoder.trunk.blocks.24.norm2.weight', 'image_encoder.trunk.blocks.4.norm2.bias', 'image_encoder.trunk.blocks.13.norm2.bias', 'memory_attention.layers.3.norm2.bias', 'image_encoder.trunk.blocks.8.norm2.bias', 'image_encoder.trunk.blocks.31.norm1.weight', 'image_encoder.trunk.blocks.40.norm2.bias', 'image_encoder.trunk.blocks.5.norm2.bias', 'image_encoder.trunk.blocks.35.norm1.weight', 'image_encoder.trunk.blocks.34.norm1.bias', 'image_encoder.trunk.blocks.3.norm1.bias', 'image_encoder.trunk.blocks.11.norm2.bias', 'image_encoder.trunk.blocks.24.norm1.bias', 'image_encoder.trunk.blocks.33.norm1.bias', 'image_encoder.trunk.blocks.26.norm1.weight', 'sam_mask_decoder.transformer.layers.1.norm2.bias', 'image_encoder.trunk.blocks.30.norm1.weight', 'image_encoder.trunk.blocks.12.norm1.bias', 'image_encoder.trunk.blocks.5.norm1.weight', 'image_encoder.trunk.blocks.12.norm2.bias', 'image_encoder.trunk.blocks.3.norm2.weight', 'image_encoder.trunk.blocks.33.norm2.bias', 'image_encoder.trunk.blocks.21.norm2.weight', 'memory_attention.norm.weight', 'image_encoder.trunk.blocks.10.norm2.bias', 'image_encoder.trunk.blocks.23.norm2.bias', 'sam_mask_decoder.transformer.norm_final_attn.bias', 'image_encoder.trunk.blocks.23.norm1.bias', 'image_encoder.trunk.blocks.19.norm2.bias', 'image_encoder.trunk.blocks.27.norm1.bias', 'image_encoder.trunk.blocks.25.norm2.bias', 'image_encoder.trunk.blocks.44.norm2.weight', 'image_encoder.trunk.blocks.3.norm1.weight', 'image_encoder.trunk.blocks.13.norm1.weight', 'image_encoder.trunk.blocks.8.norm1.bias', 'image_encoder.trunk.blocks.42.norm2.weight', 'image_encoder.trunk.blocks.36.norm2.weight', 'image_encoder.trunk.blocks.14.norm1.bias', 'image_encoder.trunk.blocks.33.norm1.weight', 'image_encoder.trunk.blocks.46.norm2.bias', 'memory_attention.layers.0.norm3.weight', 'memory_attention.layers.2.norm2.bias', 'image_encoder.trunk.blocks.4.norm2.weight', 'image_encoder.trunk.blocks.26.norm2.weight', 'image_encoder.trunk.blocks.31.norm1.bias', 'image_encoder.trunk.blocks.38.norm1.weight', 'image_encoder.trunk.blocks.0.norm2.bias', 'image_encoder.trunk.blocks.40.norm2.weight', 'image_encoder.trunk.blocks.23.norm1.weight', 'image_encoder.trunk.blocks.45.norm1.weight', 'sam_mask_decoder.transformer.layers.1.norm3.weight', 'image_encoder.trunk.blocks.42.norm1.bias', 'image_encoder.trunk.blocks.9.norm1.weight', 'ME.seq_modeling_block.post_norm.weight', 'image_encoder.trunk.blocks.16.norm2.bias', 'image_encoder.trunk.blocks.1.norm1.bias', 'image_encoder.trunk.blocks.34.norm2.bias', 'image_encoder.trunk.blocks.22.norm1.bias', 'image_encoder.trunk.blocks.20.norm2.weight', 'image_encoder.trunk.blocks.41.norm2.weight', 'sam_mask_decoder.transformer.layers.0.norm4.bias', 'image_encoder.trunk.blocks.25.norm1.weight', 'image_encoder.trunk.blocks.35.norm2.weight', 'image_encoder.trunk.blocks.13.norm2.weight', 'image_encoder.trunk.blocks.37.norm1.bias', 'image_encoder.trunk.blocks.2.norm2.weight', 'image_encoder.trunk.blocks.7.norm2.weight', 'image_encoder.trunk.blocks.11.norm1.bias', 'sam_mask_decoder.transformer.layers.0.norm2.bias', 'image_encoder.trunk.blocks.34.norm2.weight', 'image_encoder.trunk.blocks.19.norm1.bias', 'image_encoder.trunk.blocks.4.norm1.bias', 'image_encoder.trunk.blocks.24.norm1.weight', 'memory_attention.layers.1.norm3.bias', 'image_encoder.trunk.blocks.2.norm1.weight', 'image_encoder.trunk.blocks.23.norm2.weight', 'image_encoder.trunk.blocks.16.norm2.weight', 'image_encoder.trunk.blocks.44.norm1.bias', 'image_encoder.trunk.blocks.17.norm1.bias', 'image_encoder.trunk.blocks.0.norm1.bias', 'image_encoder.trunk.blocks.39.norm1.bias', 'image_encoder.trunk.blocks.2.norm2.bias', 'memory_attention.layers.1.norm2.weight', 'image_encoder.trunk.blocks.43.norm2.weight', 'image_encoder.trunk.blocks.45.norm2.bias', 'image_encoder.trunk.blocks.27.norm1.weight', 'memory_attention.layers.0.norm2.bias', 'image_encoder.trunk.blocks.41.norm1.bias', 'sam_mask_decoder.transformer.layers.1.norm4.weight', 'image_encoder.trunk.blocks.47.norm2.weight', 'image_encoder.trunk.blocks.3.norm2.bias', 'image_encoder.trunk.blocks.22.norm1.weight', 'image_encoder.trunk.blocks.26.norm1.bias', 'image_encoder.trunk.blocks.35.norm2.bias', 'image_encoder.trunk.blocks.37.norm1.weight', 'image_encoder.trunk.blocks.39.norm2.bias', 'sam_mask_decoder.transformer.layers.1.norm3.bias', 'image_encoder.trunk.blocks.6.norm1.weight', 'image_encoder.trunk.blocks.36.norm1.weight', 'image_encoder.trunk.blocks.35.norm1.bias', 'memory_attention.layers.3.norm3.bias', 'image_encoder.trunk.blocks.0.norm1.weight', 'image_encoder.trunk.blocks.45.norm2.weight', 'sam_mask_decoder.transformer.layers.0.norm1.weight', 'image_encoder.trunk.blocks.12.norm2.weight', 'image_encoder.trunk.blocks.7.norm2.bias', 'image_encoder.trunk.blocks.0.norm2.weight', 'sam_mask_decoder.transformer.layers.1.norm1.bias', 'image_encoder.trunk.blocks.30.norm1.bias', 'image_encoder.trunk.blocks.9.norm2.weight', 'memory_attention.layers.0.norm1.bias', 'image_encoder.trunk.blocks.14.norm2.weight', 'image_encoder.trunk.blocks.38.norm2.bias', 'image_encoder.trunk.blocks.46.norm1.bias', 'memory_attention.layers.1.norm1.bias', 'image_encoder.trunk.blocks.29.norm1.bias', 'image_encoder.trunk.blocks.30.norm2.weight', 'image_encoder.trunk.blocks.22.norm2.weight', 'sam_mask_decoder.transformer.layers.0.norm4.weight', 'ME.norm.bias', 'image_encoder.trunk.blocks.28.norm1.weight', 'image_encoder.trunk.blocks.11.norm1.weight', 'image_encoder.trunk.blocks.18.norm2.bias', 'image_encoder.trunk.blocks.9.norm2.bias', 'image_encoder.trunk.blocks.21.norm1.weight', 'image_encoder.trunk.blocks.29.norm1.weight', 'image_encoder.trunk.blocks.44.norm2.bias', 'image_encoder.trunk.blocks.13.norm1.bias', 'image_encoder.trunk.blocks.5.norm2.weight', 'image_encoder.trunk.blocks.26.norm2.bias', 'image_encoder.trunk.blocks.24.norm2.bias', 'image_encoder.trunk.blocks.27.norm2.weight', 'image_encoder.trunk.blocks.18.norm1.bias', 'sam_mask_decoder.transformer.layers.1.norm1.weight', 'image_encoder.trunk.blocks.8.norm1.weight', 'image_encoder.trunk.blocks.14.norm1.weight', 'image_encoder.trunk.blocks.45.norm1.bias', 'image_encoder.trunk.blocks.42.norm1.weight', 'image_encoder.trunk.blocks.36.norm1.bias', 'image_encoder.trunk.blocks.32.norm2.weight', 'memory_attention.layers.1.norm2.bias', 'image_encoder.trunk.blocks.2.norm1.bias', 'image_encoder.trunk.blocks.1.norm2.bias', 'image_encoder.trunk.blocks.8.norm2.weight', 'sam_mask_decoder.transformer.norm_final_attn.weight', 'image_encoder.trunk.blocks.22.norm2.bias'} 
INFO 2025-12-09 22:19:02,198 sam2_datasets.py: 125: Dataset mixing probabilities: [1.0]
INFO 2025-12-09 22:19:02,733 trainer.py: 417: Loading pretrained checkpoint from {'_partial_': True, '_target_': 'training.utils.checkpoint_utils.load_state_dict_into_model', 'strict': False, 'ignore_unexpected_keys': None, 'ignore_missing_keys': ['ME*', 'routefuse*'], 'state_dict': {'_target_': 'training.utils.checkpoint_utils.load_checkpoint_and_apply_kernels', 'checkpoint_path': 'checkpoints/sam2.1_hiera_large.pt', 'ckpt_state_dict_keys': ['model']}}
INFO 2025-12-09 22:19:21,308 train_utils.py: 271: Train Epoch: [0][ 0/45] | Batch Time: 18.30 (18.30) | Data Time: 8.17 (8.17) | Mem (GB): 33.00 (33.00/33.00) | Time Elapsed: 00d 00h 00m | Losses/train_all_loss: 1.10e+00 (1.10e+00)
INFO 2025-12-09 22:21:08,266 train_utils.py: 271: Train Epoch: [0][10/45] | Batch Time: 12.93 (11.39) | Data Time: 0.00 (0.74) | Mem (GB): 45.00 (30.82/45.00) | Time Elapsed: 00d 00h 02m | Losses/train_all_loss: 4.60e+00 (2.26e+00)
INFO 2025-12-09 22:22:40,421 train_utils.py: 271: Train Epoch: [0][20/45] | Batch Time: 6.42 (10.35) | Data Time: 0.00 (0.39) | Mem (GB): 15.00 (31.57/45.00) | Time Elapsed: 00d 00h 03m | Losses/train_all_loss: 2.99e-01 (2.29e+00)
INFO 2025-12-09 22:24:43,267 train_utils.py: 271: Train Epoch: [0][30/45] | Batch Time: 6.87 (10.98) | Data Time: 0.00 (0.26) | Mem (GB): 35.00 (33.84/64.00) | Time Elapsed: 00d 00h 05m | Losses/train_all_loss: 6.46e-01 (2.57e+00)
INFO 2025-12-09 22:26:34,579 train_utils.py: 271: Train Epoch: [0][40/45] | Batch Time: 6.90 (11.01) | Data Time: 0.00 (0.20) | Mem (GB): 33.00 (32.41/64.00) | Time Elapsed: 00d 00h 07m | Losses/train_all_loss: 3.15e-01 (2.67e+00)
INFO 2025-12-09 22:27:04,016 trainer.py: 950: Estimated time remaining: 00d 06h 32m
INFO 2025-12-09 22:27:04,018 trainer.py: 892: Synchronizing meters
INFO 2025-12-09 22:27:04,018 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 2.5388275530603197, 'Losses/train_all_loss_mask': 0.03632567290527125, 'Losses/train_all_loss_dice': 1.1467072046465343, 'Losses/train_all_loss_iou': 0.5387116113884581, 'Losses/train_all_loss_class': 0.1268952580736065, 'Losses/train_all_core_loss': 2.5388275530603197, 'Trainer/where': 0.019555555555555555, 'Trainer/epoch': 0, 'Trainer/steps_train': 45}
INFO 2025-12-09 22:27:34,458 train_utils.py: 271: Train Epoch: [1][ 0/45] | Batch Time: 29.30 (29.30) | Data Time: 9.57 (9.57) | Mem (GB): 61.00 (61.00/61.00) | Time Elapsed: 00d 00h 08m | Losses/train_all_loss: 3.59e+00 (3.59e+00)
INFO 2025-12-09 22:29:29,904 train_utils.py: 271: Train Epoch: [1][10/45] | Batch Time: 6.94 (13.16) | Data Time: 0.00 (0.87) | Mem (GB): 29.00 (34.00/61.00) | Time Elapsed: 00d 00h 10m | Losses/train_all_loss: 3.84e-01 (2.36e+00)
INFO 2025-12-09 22:31:21,502 train_utils.py: 271: Train Epoch: [1][20/45] | Batch Time: 17.13 (12.21) | Data Time: 0.00 (0.46) | Mem (GB): 41.00 (33.29/61.00) | Time Elapsed: 00d 00h 12m | Losses/train_all_loss: 2.35e+00 (2.35e+00)
INFO 2025-12-09 22:33:06,202 train_utils.py: 271: Train Epoch: [1][30/45] | Batch Time: 11.86 (11.65) | Data Time: 0.00 (0.31) | Mem (GB): 28.00 (31.61/61.00) | Time Elapsed: 00d 00h 14m | Losses/train_all_loss: 4.38e+00 (2.40e+00)
INFO 2025-12-09 22:34:47,823 train_utils.py: 271: Train Epoch: [1][40/45] | Batch Time: 12.49 (11.28) | Data Time: 0.00 (0.23) | Mem (GB): 45.00 (31.80/61.00) | Time Elapsed: 00d 00h 15m | Losses/train_all_loss: 3.94e+00 (2.23e+00)
INFO 2025-12-09 22:35:37,964 trainer.py: 950: Estimated time remaining: 00d 06h 49m
INFO 2025-12-09 22:35:37,965 trainer.py: 892: Synchronizing meters
INFO 2025-12-09 22:35:37,965 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 2.3330684334039686, 'Losses/train_all_loss_mask': 0.03218771295828952, 'Losses/train_all_loss_dice': 1.1224629723363453, 'Losses/train_all_loss_iou': 0.5057047897742855, 'Losses/train_all_loss_class': 0.06114643768280782, 'Losses/train_all_core_loss': 2.3330684334039686, 'Trainer/where': 0.03955555555555556, 'Trainer/epoch': 1, 'Trainer/steps_train': 90}
INFO 2025-12-09 22:35:55,641 train_utils.py: 271: Train Epoch: [2][ 0/45] | Batch Time: 16.60 (16.60) | Data Time: 9.53 (9.53) | Mem (GB): 27.00 (27.00/27.00) | Time Elapsed: 00d 00h 16m | Losses/train_all_loss: 2.73e-01 (2.73e-01)
INFO 2025-12-09 22:37:35,173 train_utils.py: 271: Train Epoch: [2][10/45] | Batch Time: 17.46 (10.56) | Data Time: 0.00 (0.87) | Mem (GB): 23.00 (23.00/33.00) | Time Elapsed: 00d 00h 18m | Losses/train_all_loss: 5.31e+00 (1.51e+00)
INFO 2025-12-09 22:39:44,468 train_utils.py: 271: Train Epoch: [2][20/45] | Batch Time: 17.42 (11.69) | Data Time: 0.00 (0.45) | Mem (GB): 43.00 (32.48/64.00) | Time Elapsed: 00d 00h 20m | Losses/train_all_loss: 3.58e+00 (2.04e+00)
INFO 2025-12-09 22:41:25,876 train_utils.py: 271: Train Epoch: [2][30/45] | Batch Time: 11.62 (11.19) | Data Time: 0.00 (0.31) | Mem (GB): 19.00 (32.68/64.00) | Time Elapsed: 00d 00h 22m | Losses/train_all_loss: 1.15e+00 (2.26e+00)
INFO 2025-12-09 22:43:22,824 train_utils.py: 271: Train Epoch: [2][40/45] | Batch Time: 7.25 (11.31) | Data Time: 0.00 (0.23) | Mem (GB): 35.00 (33.12/64.00) | Time Elapsed: 00d 00h 24m | Losses/train_all_loss: 1.26e+00 (2.18e+00)
INFO 2025-12-09 22:44:19,496 trainer.py: 950: Estimated time remaining: 00d 06h 46m
INFO 2025-12-09 22:44:19,496 trainer.py: 892: Synchronizing meters
INFO 2025-12-09 22:44:19,497 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 2.2866080274184544, 'Losses/train_all_loss_mask': 0.03182036256314152, 'Losses/train_all_loss_dice': 1.11248180270195, 'Losses/train_all_loss_iou': 0.49118105951282715, 'Losses/train_all_loss_class': 0.04653786160815798, 'Losses/train_all_core_loss': 2.2866080274184544, 'Trainer/where': 0.059555555555555556, 'Trainer/epoch': 2, 'Trainer/steps_train': 135}
INFO 2025-12-09 22:44:35,553 train_utils.py: 271: Train Epoch: [3][ 0/45] | Batch Time: 15.02 (15.02) | Data Time: 7.77 (7.77) | Mem (GB): 33.00 (33.00/33.00) | Time Elapsed: 00d 00h 25m | Losses/train_all_loss: 9.22e-01 (9.22e-01)
INFO 2025-12-09 22:46:41,340 train_utils.py: 271: Train Epoch: [3][10/45] | Batch Time: 6.68 (12.80) | Data Time: 0.00 (0.71) | Mem (GB): 27.00 (32.27/43.00) | Time Elapsed: 00d 00h 27m | Losses/train_all_loss: 2.65e-01 (1.91e+00)
INFO 2025-12-09 22:48:42,556 train_utils.py: 271: Train Epoch: [3][20/45] | Batch Time: 17.66 (12.48) | Data Time: 0.00 (0.37) | Mem (GB): 32.00 (33.29/52.00) | Time Elapsed: 00d 00h 29m | Losses/train_all_loss: 2.03e+00 (2.75e+00)
INFO 2025-12-09 22:50:22,806 train_utils.py: 271: Train Epoch: [3][30/45] | Batch Time: 6.79 (11.69) | Data Time: 0.00 (0.25) | Mem (GB): 35.00 (32.42/64.00) | Time Elapsed: 00d 00h 31m | Losses/train_all_loss: 1.35e+00 (2.37e+00)
INFO 2025-12-09 22:52:33,072 train_utils.py: 271: Train Epoch: [3][40/45] | Batch Time: 6.72 (12.01) | Data Time: 0.00 (0.19) | Mem (GB): 21.00 (33.63/64.00) | Time Elapsed: 00d 00h 33m | Losses/train_all_loss: 6.21e-01 (2.51e+00)
INFO 2025-12-09 22:53:00,893 trainer.py: 950: Estimated time remaining: 00d 06h 38m
INFO 2025-12-09 22:53:00,894 trainer.py: 892: Synchronizing meters
INFO 2025-12-09 22:53:00,894 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 2.3653549661238986, 'Losses/train_all_loss_mask': 0.029078847635537385, 'Losses/train_all_loss_dice': 1.1960522085428238, 'Losses/train_all_loss_iou': 0.5517269043044911, 'Losses/train_all_loss_class': 0.03599889519426035, 'Losses/train_all_core_loss': 2.3653549661238986, 'Trainer/where': 0.07955555555555556, 'Trainer/epoch': 3, 'Trainer/steps_train': 180}
INFO 2025-12-09 22:53:15,605 train_utils.py: 271: Train Epoch: [4][ 0/45] | Batch Time: 13.64 (13.64) | Data Time: 6.63 (6.63) | Mem (GB): 27.00 (27.00/27.00) | Time Elapsed: 00d 00h 34m | Losses/train_all_loss: 2.62e-01 (2.62e-01)
INFO 2025-12-09 22:55:05,951 train_utils.py: 271: Train Epoch: [4][10/45] | Batch Time: 17.14 (11.27) | Data Time: 0.00 (0.60) | Mem (GB): 41.00 (30.36/52.00) | Time Elapsed: 00d 00h 36m | Losses/train_all_loss: 3.78e+00 (1.67e+00)
INFO 2025-12-09 22:57:18,638 train_utils.py: 271: Train Epoch: [4][20/45] | Batch Time: 12.71 (12.22) | Data Time: 0.00 (0.32) | Mem (GB): 53.00 (36.24/62.00) | Time Elapsed: 00d 00h 38m | Losses/train_all_loss: 5.96e+00 (2.46e+00)
INFO 2025-12-09 22:59:09,167 train_utils.py: 271: Train Epoch: [4][30/45] | Batch Time: 6.61 (11.85) | Data Time: 0.00 (0.21) | Mem (GB): 15.00 (33.48/62.00) | Time Elapsed: 00d 00h 40m | Losses/train_all_loss: 3.54e-01 (2.12e+00)
INFO 2025-12-09 23:00:54,434 train_utils.py: 271: Train Epoch: [4][40/45] | Batch Time: 6.81 (11.52) | Data Time: 0.00 (0.16) | Mem (GB): 29.00 (33.59/62.00) | Time Elapsed: 00d 00h 41m | Losses/train_all_loss: 3.52e-01 (2.11e+00)
INFO 2025-12-09 23:01:27,741 trainer.py: 950: Estimated time remaining: 00d 06h 18m
INFO 2025-12-09 23:01:27,742 trainer.py: 892: Synchronizing meters
INFO 2025-12-09 23:01:27,742 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 2.0176586674319372, 'Losses/train_all_loss_mask': 0.02424050795638727, 'Losses/train_all_loss_dice': 1.0591881179147296, 'Losses/train_all_loss_iou': 0.4724102947033114, 'Losses/train_all_loss_class': 0.0012501206212386744, 'Losses/train_all_core_loss': 2.0176586674319372, 'Trainer/where': 0.09955555555555556, 'Trainer/epoch': 4, 'Trainer/steps_train': 225}
INFO 2025-12-09 23:01:56,440 train_utils.py: 271: Train Epoch: [5][ 0/45] | Batch Time: 27.66 (27.66) | Data Time: 20.82 (20.82) | Mem (GB): 35.00 (35.00/35.00) | Time Elapsed: 00d 00h 42m | Losses/train_all_loss: 6.34e-01 (6.34e-01)
INFO 2025-12-09 23:04:12,699 train_utils.py: 271: Train Epoch: [5][10/45] | Batch Time: 17.76 (14.90) | Data Time: 0.00 (1.89) | Mem (GB): 41.00 (34.00/42.00) | Time Elapsed: 00d 00h 45m | Losses/train_all_loss: 1.54e+00 (2.96e+00)
INFO 2025-12-09 23:06:08,094 train_utils.py: 271: Train Epoch: [5][20/45] | Batch Time: 11.99 (13.30) | Data Time: 0.00 (0.99) | Mem (GB): 45.00 (30.86/45.00) | Time Elapsed: 00d 00h 47m | Losses/train_all_loss: 1.36e+01 (3.00e+00)
INFO 2025-12-09 23:08:31,174 train_utils.py: 271: Train Epoch: [5][30/45] | Batch Time: 17.76 (13.63) | Data Time: 0.00 (0.67) | Mem (GB): 54.00 (34.32/61.00) | Time Elapsed: 00d 00h 49m | Losses/train_all_loss: 3.42e+00 (3.13e+00)
INFO 2025-12-09 23:09:40,743 train_utils.py: 271: Train Epoch: [5][40/45] | Batch Time: 7.01 (12.00) | Data Time: 0.00 (0.51) | Mem (GB): 29.00 (33.44/61.00) | Time Elapsed: 00d 00h 50m | Losses/train_all_loss: 1.31e+00 (2.54e+00)
INFO 2025-12-09 23:10:20,174 trainer.py: 950: Estimated time remaining: 00d 06h 29m
INFO 2025-12-09 23:10:20,175 trainer.py: 892: Synchronizing meters
INFO 2025-12-09 23:10:20,175 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 2.4534183147880766, 'Losses/train_all_loss_mask': 0.03163638351899054, 'Losses/train_all_loss_dice': 1.0606850826077991, 'Losses/train_all_loss_iou': 0.49234394120673336, 'Losses/train_all_loss_class': 0.2676616587896161, 'Losses/train_all_core_loss': 2.4534183147880766, 'Trainer/where': 0.11955555555555555, 'Trainer/epoch': 5, 'Trainer/steps_train': 270}
INFO 2025-12-09 23:10:46,229 train_utils.py: 271: Train Epoch: [6][ 0/45] | Batch Time: 25.05 (25.05) | Data Time: 12.69 (12.69) | Mem (GB): 28.00 (28.00/28.00) | Time Elapsed: 00d 00h 51m | Losses/train_all_loss: 1.33e+00 (1.33e+00)
INFO 2025-12-09 23:12:49,075 train_utils.py: 271: Train Epoch: [6][10/45] | Batch Time: 6.85 (13.45) | Data Time: 0.00 (1.15) | Mem (GB): 33.00 (31.64/61.00) | Time Elapsed: 00d 00h 53m | Losses/train_all_loss: 6.44e-01 (1.96e+00)
INFO 2025-12-09 23:15:05,595 train_utils.py: 271: Train Epoch: [6][20/45] | Batch Time: 17.14 (13.54) | Data Time: 0.00 (0.61) | Mem (GB): 43.00 (33.48/61.00) | Time Elapsed: 00d 00h 56m | Losses/train_all_loss: 1.51e+01 (3.14e+00)
INFO 2025-12-09 23:17:00,753 train_utils.py: 271: Train Epoch: [6][30/45] | Batch Time: 12.02 (12.89) | Data Time: 0.00 (0.41) | Mem (GB): 36.00 (34.55/61.00) | Time Elapsed: 00d 00h 58m | Losses/train_all_loss: 1.96e+00 (2.87e+00)
INFO 2025-12-09 23:18:48,942 train_utils.py: 271: Train Epoch: [6][40/45] | Batch Time: 6.83 (12.38) | Data Time: 0.00 (0.31) | Mem (GB): 35.00 (34.12/61.00) | Time Elapsed: 00d 00h 59m | Losses/train_all_loss: 1.86e+00 (2.61e+00)
INFO 2025-12-09 23:19:37,879 trainer.py: 950: Estimated time remaining: 00d 06h 38m
INFO 2025-12-09 23:19:37,880 trainer.py: 892: Synchronizing meters
INFO 2025-12-09 23:19:37,880 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 2.8422818058066897, 'Losses/train_all_loss_mask': 0.03628610211114089, 'Losses/train_all_loss_dice': 1.3776252862479952, 'Losses/train_all_loss_iou': 0.6301850750628445, 'Losses/train_all_loss_class': 0.10874944459593966, 'Losses/train_all_core_loss': 2.8422818058066897, 'Trainer/where': 0.13955555555555554, 'Trainer/epoch': 6, 'Trainer/steps_train': 315}
INFO 2025-12-09 23:19:59,826 train_utils.py: 271: Train Epoch: [7][ 0/45] | Batch Time: 20.95 (20.95) | Data Time: 8.33 (8.33) | Mem (GB): 28.00 (28.00/28.00) | Time Elapsed: 00d 01h 00m | Losses/train_all_loss: 1.96e+00 (1.96e+00)
INFO 2025-12-09 23:21:21,702 train_utils.py: 271: Train Epoch: [7][10/45] | Batch Time: 6.75 (9.35) | Data Time: 0.00 (0.76) | Mem (GB): 15.00 (27.27/35.00) | Time Elapsed: 00d 01h 02m | Losses/train_all_loss: 2.00e-01 (1.04e+00)
INFO 2025-12-09 23:23:07,045 train_utils.py: 271: Train Epoch: [7][20/45] | Batch Time: 18.47 (9.91) | Data Time: 0.00 (0.40) | Mem (GB): 32.00 (28.71/43.00) | Time Elapsed: 00d 01h 04m | Losses/train_all_loss: 4.98e+00 (1.46e+00)
INFO 2025-12-09 23:25:16,011 train_utils.py: 271: Train Epoch: [7][30/45] | Batch Time: 7.28 (10.88) | Data Time: 0.00 (0.27) | Mem (GB): 29.00 (29.94/52.00) | Time Elapsed: 00d 01h 06m | Losses/train_all_loss: 3.97e-01 (1.63e+00)
INFO 2025-12-09 23:27:29,759 train_utils.py: 271: Train Epoch: [7][40/45] | Batch Time: 18.25 (11.48) | Data Time: 0.00 (0.20) | Mem (GB): 42.00 (32.27/64.00) | Time Elapsed: 00d 01h 08m | Losses/train_all_loss: 1.31e+01 (2.05e+00)
INFO 2025-12-09 23:27:59,547 trainer.py: 950: Estimated time remaining: 00d 05h 49m
INFO 2025-12-09 23:27:59,547 trainer.py: 892: Synchronizing meters
INFO 2025-12-09 23:27:59,548 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 1.951804553469022, 'Losses/train_all_loss_mask': 0.02438490327137212, 'Losses/train_all_loss_dice': 1.005285828643375, 'Losses/train_all_loss_iou': 0.42447951169063647, 'Losses/train_all_loss_class': 0.03434107657446642, 'Losses/train_all_core_loss': 1.951804553469022, 'Trainer/where': 0.15955555555555556, 'Trainer/epoch': 7, 'Trainer/steps_train': 360}
INFO 2025-12-09 23:28:15,466 train_utils.py: 271: Train Epoch: [8][ 0/45] | Batch Time: 14.79 (14.79) | Data Time: 7.36 (7.36) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 01h 09m | Losses/train_all_loss: 2.73e-01 (2.73e-01)
INFO 2025-12-09 23:30:15,196 train_utils.py: 271: Train Epoch: [8][10/45] | Batch Time: 18.36 (12.23) | Data Time: 0.00 (0.90) | Mem (GB): 43.00 (30.00/51.00) | Time Elapsed: 00d 01h 11m | Losses/train_all_loss: 1.70e+00 (2.06e+00)
INFO 2025-12-09 23:31:54,824 train_utils.py: 271: Train Epoch: [8][20/45] | Batch Time: 18.66 (11.15) | Data Time: 0.00 (0.47) | Mem (GB): 43.00 (30.24/51.00) | Time Elapsed: 00d 01h 12m | Losses/train_all_loss: 6.98e+00 (1.92e+00)
INFO 2025-12-09 23:33:40,117 train_utils.py: 271: Train Epoch: [8][30/45] | Batch Time: 6.99 (10.95) | Data Time: 0.00 (0.32) | Mem (GB): 27.00 (31.42/51.00) | Time Elapsed: 00d 01h 14m | Losses/train_all_loss: 7.24e-01 (1.83e+00)
INFO 2025-12-09 23:35:53,683 train_utils.py: 271: Train Epoch: [8][40/45] | Batch Time: 12.81 (11.54) | Data Time: 0.00 (0.24) | Mem (GB): 36.00 (32.95/64.00) | Time Elapsed: 00d 01h 16m | Losses/train_all_loss: 2.75e+00 (1.79e+00)
INFO 2025-12-09 23:36:40,017 trainer.py: 950: Estimated time remaining: 00d 05h 54m
INFO 2025-12-09 23:36:40,018 trainer.py: 892: Synchronizing meters
INFO 2025-12-09 23:36:40,018 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 1.8085472911596299, 'Losses/train_all_loss_mask': 0.020106769487675695, 'Losses/train_all_loss_dice': 0.931510939862993, 'Losses/train_all_loss_iou': 0.426399232322971, 'Losses/train_all_loss_class': 0.048501734174653026, 'Losses/train_all_core_loss': 1.8085472911596299, 'Trainer/where': 0.17955555555555555, 'Trainer/epoch': 8, 'Trainer/steps_train': 405}
INFO 2025-12-09 23:37:15,970 train_utils.py: 271: Train Epoch: [9][ 0/45] | Batch Time: 34.87 (34.87) | Data Time: 15.85 (15.85) | Mem (GB): 33.00 (33.00/33.00) | Time Elapsed: 00d 01h 18m | Losses/train_all_loss: 4.49e+00 (4.49e+00)
INFO 2025-12-09 23:39:07,502 train_utils.py: 271: Train Epoch: [9][10/45] | Batch Time: 18.23 (13.31) | Data Time: 0.00 (1.44) | Mem (GB): 23.00 (31.91/53.00) | Time Elapsed: 00d 01h 20m | Losses/train_all_loss: 2.40e+00 (2.55e+00)
INFO 2025-12-09 23:40:36,237 train_utils.py: 271: Train Epoch: [9][20/45] | Batch Time: 7.35 (11.20) | Data Time: 0.00 (0.76) | Mem (GB): 42.00 (31.05/53.00) | Time Elapsed: 00d 01h 21m | Losses/train_all_loss: 1.78e+00 (1.76e+00)
INFO 2025-12-09 23:42:44,120 train_utils.py: 271: Train Epoch: [9][30/45] | Batch Time: 7.04 (11.71) | Data Time: 0.00 (0.51) | Mem (GB): 27.00 (32.52/53.00) | Time Elapsed: 00d 01h 23m | Losses/train_all_loss: 2.87e-01 (1.95e+00)
INFO 2025-12-09 23:45:13,370 train_utils.py: 271: Train Epoch: [9][40/45] | Batch Time: 7.24 (12.49) | Data Time: 0.00 (0.39) | Mem (GB): 42.00 (32.59/53.00) | Time Elapsed: 00d 01h 26m | Losses/train_all_loss: 3.86e-01 (2.27e+00)
INFO 2025-12-09 23:46:16,872 trainer.py: 950: Estimated time remaining: 00d 06h 23m
INFO 2025-12-09 23:46:16,873 trainer.py: 892: Synchronizing meters
INFO 2025-12-09 23:46:16,873 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 2.613400468892521, 'Losses/train_all_loss_mask': 0.033543435375516614, 'Losses/train_all_loss_dice': 1.3253244459629059, 'Losses/train_all_loss_iou': 0.6060279819907414, 'Losses/train_all_loss_class': 0.011179370215963443, 'Losses/train_all_core_loss': 2.613400468892521, 'Trainer/where': 0.19955555555555557, 'Trainer/epoch': 9, 'Trainer/steps_train': 450}
INFO 2025-12-09 23:46:57,102 train_utils.py: 271: Train Epoch: [10][ 0/45] | Batch Time: 39.16 (39.16) | Data Time: 20.00 (20.00) | Mem (GB): 61.00 (61.00/61.00) | Time Elapsed: 00d 01h 27m | Losses/train_all_loss: 4.94e+00 (4.94e+00)
INFO 2025-12-09 23:48:35,972 train_utils.py: 271: Train Epoch: [10][10/45] | Batch Time: 6.87 (12.55) | Data Time: 0.00 (1.82) | Mem (GB): 14.00 (31.91/61.00) | Time Elapsed: 00d 01h 29m | Losses/train_all_loss: 2.88e-01 (2.20e+00)
INFO 2025-12-09 23:50:55,865 train_utils.py: 271: Train Epoch: [10][20/45] | Batch Time: 18.95 (13.23) | Data Time: 0.00 (0.95) | Mem (GB): 51.00 (34.05/61.00) | Time Elapsed: 00d 01h 31m | Losses/train_all_loss: 2.72e+00 (2.18e+00)
INFO 2025-12-09 23:52:41,110 train_utils.py: 271: Train Epoch: [10][30/45] | Batch Time: 6.99 (12.36) | Data Time: 0.00 (0.65) | Mem (GB): 27.00 (33.23/64.00) | Time Elapsed: 00d 01h 33m | Losses/train_all_loss: 3.10e-01 (1.82e+00)
INFO 2025-12-09 23:55:05,180 train_utils.py: 271: Train Epoch: [10][40/45] | Batch Time: 18.29 (12.86) | Data Time: 0.00 (0.49) | Mem (GB): 33.00 (34.39/64.00) | Time Elapsed: 00d 01h 36m | Losses/train_all_loss: 3.75e+00 (2.23e+00)
INFO 2025-12-09 23:55:45,647 trainer.py: 950: Estimated time remaining: 00d 06h 08m
INFO 2025-12-09 23:55:45,647 trainer.py: 892: Synchronizing meters
INFO 2025-12-09 23:55:45,647 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 2.1138146112362546, 'Losses/train_all_loss_mask': 0.030273252316854068, 'Losses/train_all_loss_dice': 1.0144616908497281, 'Losses/train_all_loss_iou': 0.39658684900237456, 'Losses/train_all_loss_class': 0.09730107960557312, 'Losses/train_all_core_loss': 2.1138146112362546, 'Trainer/where': 0.21955555555555556, 'Trainer/epoch': 10, 'Trainer/steps_train': 495}
INFO 2025-12-09 23:56:04,303 train_utils.py: 271: Train Epoch: [11][ 0/45] | Batch Time: 17.58 (17.58) | Data Time: 9.86 (9.86) | Mem (GB): 39.00 (39.00/39.00) | Time Elapsed: 00d 01h 37m | Losses/train_all_loss: 4.86e-01 (4.86e-01)
INFO 2025-12-09 23:58:01,383 train_utils.py: 271: Train Epoch: [11][10/45] | Batch Time: 6.87 (12.24) | Data Time: 0.00 (1.84) | Mem (GB): 15.00 (32.55/62.00) | Time Elapsed: 00d 01h 39m | Losses/train_all_loss: 4.85e-01 (1.41e+00)
INFO 2025-12-09 23:59:59,864 train_utils.py: 271: Train Epoch: [11][20/45] | Batch Time: 7.39 (12.05) | Data Time: 0.00 (0.97) | Mem (GB): 42.00 (32.38/62.00) | Time Elapsed: 00d 01h 40m | Losses/train_all_loss: 1.48e+00 (2.05e+00)
INFO 2025-12-10 00:01:47,531 train_utils.py: 271: Train Epoch: [11][30/45] | Batch Time: 18.93 (11.64) | Data Time: 0.00 (0.65) | Mem (GB): 32.00 (32.71/62.00) | Time Elapsed: 00d 01h 42m | Losses/train_all_loss: 4.13e+00 (2.00e+00)
INFO 2025-12-10 00:04:08,825 train_utils.py: 271: Train Epoch: [11][40/45] | Batch Time: 18.69 (12.25) | Data Time: 0.00 (0.49) | Mem (GB): 43.00 (33.39/62.00) | Time Elapsed: 00d 01h 45m | Losses/train_all_loss: 1.01e+01 (2.14e+00)
INFO 2025-12-10 00:05:13,398 trainer.py: 950: Estimated time remaining: 00d 05h 58m
INFO 2025-12-10 00:05:13,399 trainer.py: 892: Synchronizing meters
INFO 2025-12-10 00:05:13,399 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 2.1882825358046425, 'Losses/train_all_loss_mask': 0.03154180384654966, 'Losses/train_all_loss_dice': 1.0564582139253615, 'Losses/train_all_loss_iou': 0.43409394464559026, 'Losses/train_all_loss_class': 0.06689429595667935, 'Losses/train_all_core_loss': 2.1882825358046425, 'Trainer/where': 0.23955555555555555, 'Trainer/epoch': 11, 'Trainer/steps_train': 540}
INFO 2025-12-10 00:05:53,349 train_utils.py: 271: Train Epoch: [12][ 0/45] | Batch Time: 38.89 (38.89) | Data Time: 19.54 (19.54) | Mem (GB): 43.00 (43.00/43.00) | Time Elapsed: 00d 01h 46m | Losses/train_all_loss: 2.34e+00 (2.34e+00)
INFO 2025-12-10 00:07:39,394 train_utils.py: 271: Train Epoch: [12][10/45] | Batch Time: 7.07 (13.18) | Data Time: 0.00 (1.78) | Mem (GB): 21.00 (32.82/61.00) | Time Elapsed: 00d 01h 48m | Losses/train_all_loss: 3.09e-01 (1.62e+00)
INFO 2025-12-10 00:09:43,435 train_utils.py: 271: Train Epoch: [12][20/45] | Batch Time: 18.59 (12.81) | Data Time: 0.00 (0.93) | Mem (GB): 41.00 (33.57/61.00) | Time Elapsed: 00d 01h 50m | Losses/train_all_loss: 2.66e+00 (1.79e+00)
INFO 2025-12-10 00:12:05,215 train_utils.py: 271: Train Epoch: [12][30/45] | Batch Time: 18.81 (13.25) | Data Time: 0.00 (0.63) | Mem (GB): 23.00 (34.68/61.00) | Time Elapsed: 00d 01h 53m | Losses/train_all_loss: 1.12e+00 (2.05e+00)
INFO 2025-12-10 00:14:31,052 train_utils.py: 271: Train Epoch: [12][40/45] | Batch Time: 18.67 (13.58) | Data Time: 0.00 (0.48) | Mem (GB): 52.00 (35.02/61.00) | Time Elapsed: 00d 01h 55m | Losses/train_all_loss: 3.42e+00 (2.42e+00)
INFO 2025-12-10 00:15:17,874 trainer.py: 950: Estimated time remaining: 00d 06h 11m
INFO 2025-12-10 00:15:17,875 trainer.py: 892: Synchronizing meters
INFO 2025-12-10 00:15:17,875 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 2.337684478362401, 'Losses/train_all_loss_mask': 0.03216410643007192, 'Losses/train_all_loss_dice': 1.1735013282961315, 'Losses/train_all_loss_iou': 0.47506908939944376, 'Losses/train_all_loss_class': 0.04583194566693069, 'Losses/train_all_core_loss': 2.337684478362401, 'Trainer/where': 0.25955555555555554, 'Trainer/epoch': 12, 'Trainer/steps_train': 585}
INFO 2025-12-10 00:15:46,077 train_utils.py: 271: Train Epoch: [13][ 0/45] | Batch Time: 27.15 (27.15) | Data Time: 7.62 (7.62) | Mem (GB): 33.00 (33.00/33.00) | Time Elapsed: 00d 01h 56m | Losses/train_all_loss: 2.01e+00 (2.01e+00)
INFO 2025-12-10 00:18:01,007 train_utils.py: 271: Train Epoch: [13][10/45] | Batch Time: 18.71 (14.73) | Data Time: 0.00 (0.69) | Mem (GB): 22.00 (31.45/54.00) | Time Elapsed: 00d 01h 59m | Losses/train_all_loss: 1.34e+00 (1.50e+00)
INFO 2025-12-10 00:20:10,047 train_utils.py: 271: Train Epoch: [13][20/45] | Batch Time: 18.40 (13.86) | Data Time: 0.00 (0.36) | Mem (GB): 22.00 (33.33/54.00) | Time Elapsed: 00d 02h 01m | Losses/train_all_loss: 1.51e+00 (1.68e+00)
INFO 2025-12-10 00:21:43,666 train_utils.py: 271: Train Epoch: [13][30/45] | Batch Time: 6.97 (12.41) | Data Time: 0.00 (0.25) | Mem (GB): 27.00 (31.58/54.00) | Time Elapsed: 00d 02h 02m | Losses/train_all_loss: 5.87e-01 (1.57e+00)
INFO 2025-12-10 00:23:40,871 train_utils.py: 271: Train Epoch: [13][40/45] | Batch Time: 7.14 (12.24) | Data Time: 0.00 (0.19) | Mem (GB): 27.00 (33.24/61.00) | Time Elapsed: 00d 02h 04m | Losses/train_all_loss: 5.40e-01 (1.65e+00)
INFO 2025-12-10 00:24:21,625 trainer.py: 950: Estimated time remaining: 00d 05h 24m
INFO 2025-12-10 00:24:21,626 trainer.py: 892: Synchronizing meters
INFO 2025-12-10 00:24:21,626 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 1.6984215888712142, 'Losses/train_all_loss_mask': 0.02151395898933212, 'Losses/train_all_loss_dice': 0.92038524515099, 'Losses/train_all_loss_iou': 0.3477052085929447, 'Losses/train_all_loss_class': 5.198484425300206e-05, 'Losses/train_all_core_loss': 1.6984215888712142, 'Trainer/where': 0.27955555555555556, 'Trainer/epoch': 13, 'Trainer/steps_train': 630}
INFO 2025-12-10 00:24:38,816 train_utils.py: 271: Train Epoch: [14][ 0/45] | Batch Time: 16.15 (16.15) | Data Time: 8.55 (8.55) | Mem (GB): 27.00 (27.00/27.00) | Time Elapsed: 00d 02h 05m | Losses/train_all_loss: 5.91e-01 (5.91e-01)
INFO 2025-12-10 00:27:10,323 train_utils.py: 271: Train Epoch: [14][10/45] | Batch Time: 18.56 (15.24) | Data Time: 0.00 (1.09) | Mem (GB): 23.00 (33.00/62.00) | Time Elapsed: 00d 02h 08m | Losses/train_all_loss: 1.77e+00 (2.52e+00)
INFO 2025-12-10 00:29:26,221 train_utils.py: 271: Train Epoch: [14][20/45] | Batch Time: 7.15 (14.46) | Data Time: 0.00 (0.57) | Mem (GB): 22.00 (34.24/62.00) | Time Elapsed: 00d 02h 10m | Losses/train_all_loss: 5.30e-01 (2.49e+00)
INFO 2025-12-10 00:31:25,344 train_utils.py: 271: Train Epoch: [14][30/45] | Batch Time: 7.42 (13.63) | Data Time: 0.00 (0.39) | Mem (GB): 35.00 (33.94/62.00) | Time Elapsed: 00d 02h 12m | Losses/train_all_loss: 3.08e-01 (2.24e+00)
INFO 2025-12-10 00:33:18,023 train_utils.py: 271: Train Epoch: [14][40/45] | Batch Time: 7.15 (13.06) | Data Time: 0.00 (0.29) | Mem (GB): 22.00 (33.63/62.00) | Time Elapsed: 00d 02h 14m | Losses/train_all_loss: 4.00e-01 (2.18e+00)
INFO 2025-12-10 00:34:11,537 trainer.py: 950: Estimated time remaining: 00d 05h 42m
INFO 2025-12-10 00:34:11,538 trainer.py: 892: Synchronizing meters
INFO 2025-12-10 00:34:11,538 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 2.254053039683236, 'Losses/train_all_loss_mask': 0.024925862149231964, 'Losses/train_all_loss_dice': 1.2045457945929634, 'Losses/train_all_loss_iou': 0.4589637615614467, 'Losses/train_all_loss_class': 0.09202624620826066, 'Losses/train_all_core_loss': 2.254053039683236, 'Trainer/where': 0.2995555555555556, 'Trainer/epoch': 14, 'Trainer/steps_train': 675}
INFO 2025-12-10 00:34:40,985 train_utils.py: 271: Train Epoch: [15][ 0/45] | Batch Time: 28.34 (28.34) | Data Time: 8.44 (8.44) | Mem (GB): 41.00 (41.00/41.00) | Time Elapsed: 00d 02h 15m | Losses/train_all_loss: 1.83e+00 (1.83e+00)
INFO 2025-12-10 00:36:39,109 train_utils.py: 271: Train Epoch: [15][10/45] | Batch Time: 19.01 (13.32) | Data Time: 0.00 (0.77) | Mem (GB): 32.00 (28.18/43.00) | Time Elapsed: 00d 02h 17m | Losses/train_all_loss: 4.83e+00 (1.61e+00)
INFO 2025-12-10 00:38:14,257 train_utils.py: 271: Train Epoch: [15][20/45] | Batch Time: 7.13 (11.51) | Data Time: 0.00 (0.40) | Mem (GB): 22.00 (29.62/62.00) | Time Elapsed: 00d 02h 19m | Losses/train_all_loss: 1.74e+00 (1.67e+00)
INFO 2025-12-10 00:40:23,843 train_utils.py: 271: Train Epoch: [15][30/45] | Batch Time: 18.61 (11.97) | Data Time: 0.00 (0.27) | Mem (GB): 41.00 (31.74/64.00) | Time Elapsed: 00d 02h 21m | Losses/train_all_loss: 2.58e+00 (1.96e+00)
INFO 2025-12-10 00:42:21,889 train_utils.py: 271: Train Epoch: [15][40/45] | Batch Time: 18.98 (11.93) | Data Time: 0.00 (0.21) | Mem (GB): 51.00 (32.20/64.00) | Time Elapsed: 00d 02h 23m | Losses/train_all_loss: 2.40e+00 (1.88e+00)
INFO 2025-12-10 00:43:09,276 trainer.py: 950: Estimated time remaining: 00d 05h 03m
INFO 2025-12-10 00:43:09,277 trainer.py: 892: Synchronizing meters
INFO 2025-12-10 00:43:09,277 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 1.9167199386490716, 'Losses/train_all_loss_mask': 0.02178998961009913, 'Losses/train_all_loss_dice': 1.0025076831380526, 'Losses/train_all_loss_iou': 0.4230187296039528, 'Losses/train_all_loss_class': 0.055393716920866906, 'Losses/train_all_core_loss': 1.9167199386490716, 'Trainer/where': 0.31955555555555554, 'Trainer/epoch': 15, 'Trainer/steps_train': 720}
INFO 2025-12-10 00:43:30,050 train_utils.py: 271: Train Epoch: [16][ 0/45] | Batch Time: 19.71 (19.71) | Data Time: 12.45 (12.45) | Mem (GB): 15.00 (15.00/15.00) | Time Elapsed: 00d 02h 24m | Losses/train_all_loss: 4.75e-01 (4.75e-01)
INFO 2025-12-10 00:45:33,432 train_utils.py: 271: Train Epoch: [16][10/45] | Batch Time: 7.15 (13.01) | Data Time: 0.00 (1.13) | Mem (GB): 35.00 (29.64/45.00) | Time Elapsed: 00d 02h 26m | Losses/train_all_loss: 5.84e-01 (1.36e+00)
INFO 2025-12-10 00:47:42,248 train_utils.py: 271: Train Epoch: [16][20/45] | Batch Time: 7.05 (12.95) | Data Time: 0.00 (0.59) | Mem (GB): 27.00 (30.48/45.00) | Time Elapsed: 00d 02h 28m | Losses/train_all_loss: 5.11e-01 (1.49e+00)
INFO 2025-12-10 00:49:40,099 train_utils.py: 271: Train Epoch: [16][30/45] | Batch Time: 7.09 (12.57) | Data Time: 0.00 (0.40) | Mem (GB): 27.00 (32.19/64.00) | Time Elapsed: 00d 02h 30m | Losses/train_all_loss: 3.12e-01 (1.82e+00)
INFO 2025-12-10 00:51:14,784 train_utils.py: 271: Train Epoch: [16][40/45] | Batch Time: 7.10 (11.82) | Data Time: 0.00 (0.30) | Mem (GB): 27.00 (32.34/64.00) | Time Elapsed: 00d 02h 32m | Losses/train_all_loss: 4.58e-01 (1.80e+00)
INFO 2025-12-10 00:51:55,669 trainer.py: 950: Estimated time remaining: 00d 04h 48m
INFO 2025-12-10 00:51:55,670 trainer.py: 892: Synchronizing meters
INFO 2025-12-10 00:51:55,670 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 1.772740951842732, 'Losses/train_all_loss_mask': 0.023920856359311276, 'Losses/train_all_loss_dice': 0.8495633982949786, 'Losses/train_all_loss_iou': 0.38188627043532003, 'Losses/train_all_loss_class': 0.06287418844680441, 'Losses/train_all_core_loss': 1.772740951842732, 'Trainer/where': 0.33955555555555555, 'Trainer/epoch': 16, 'Trainer/steps_train': 765}
INFO 2025-12-10 00:52:27,115 train_utils.py: 271: Train Epoch: [17][ 0/45] | Batch Time: 30.36 (30.36) | Data Time: 17.26 (17.26) | Mem (GB): 36.00 (36.00/36.00) | Time Elapsed: 00d 02h 33m | Losses/train_all_loss: 1.74e+00 (1.74e+00)
INFO 2025-12-10 00:54:29,507 train_utils.py: 271: Train Epoch: [17][10/45] | Batch Time: 18.52 (13.89) | Data Time: 0.00 (1.57) | Mem (GB): 52.00 (35.64/54.00) | Time Elapsed: 00d 02h 35m | Losses/train_all_loss: 7.21e+00 (3.18e+00)
INFO 2025-12-10 00:56:09,479 train_utils.py: 271: Train Epoch: [17][20/45] | Batch Time: 7.36 (12.03) | Data Time: 0.00 (0.82) | Mem (GB): 39.00 (33.29/54.00) | Time Elapsed: 00d 02h 37m | Losses/train_all_loss: 7.23e-01 (2.24e+00)
INFO 2025-12-10 00:58:28,695 train_utils.py: 271: Train Epoch: [17][30/45] | Batch Time: 18.43 (12.64) | Data Time: 0.00 (0.56) | Mem (GB): 52.00 (34.03/64.00) | Time Elapsed: 00d 02h 39m | Losses/train_all_loss: 5.58e+00 (2.21e+00)
INFO 2025-12-10 01:00:07,210 train_utils.py: 271: Train Epoch: [17][40/45] | Batch Time: 17.76 (11.96) | Data Time: 0.00 (0.42) | Mem (GB): 41.00 (33.32/64.00) | Time Elapsed: 00d 02h 41m | Losses/train_all_loss: 3.60e+00 (2.09e+00)
INFO 2025-12-10 01:01:21,368 trainer.py: 950: Estimated time remaining: 00d 05h 00m
INFO 2025-12-10 01:01:21,369 trainer.py: 892: Synchronizing meters
INFO 2025-12-10 01:01:21,369 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 2.3271634373399945, 'Losses/train_all_loss_mask': 0.031091652836443648, 'Losses/train_all_loss_dice': 1.215155662761794, 'Losses/train_all_loss_iou': 0.47927944411834084, 'Losses/train_all_loss_class': 0.010895274804588132, 'Losses/train_all_core_loss': 2.3271634373399945, 'Trainer/where': 0.3595555555555556, 'Trainer/epoch': 17, 'Trainer/steps_train': 810}
INFO 2025-12-10 01:01:48,682 train_utils.py: 271: Train Epoch: [18][ 0/45] | Batch Time: 26.16 (26.16) | Data Time: 6.67 (6.67) | Mem (GB): 52.00 (52.00/52.00) | Time Elapsed: 00d 02h 42m | Losses/train_all_loss: 3.66e+00 (3.66e+00)
INFO 2025-12-10 01:03:49,130 train_utils.py: 271: Train Epoch: [18][10/45] | Batch Time: 19.14 (13.33) | Data Time: 0.00 (0.61) | Mem (GB): 54.00 (39.82/61.00) | Time Elapsed: 00d 02h 44m | Losses/train_all_loss: 6.62e+00 (3.01e+00)
INFO 2025-12-10 01:05:53,949 train_utils.py: 271: Train Epoch: [18][20/45] | Batch Time: 13.11 (12.92) | Data Time: 0.00 (0.32) | Mem (GB): 45.00 (36.29/64.00) | Time Elapsed: 00d 02h 46m | Losses/train_all_loss: 5.78e+00 (2.50e+00)
INFO 2025-12-10 01:07:51,445 train_utils.py: 271: Train Epoch: [18][30/45] | Batch Time: 12.73 (12.55) | Data Time: 0.00 (0.22) | Mem (GB): 28.00 (34.35/64.00) | Time Elapsed: 00d 02h 48m | Losses/train_all_loss: 1.74e+00 (2.49e+00)
INFO 2025-12-10 01:10:09,685 train_utils.py: 271: Train Epoch: [18][40/45] | Batch Time: 7.39 (12.86) | Data Time: 0.00 (0.16) | Mem (GB): 35.00 (34.12/64.00) | Time Elapsed: 00d 02h 51m | Losses/train_all_loss: 1.07e+00 (2.38e+00)
INFO 2025-12-10 01:10:44,582 trainer.py: 950: Estimated time remaining: 00d 04h 49m
INFO 2025-12-10 01:10:44,583 trainer.py: 892: Synchronizing meters
INFO 2025-12-10 01:10:44,583 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 2.2587036649386087, 'Losses/train_all_loss_mask': 0.027028367575258016, 'Losses/train_all_loss_dice': 1.1774300194448895, 'Losses/train_all_loss_iou': 0.4909979679104355, 'Losses/train_all_loss_class': 0.04970828940932853, 'Losses/train_all_core_loss': 2.2587036649386087, 'Trainer/where': 0.37955555555555553, 'Trainer/epoch': 18, 'Trainer/steps_train': 855}
INFO 2025-12-10 01:11:12,654 train_utils.py: 271: Train Epoch: [19][ 0/45] | Batch Time: 27.00 (27.00) | Data Time: 8.08 (8.08) | Mem (GB): 41.00 (41.00/41.00) | Time Elapsed: 00d 02h 52m | Losses/train_all_loss: 1.79e+00 (1.79e+00)
INFO 2025-12-10 01:13:15,024 train_utils.py: 271: Train Epoch: [19][10/45] | Batch Time: 18.14 (13.58) | Data Time: 0.00 (0.74) | Mem (GB): 41.00 (32.45/54.00) | Time Elapsed: 00d 02h 54m | Losses/train_all_loss: 1.27e+00 (1.96e+00)
INFO 2025-12-10 01:15:16,418 train_utils.py: 271: Train Epoch: [19][20/45] | Batch Time: 18.34 (12.89) | Data Time: 0.00 (0.39) | Mem (GB): 41.00 (30.81/54.00) | Time Elapsed: 00d 02h 56m | Losses/train_all_loss: 2.49e+00 (1.62e+00)
INFO 2025-12-10 01:17:41,692 train_utils.py: 271: Train Epoch: [19][30/45] | Batch Time: 12.74 (13.42) | Data Time: 0.00 (0.26) | Mem (GB): 28.00 (32.68/61.00) | Time Elapsed: 00d 02h 58m | Losses/train_all_loss: 1.36e+00 (2.31e+00)
INFO 2025-12-10 01:19:21,135 train_utils.py: 271: Train Epoch: [19][40/45] | Batch Time: 6.94 (12.57) | Data Time: 0.00 (0.20) | Mem (GB): 21.00 (33.15/61.00) | Time Elapsed: 00d 03h 00m | Losses/train_all_loss: 5.73e-01 (2.16e+00)
INFO 2025-12-10 01:20:12,930 trainer.py: 950: Estimated time remaining: 00d 04h 43m
INFO 2025-12-10 01:20:12,931 trainer.py: 892: Synchronizing meters
INFO 2025-12-10 01:20:12,931 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 2.0867264211177825, 'Losses/train_all_loss_mask': 0.025688872563963135, 'Losses/train_all_loss_dice': 1.0984701073831982, 'Losses/train_all_loss_iou': 0.43217102881107067, 'Losses/train_all_loss_class': 0.04230786197826935, 'Losses/train_all_core_loss': 2.0867264211177825, 'Trainer/where': 0.39955555555555555, 'Trainer/epoch': 19, 'Trainer/steps_train': 900}
INFO 2025-12-10 01:20:42,140 train_utils.py: 271: Train Epoch: [20][ 0/45] | Batch Time: 28.14 (28.14) | Data Time: 14.98 (14.98) | Mem (GB): 45.00 (45.00/45.00) | Time Elapsed: 00d 03h 01m | Losses/train_all_loss: 1.72e+00 (1.72e+00)
INFO 2025-12-10 01:22:39,064 train_utils.py: 271: Train Epoch: [20][10/45] | Batch Time: 18.49 (13.19) | Data Time: 0.00 (1.36) | Mem (GB): 43.00 (33.27/52.00) | Time Elapsed: 00d 03h 03m | Losses/train_all_loss: 1.82e+00 (1.57e+00)
INFO 2025-12-10 01:24:35,605 train_utils.py: 271: Train Epoch: [20][20/45] | Batch Time: 7.20 (12.46) | Data Time: 0.00 (0.71) | Mem (GB): 27.00 (31.81/52.00) | Time Elapsed: 00d 03h 05m | Losses/train_all_loss: 6.35e-01 (2.04e+00)
INFO 2025-12-10 01:27:11,592 train_utils.py: 271: Train Epoch: [20][30/45] | Batch Time: 12.90 (13.47) | Data Time: 0.00 (0.48) | Mem (GB): 45.00 (34.71/64.00) | Time Elapsed: 00d 03h 08m | Losses/train_all_loss: 1.67e+00 (2.24e+00)
INFO 2025-12-10 01:29:13,137 train_utils.py: 271: Train Epoch: [20][40/45] | Batch Time: 18.07 (13.15) | Data Time: 0.00 (0.37) | Mem (GB): 23.00 (33.32/64.00) | Time Elapsed: 00d 03h 10m | Losses/train_all_loss: 9.90e-01 (2.11e+00)
INFO 2025-12-10 01:30:05,466 trainer.py: 950: Estimated time remaining: 00d 04h 45m
INFO 2025-12-10 01:30:05,467 trainer.py: 892: Synchronizing meters
INFO 2025-12-10 01:30:05,468 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 2.180792898270819, 'Losses/train_all_loss_mask': 0.03184586723024647, 'Losses/train_all_loss_dice': 1.0942104584640926, 'Losses/train_all_loss_iou': 0.44027169831097124, 'Losses/train_all_loss_class': 0.009393357856569863, 'Losses/train_all_core_loss': 2.180792898270819, 'Trainer/where': 0.41955555555555557, 'Trainer/epoch': 20, 'Trainer/steps_train': 945}
INFO 2025-12-10 01:30:27,566 train_utils.py: 271: Train Epoch: [21][ 0/45] | Batch Time: 21.03 (21.03) | Data Time: 7.51 (7.51) | Mem (GB): 36.00 (36.00/36.00) | Time Elapsed: 00d 03h 11m | Losses/train_all_loss: 8.96e+00 (8.96e+00)
INFO 2025-12-10 01:32:41,574 train_utils.py: 271: Train Epoch: [21][10/45] | Batch Time: 18.43 (14.09) | Data Time: 0.00 (0.68) | Mem (GB): 42.00 (35.27/53.00) | Time Elapsed: 00d 03h 13m | Losses/train_all_loss: 5.81e+00 (2.77e+00)
INFO 2025-12-10 01:35:07,820 train_utils.py: 271: Train Epoch: [21][20/45] | Batch Time: 18.58 (14.35) | Data Time: 0.00 (0.36) | Mem (GB): 32.00 (35.90/61.00) | Time Elapsed: 00d 03h 16m | Losses/train_all_loss: 2.07e+00 (2.75e+00)
INFO 2025-12-10 01:36:59,364 train_utils.py: 271: Train Epoch: [21][30/45] | Batch Time: 7.22 (13.32) | Data Time: 0.00 (0.24) | Mem (GB): 39.00 (35.71/61.00) | Time Elapsed: 00d 03h 17m | Losses/train_all_loss: 3.45e-01 (2.47e+00)
INFO 2025-12-10 01:38:43,916 train_utils.py: 271: Train Epoch: [21][40/45] | Batch Time: 7.25 (12.62) | Data Time: 0.00 (0.18) | Mem (GB): 27.00 (34.20/61.00) | Time Elapsed: 00d 03h 19m | Losses/train_all_loss: 6.21e-01 (2.39e+00)
INFO 2025-12-10 01:39:24,390 trainer.py: 950: Estimated time remaining: 00d 04h 19m
INFO 2025-12-10 01:39:24,391 trainer.py: 892: Synchronizing meters
INFO 2025-12-10 01:39:24,391 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 2.260710774196519, 'Losses/train_all_loss_mask': 0.02860136998610364, 'Losses/train_all_loss_dice': 1.2249377740754022, 'Losses/train_all_loss_iou': 0.40880893719279104, 'Losses/train_all_loss_class': 0.05493665793514681, 'Losses/train_all_core_loss': 2.260710774196519, 'Trainer/where': 0.43955555555555553, 'Trainer/epoch': 21, 'Trainer/steps_train': 990}
INFO 2025-12-10 01:39:42,302 train_utils.py: 271: Train Epoch: [22][ 0/45] | Batch Time: 16.85 (16.85) | Data Time: 9.43 (9.43) | Mem (GB): 29.00 (29.00/29.00) | Time Elapsed: 00d 03h 20m | Losses/train_all_loss: 2.78e-01 (2.78e-01)
INFO 2025-12-10 01:41:39,604 train_utils.py: 271: Train Epoch: [22][10/45] | Batch Time: 18.57 (12.20) | Data Time: 0.00 (0.86) | Mem (GB): 41.00 (31.45/54.00) | Time Elapsed: 00d 03h 22m | Losses/train_all_loss: 1.08e+01 (2.27e+00)
INFO 2025-12-10 01:43:53,129 train_utils.py: 271: Train Epoch: [22][20/45] | Batch Time: 12.86 (12.75) | Data Time: 0.00 (0.45) | Mem (GB): 45.00 (31.00/54.00) | Time Elapsed: 00d 03h 24m | Losses/train_all_loss: 3.71e+00 (2.36e+00)
INFO 2025-12-10 01:46:12,664 train_utils.py: 271: Train Epoch: [22][30/45] | Batch Time: 7.17 (13.14) | Data Time: 0.00 (0.30) | Mem (GB): 35.00 (35.19/64.00) | Time Elapsed: 00d 03h 27m | Losses/train_all_loss: 2.37e+00 (2.42e+00)
INFO 2025-12-10 01:48:08,420 train_utils.py: 271: Train Epoch: [22][40/45] | Batch Time: 18.48 (12.76) | Data Time: 0.00 (0.23) | Mem (GB): 51.00 (35.02/64.00) | Time Elapsed: 00d 03h 29m | Losses/train_all_loss: 1.53e+00 (2.39e+00)
INFO 2025-12-10 01:48:59,726 trainer.py: 950: Estimated time remaining: 00d 04h 18m
INFO 2025-12-10 01:48:59,727 trainer.py: 892: Synchronizing meters
INFO 2025-12-10 01:48:59,727 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 2.3521429075135125, 'Losses/train_all_loss_mask': 0.025034303502697083, 'Losses/train_all_loss_dice': 1.306783307923211, 'Losses/train_all_loss_iou': 0.4354304689086146, 'Losses/train_all_loss_class': 0.10924306117665393, 'Losses/train_all_core_loss': 2.3521429075135125, 'Trainer/where': 0.45955555555555555, 'Trainer/epoch': 22, 'Trainer/steps_train': 1035}
INFO 2025-12-10 01:49:28,946 train_utils.py: 271: Train Epoch: [23][ 0/45] | Batch Time: 28.19 (28.19) | Data Time: 8.71 (8.71) | Mem (GB): 54.00 (54.00/54.00) | Time Elapsed: 00d 03h 30m | Losses/train_all_loss: 4.07e+00 (4.07e+00)
INFO 2025-12-10 01:51:14,288 train_utils.py: 271: Train Epoch: [23][10/45] | Batch Time: 12.74 (12.14) | Data Time: 0.00 (0.79) | Mem (GB): 28.00 (33.18/54.00) | Time Elapsed: 00d 03h 32m | Losses/train_all_loss: 2.09e+00 (1.84e+00)
INFO 2025-12-10 01:52:55,003 train_utils.py: 271: Train Epoch: [23][20/45] | Batch Time: 7.53 (11.15) | Data Time: 0.00 (0.42) | Mem (GB): 42.00 (32.24/54.00) | Time Elapsed: 00d 03h 33m | Losses/train_all_loss: 5.50e-01 (1.83e+00)
INFO 2025-12-10 01:55:20,389 train_utils.py: 271: Train Epoch: [23][30/45] | Batch Time: 18.29 (12.25) | Data Time: 0.00 (0.28) | Mem (GB): 42.00 (34.52/54.00) | Time Elapsed: 00d 03h 36m | Losses/train_all_loss: 1.36e+01 (2.38e+00)
INFO 2025-12-10 01:57:28,529 train_utils.py: 271: Train Epoch: [23][40/45] | Batch Time: 18.56 (12.38) | Data Time: 0.00 (0.21) | Mem (GB): 22.00 (33.98/54.00) | Time Elapsed: 00d 03h 38m | Losses/train_all_loss: 2.37e+00 (2.23e+00)
INFO 2025-12-10 01:58:20,617 trainer.py: 950: Estimated time remaining: 00d 04h 02m
INFO 2025-12-10 01:58:20,618 trainer.py: 892: Synchronizing meters
INFO 2025-12-10 01:58:20,618 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 2.2547396894958283, 'Losses/train_all_loss_mask': 0.026755871522861224, 'Losses/train_all_loss_dice': 1.2179964837100772, 'Losses/train_all_loss_iou': 0.459159618926545, 'Losses/train_all_loss_class': 0.042466191983108525, 'Losses/train_all_core_loss': 2.2547396894958283, 'Trainer/where': 0.47955555555555557, 'Trainer/epoch': 23, 'Trainer/steps_train': 1080}
INFO 2025-12-10 01:58:50,704 train_utils.py: 271: Train Epoch: [24][ 0/45] | Batch Time: 29.03 (29.03) | Data Time: 21.69 (21.69) | Mem (GB): 29.00 (29.00/29.00) | Time Elapsed: 00d 03h 39m | Losses/train_all_loss: 5.19e-01 (5.19e-01)
INFO 2025-12-10 02:00:29,973 train_utils.py: 271: Train Epoch: [24][10/45] | Batch Time: 7.07 (11.66) | Data Time: 0.00 (1.97) | Mem (GB): 21.00 (31.55/53.00) | Time Elapsed: 00d 03h 41m | Losses/train_all_loss: 4.00e-01 (1.57e+00)
INFO 2025-12-10 02:02:38,340 train_utils.py: 271: Train Epoch: [24][20/45] | Batch Time: 18.35 (12.22) | Data Time: 0.00 (1.03) | Mem (GB): 42.00 (32.33/53.00) | Time Elapsed: 00d 03h 43m | Losses/train_all_loss: 1.69e+00 (1.83e+00)
INFO 2025-12-10 02:03:50,436 train_utils.py: 271: Train Epoch: [24][30/45] | Batch Time: 7.03 (10.61) | Data Time: 0.00 (0.70) | Mem (GB): 22.00 (31.06/53.00) | Time Elapsed: 00d 03h 44m | Losses/train_all_loss: 4.41e-01 (1.44e+00)
INFO 2025-12-10 02:05:57,894 train_utils.py: 271: Train Epoch: [24][40/45] | Batch Time: 7.15 (11.13) | Data Time: 0.00 (0.53) | Mem (GB): 27.00 (30.76/53.00) | Time Elapsed: 00d 03h 46m | Losses/train_all_loss: 4.28e-01 (1.69e+00)
INFO 2025-12-10 02:06:33,081 trainer.py: 950: Estimated time remaining: 00d 03h 24m
INFO 2025-12-10 02:06:33,082 trainer.py: 892: Synchronizing meters
INFO 2025-12-10 02:06:33,083 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 1.6719761047098372, 'Losses/train_all_loss_mask': 0.018192658366428482, 'Losses/train_all_loss_dice': 0.9494969046778149, 'Losses/train_all_loss_iou': 0.3374786427037583, 'Losses/train_all_loss_class': 0.021147400664940436, 'Losses/train_all_core_loss': 1.6719761047098372, 'Trainer/where': 0.49955555555555553, 'Trainer/epoch': 24, 'Trainer/steps_train': 1125}
INFO 2025-12-10 02:06:48,492 train_utils.py: 271: Train Epoch: [25][ 0/45] | Batch Time: 14.25 (14.25) | Data Time: 6.99 (6.99) | Mem (GB): 14.00 (14.00/14.00) | Time Elapsed: 00d 03h 47m | Losses/train_all_loss: 2.14e-01 (2.14e-01)
INFO 2025-12-10 02:09:13,835 train_utils.py: 271: Train Epoch: [25][10/45] | Batch Time: 18.45 (14.51) | Data Time: 0.00 (0.64) | Mem (GB): 33.00 (29.73/42.00) | Time Elapsed: 00d 03h 50m | Losses/train_all_loss: 8.27e-01 (2.08e+00)
INFO 2025-12-10 02:11:34,061 train_utils.py: 271: Train Epoch: [25][20/45] | Batch Time: 7.06 (14.28) | Data Time: 0.00 (0.33) | Mem (GB): 21.00 (35.57/61.00) | Time Elapsed: 00d 03h 52m | Losses/train_all_loss: 7.37e-01 (2.21e+00)
INFO 2025-12-10 02:13:25,247 train_utils.py: 271: Train Epoch: [25][30/45] | Batch Time: 18.52 (13.26) | Data Time: 0.00 (0.23) | Mem (GB): 54.00 (34.87/61.00) | Time Elapsed: 00d 03h 54m | Losses/train_all_loss: 2.39e+00 (1.84e+00)
INFO 2025-12-10 02:15:32,773 train_utils.py: 271: Train Epoch: [25][40/45] | Batch Time: 7.49 (13.13) | Data Time: 0.00 (0.17) | Mem (GB): 39.00 (34.83/61.00) | Time Elapsed: 00d 03h 56m | Losses/train_all_loss: 5.30e-01 (1.87e+00)
INFO 2025-12-10 02:16:25,139 trainer.py: 950: Estimated time remaining: 00d 03h 56m
INFO 2025-12-10 02:16:25,140 trainer.py: 892: Synchronizing meters
INFO 2025-12-10 02:16:25,140 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 2.019239212407006, 'Losses/train_all_loss_mask': 0.024270522946284876, 'Losses/train_all_loss_dice': 1.025162347488933, 'Losses/train_all_loss_iou': 0.3947985330803527, 'Losses/train_all_loss_class': 0.1138678765093742, 'Losses/train_all_core_loss': 2.019239212407006, 'Trainer/where': 0.5195555555555555, 'Trainer/epoch': 25, 'Trainer/steps_train': 1170}
INFO 2025-12-10 02:16:41,692 train_utils.py: 271: Train Epoch: [26][ 0/45] | Batch Time: 15.47 (15.47) | Data Time: 7.90 (7.90) | Mem (GB): 29.00 (29.00/29.00) | Time Elapsed: 00d 03h 57m | Losses/train_all_loss: 1.88e+00 (1.88e+00)
INFO 2025-12-10 02:19:03,776 train_utils.py: 271: Train Epoch: [26][10/45] | Batch Time: 18.70 (14.32) | Data Time: 0.00 (0.86) | Mem (GB): 54.00 (37.09/54.00) | Time Elapsed: 00d 04h 00m | Losses/train_all_loss: 2.38e+00 (2.84e+00)
INFO 2025-12-10 02:21:12,073 train_utils.py: 271: Train Epoch: [26][20/45] | Batch Time: 18.44 (13.61) | Data Time: 0.00 (0.45) | Mem (GB): 23.00 (34.67/54.00) | Time Elapsed: 00d 04h 02m | Losses/train_all_loss: 1.85e+00 (2.38e+00)
INFO 2025-12-10 02:22:46,303 train_utils.py: 271: Train Epoch: [26][30/45] | Batch Time: 6.94 (12.26) | Data Time: 0.00 (0.31) | Mem (GB): 22.00 (33.29/54.00) | Time Elapsed: 00d 04h 03m | Losses/train_all_loss: 4.32e-01 (2.04e+00)
INFO 2025-12-10 02:24:42,701 train_utils.py: 271: Train Epoch: [26][40/45] | Batch Time: 6.98 (12.11) | Data Time: 0.00 (0.23) | Mem (GB): 22.00 (33.59/61.00) | Time Elapsed: 00d 04h 05m | Losses/train_all_loss: 7.11e-01 (2.17e+00)
INFO 2025-12-10 02:25:29,062 trainer.py: 950: Estimated time remaining: 00d 03h 27m
INFO 2025-12-10 02:25:29,063 trainer.py: 892: Synchronizing meters
INFO 2025-12-10 02:25:29,063 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 2.1914550340837904, 'Losses/train_all_loss_mask': 0.022247614639086855, 'Losses/train_all_loss_dice': 1.2634266595045724, 'Losses/train_all_loss_iou': 0.4493749070498678, 'Losses/train_all_loss_class': 0.03370120863355015, 'Losses/train_all_core_loss': 2.1914550340837904, 'Trainer/where': 0.5395555555555556, 'Trainer/epoch': 26, 'Trainer/steps_train': 1215}
INFO 2025-12-10 02:25:57,229 train_utils.py: 271: Train Epoch: [27][ 0/45] | Batch Time: 27.09 (27.09) | Data Time: 7.92 (7.92) | Mem (GB): 41.00 (41.00/41.00) | Time Elapsed: 00d 04h 06m | Losses/train_all_loss: 1.06e+01 (1.06e+01)
INFO 2025-12-10 02:27:48,276 train_utils.py: 271: Train Epoch: [27][10/45] | Batch Time: 13.19 (12.56) | Data Time: 0.00 (0.72) | Mem (GB): 45.00 (31.09/45.00) | Time Elapsed: 00d 04h 08m | Losses/train_all_loss: 3.06e+00 (3.05e+00)
INFO 2025-12-10 02:29:45,258 train_utils.py: 271: Train Epoch: [27][20/45] | Batch Time: 18.42 (12.15) | Data Time: 0.00 (0.38) | Mem (GB): 43.00 (32.14/45.00) | Time Elapsed: 00d 04h 10m | Losses/train_all_loss: 3.91e+00 (2.26e+00)
INFO 2025-12-10 02:31:53,864 train_utils.py: 271: Train Epoch: [27][30/45] | Batch Time: 18.51 (12.38) | Data Time: 0.00 (0.26) | Mem (GB): 54.00 (33.65/54.00) | Time Elapsed: 00d 04h 12m | Losses/train_all_loss: 2.64e+00 (2.13e+00)
INFO 2025-12-10 02:33:50,162 train_utils.py: 271: Train Epoch: [27][40/45] | Batch Time: 7.50 (12.20) | Data Time: 0.00 (0.19) | Mem (GB): 42.00 (33.29/54.00) | Time Elapsed: 00d 04h 14m | Losses/train_all_loss: 8.46e-01 (1.96e+00)
INFO 2025-12-10 02:34:53,227 trainer.py: 950: Estimated time remaining: 00d 03h 26m
INFO 2025-12-10 02:34:53,228 trainer.py: 892: Synchronizing meters
INFO 2025-12-10 02:34:53,228 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 2.043728219800525, 'Losses/train_all_loss_mask': 0.02610853664163086, 'Losses/train_all_loss_dice': 1.1328197807073592, 'Losses/train_all_loss_iou': 0.378625686859919, 'Losses/train_all_loss_class': 0.010112054322447248, 'Losses/train_all_core_loss': 2.043728219800525, 'Trainer/where': 0.5595555555555556, 'Trainer/epoch': 27, 'Trainer/steps_train': 1260}
INFO 2025-12-10 02:35:21,162 train_utils.py: 271: Train Epoch: [28][ 0/45] | Batch Time: 26.87 (26.87) | Data Time: 7.77 (7.77) | Mem (GB): 41.00 (41.00/41.00) | Time Elapsed: 00d 04h 16m | Losses/train_all_loss: 2.97e+00 (2.97e+00)
INFO 2025-12-10 02:37:50,673 train_utils.py: 271: Train Epoch: [28][10/45] | Batch Time: 7.05 (16.03) | Data Time: 0.00 (0.71) | Mem (GB): 22.00 (33.82/43.00) | Time Elapsed: 00d 04h 18m | Losses/train_all_loss: 6.84e-01 (2.59e+00)
INFO 2025-12-10 02:39:36,023 train_utils.py: 271: Train Epoch: [28][20/45] | Batch Time: 7.28 (13.42) | Data Time: 0.00 (0.37) | Mem (GB): 39.00 (32.81/54.00) | Time Elapsed: 00d 04h 20m | Losses/train_all_loss: 3.50e-01 (2.12e+00)
INFO 2025-12-10 02:41:33,653 train_utils.py: 271: Train Epoch: [28][30/45] | Batch Time: 7.16 (12.88) | Data Time: 0.00 (0.25) | Mem (GB): 33.00 (33.35/54.00) | Time Elapsed: 00d 04h 22m | Losses/train_all_loss: 2.56e-01 (1.88e+00)
INFO 2025-12-10 02:43:23,916 train_utils.py: 271: Train Epoch: [28][40/45] | Batch Time: 7.43 (12.43) | Data Time: 0.00 (0.19) | Mem (GB): 39.00 (32.44/54.00) | Time Elapsed: 00d 04h 24m | Losses/train_all_loss: 6.38e-01 (1.85e+00)
INFO 2025-12-10 02:44:10,327 trainer.py: 950: Estimated time remaining: 00d 03h 14m
INFO 2025-12-10 02:44:10,328 trainer.py: 892: Synchronizing meters
INFO 2025-12-10 02:44:10,328 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 1.7928674770726098, 'Losses/train_all_loss_mask': 0.020608722294370333, 'Losses/train_all_loss_dice': 0.9502950817346573, 'Losses/train_all_loss_iou': 0.3340991273522377, 'Losses/train_all_loss_class': 0.09629882862202697, 'Losses/train_all_core_loss': 1.7928674770726098, 'Trainer/where': 0.5795555555555556, 'Trainer/epoch': 28, 'Trainer/steps_train': 1305}
INFO 2025-12-10 02:44:26,385 train_utils.py: 271: Train Epoch: [29][ 0/45] | Batch Time: 15.04 (15.04) | Data Time: 7.54 (7.54) | Mem (GB): 27.00 (27.00/27.00) | Time Elapsed: 00d 04h 25m | Losses/train_all_loss: 3.75e-01 (3.75e-01)
INFO 2025-12-10 02:46:18,467 train_utils.py: 271: Train Epoch: [29][10/45] | Batch Time: 7.00 (11.56) | Data Time: 0.00 (0.69) | Mem (GB): 21.00 (32.09/52.00) | Time Elapsed: 00d 04h 27m | Losses/train_all_loss: 1.02e+00 (1.50e+00)
INFO 2025-12-10 02:48:26,950 train_utils.py: 271: Train Epoch: [29][20/45] | Batch Time: 7.29 (12.17) | Data Time: 0.00 (0.36) | Mem (GB): 27.00 (33.95/61.00) | Time Elapsed: 00d 04h 29m | Losses/train_all_loss: 7.06e-01 (1.81e+00)
INFO 2025-12-10 02:50:34,791 train_utils.py: 271: Train Epoch: [29][30/45] | Batch Time: 7.13 (12.37) | Data Time: 0.00 (0.24) | Mem (GB): 29.00 (34.13/64.00) | Time Elapsed: 00d 04h 31m | Losses/train_all_loss: 8.63e-01 (1.83e+00)
INFO 2025-12-10 02:52:14,296 train_utils.py: 271: Train Epoch: [29][40/45] | Batch Time: 6.98 (11.78) | Data Time: 0.00 (0.18) | Mem (GB): 27.00 (33.71/64.00) | Time Elapsed: 00d 04h 33m | Losses/train_all_loss: 6.27e-01 (1.70e+00)
INFO 2025-12-10 02:53:17,265 trainer.py: 950: Estimated time remaining: 00d 03h 01m
INFO 2025-12-10 02:53:17,266 trainer.py: 892: Synchronizing meters
INFO 2025-12-10 02:53:17,266 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 1.937489026122623, 'Losses/train_all_loss_mask': 0.020963117914895215, 'Losses/train_all_loss_dice': 1.077613087826305, 'Losses/train_all_loss_iou': 0.3656004050953521, 'Losses/train_all_loss_class': 0.07501312605185992, 'Losses/train_all_core_loss': 1.937489026122623, 'Trainer/where': 0.5995555555555555, 'Trainer/epoch': 29, 'Trainer/steps_train': 1350}
INFO 2025-12-10 02:53:45,877 train_utils.py: 271: Train Epoch: [30][ 0/45] | Batch Time: 27.57 (27.57) | Data Time: 8.14 (8.14) | Mem (GB): 52.00 (52.00/52.00) | Time Elapsed: 00d 04h 34m | Losses/train_all_loss: 2.35e+00 (2.35e+00)
INFO 2025-12-10 02:56:16,084 train_utils.py: 271: Train Epoch: [30][10/45] | Batch Time: 18.28 (16.16) | Data Time: 0.00 (0.74) | Mem (GB): 41.00 (38.09/52.00) | Time Elapsed: 00d 04h 37m | Losses/train_all_loss: 1.85e+00 (1.86e+00)
INFO 2025-12-10 02:58:12,814 train_utils.py: 271: Train Epoch: [30][20/45] | Batch Time: 12.56 (14.02) | Data Time: 0.00 (0.39) | Mem (GB): 28.00 (37.05/64.00) | Time Elapsed: 00d 04h 39m | Losses/train_all_loss: 2.14e+00 (2.32e+00)
INFO 2025-12-10 02:59:52,489 train_utils.py: 271: Train Epoch: [30][30/45] | Batch Time: 7.12 (12.72) | Data Time: 0.00 (0.26) | Mem (GB): 27.00 (35.13/64.00) | Time Elapsed: 00d 04h 40m | Losses/train_all_loss: 7.87e-01 (2.15e+00)
INFO 2025-12-10 03:01:43,090 train_utils.py: 271: Train Epoch: [30][40/45] | Batch Time: 12.92 (12.31) | Data Time: 0.00 (0.20) | Mem (GB): 45.00 (34.22/64.00) | Time Elapsed: 00d 04h 42m | Losses/train_all_loss: 3.54e+00 (2.01e+00)
INFO 2025-12-10 03:02:40,345 trainer.py: 950: Estimated time remaining: 00d 02h 57m
INFO 2025-12-10 03:02:40,346 trainer.py: 892: Synchronizing meters
INFO 2025-12-10 03:02:40,346 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 2.074639738930596, 'Losses/train_all_loss_mask': 0.03044238095689151, 'Losses/train_all_loss_dice': 1.0629415508773592, 'Losses/train_all_loss_iou': 0.4000312274114953, 'Losses/train_all_loss_class': 0.0028193721082368024, 'Losses/train_all_core_loss': 2.074639738930596, 'Trainer/where': 0.6195555555555555, 'Trainer/epoch': 30, 'Trainer/steps_train': 1395}
INFO 2025-12-10 03:03:15,817 train_utils.py: 271: Train Epoch: [31][ 0/45] | Batch Time: 34.41 (34.41) | Data Time: 15.79 (15.79) | Mem (GB): 41.00 (41.00/41.00) | Time Elapsed: 00d 04h 44m | Losses/train_all_loss: 1.28e+00 (1.28e+00)
INFO 2025-12-10 03:05:30,141 train_utils.py: 271: Train Epoch: [31][10/45] | Batch Time: 6.98 (15.34) | Data Time: 0.00 (1.44) | Mem (GB): 15.00 (35.00/54.00) | Time Elapsed: 00d 04h 46m | Losses/train_all_loss: 8.30e-01 (1.87e+00)
INFO 2025-12-10 03:07:26,639 train_utils.py: 271: Train Epoch: [31][20/45] | Batch Time: 7.34 (13.58) | Data Time: 0.00 (0.75) | Mem (GB): 27.00 (32.48/54.00) | Time Elapsed: 00d 04h 48m | Losses/train_all_loss: 1.82e+00 (1.81e+00)
INFO 2025-12-10 03:08:55,785 train_utils.py: 271: Train Epoch: [31][30/45] | Batch Time: 7.08 (12.08) | Data Time: 0.00 (0.51) | Mem (GB): 22.00 (32.06/54.00) | Time Elapsed: 00d 04h 49m | Losses/train_all_loss: 3.55e-01 (1.47e+00)
INFO 2025-12-10 03:11:14,919 train_utils.py: 271: Train Epoch: [31][40/45] | Batch Time: 7.30 (12.52) | Data Time: 0.00 (0.39) | Mem (GB): 42.00 (32.51/64.00) | Time Elapsed: 00d 04h 52m | Losses/train_all_loss: 5.55e-01 (1.95e+00)
INFO 2025-12-10 03:11:55,901 trainer.py: 950: Estimated time remaining: 00d 02h 46m
INFO 2025-12-10 03:11:55,902 trainer.py: 892: Synchronizing meters
INFO 2025-12-10 03:11:55,902 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 1.8788368278079564, 'Losses/train_all_loss_mask': 0.02827219432219863, 'Losses/train_all_loss_dice': 0.986360083023707, 'Losses/train_all_loss_iou': 0.3136532453613149, 'Losses/train_all_loss_class': 0.013379612371170736, 'Losses/train_all_core_loss': 1.8788368278079564, 'Trainer/where': 0.6395555555555555, 'Trainer/epoch': 31, 'Trainer/steps_train': 1440}
INFO 2025-12-10 03:12:30,597 train_utils.py: 271: Train Epoch: [32][ 0/45] | Batch Time: 33.60 (33.60) | Data Time: 14.89 (14.89) | Mem (GB): 42.00 (42.00/42.00) | Time Elapsed: 00d 04h 53m | Losses/train_all_loss: 5.31e+00 (5.31e+00)
INFO 2025-12-10 03:14:16,626 train_utils.py: 271: Train Epoch: [32][10/45] | Batch Time: 7.33 (12.69) | Data Time: 0.00 (1.35) | Mem (GB): 29.00 (33.45/42.00) | Time Elapsed: 00d 04h 55m | Losses/train_all_loss: 4.81e-01 (2.40e+00)
INFO 2025-12-10 03:16:02,550 train_utils.py: 271: Train Epoch: [32][20/45] | Batch Time: 12.63 (11.69) | Data Time: 0.00 (0.71) | Mem (GB): 19.00 (31.86/45.00) | Time Elapsed: 00d 04h 57m | Losses/train_all_loss: 1.05e+00 (1.75e+00)
INFO 2025-12-10 03:17:37,376 train_utils.py: 271: Train Epoch: [32][30/45] | Batch Time: 7.18 (10.98) | Data Time: 0.00 (0.48) | Mem (GB): 27.00 (31.71/54.00) | Time Elapsed: 00d 04h 58m | Losses/train_all_loss: 3.62e-01 (1.67e+00)
INFO 2025-12-10 03:19:17,305 train_utils.py: 271: Train Epoch: [32][40/45] | Batch Time: 12.76 (10.74) | Data Time: 0.00 (0.36) | Mem (GB): 36.00 (31.34/54.00) | Time Elapsed: 00d 05h 00m | Losses/train_all_loss: 1.37e+00 (1.49e+00)
INFO 2025-12-10 03:20:20,590 trainer.py: 950: Estimated time remaining: 00d 02h 22m
INFO 2025-12-10 03:20:20,591 trainer.py: 892: Synchronizing meters
INFO 2025-12-10 03:20:20,592 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 1.54054085082478, 'Losses/train_all_loss_mask': 0.018249322049733667, 'Losses/train_all_loss_dice': 0.8739201072189543, 'Losses/train_all_loss_iou': 0.27021683437956706, 'Losses/train_all_loss_class': 0.03141746715883666, 'Losses/train_all_core_loss': 1.54054085082478, 'Trainer/where': 0.6595555555555555, 'Trainer/epoch': 32, 'Trainer/steps_train': 1485}
INFO 2025-12-10 03:20:38,506 train_utils.py: 271: Train Epoch: [33][ 0/45] | Batch Time: 16.84 (16.84) | Data Time: 9.36 (9.36) | Mem (GB): 27.00 (27.00/27.00) | Time Elapsed: 00d 05h 01m | Losses/train_all_loss: 2.24e-01 (2.24e-01)
INFO 2025-12-10 03:22:47,282 train_utils.py: 271: Train Epoch: [33][10/45] | Batch Time: 18.50 (13.24) | Data Time: 0.00 (0.85) | Mem (GB): 52.00 (30.73/52.00) | Time Elapsed: 00d 05h 03m | Losses/train_all_loss: 3.44e+00 (1.46e+00)
INFO 2025-12-10 03:24:44,317 train_utils.py: 271: Train Epoch: [33][20/45] | Batch Time: 18.34 (12.51) | Data Time: 0.00 (0.45) | Mem (GB): 43.00 (32.00/53.00) | Time Elapsed: 00d 05h 05m | Losses/train_all_loss: 3.32e+00 (1.78e+00)
INFO 2025-12-10 03:26:41,455 train_utils.py: 271: Train Epoch: [33][30/45] | Batch Time: 7.20 (12.25) | Data Time: 0.00 (0.30) | Mem (GB): 27.00 (32.45/54.00) | Time Elapsed: 00d 05h 07m | Losses/train_all_loss: 3.84e-01 (1.93e+00)
INFO 2025-12-10 03:28:55,704 train_utils.py: 271: Train Epoch: [33][40/45] | Batch Time: 7.19 (12.54) | Data Time: 0.00 (0.23) | Mem (GB): 27.00 (33.98/62.00) | Time Elapsed: 00d 05h 09m | Losses/train_all_loss: 8.39e-01 (2.01e+00)
INFO 2025-12-10 03:29:47,184 trainer.py: 950: Estimated time remaining: 00d 02h 30m
INFO 2025-12-10 03:29:47,185 trainer.py: 892: Synchronizing meters
INFO 2025-12-10 03:29:47,185 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 1.9237156460682552, 'Losses/train_all_loss_mask': 0.02490974481528004, 'Losses/train_all_loss_dice': 1.0248731344938278, 'Losses/train_all_loss_iou': 0.3820443234509892, 'Losses/train_all_loss_class': 0.01860326299448098, 'Losses/train_all_core_loss': 1.9237156460682552, 'Trainer/where': 0.6795555555555555, 'Trainer/epoch': 33, 'Trainer/steps_train': 1530}
INFO 2025-12-10 03:30:02,709 train_utils.py: 271: Train Epoch: [34][ 0/45] | Batch Time: 14.45 (14.45) | Data Time: 7.16 (7.16) | Mem (GB): 21.00 (21.00/21.00) | Time Elapsed: 00d 05h 11m | Losses/train_all_loss: 1.10e+00 (1.10e+00)
INFO 2025-12-10 03:31:59,230 train_utils.py: 271: Train Epoch: [34][10/45] | Batch Time: 7.42 (11.91) | Data Time: 0.00 (0.65) | Mem (GB): 42.00 (29.09/42.00) | Time Elapsed: 00d 05h 12m | Losses/train_all_loss: 3.20e-01 (1.41e+00)
INFO 2025-12-10 03:34:02,002 train_utils.py: 271: Train Epoch: [34][20/45] | Batch Time: 12.73 (12.08) | Data Time: 0.00 (0.34) | Mem (GB): 19.00 (30.86/43.00) | Time Elapsed: 00d 05h 15m | Losses/train_all_loss: 1.85e+00 (1.85e+00)
INFO 2025-12-10 03:35:31,224 train_utils.py: 271: Train Epoch: [34][30/45] | Batch Time: 12.89 (11.06) | Data Time: 0.00 (0.23) | Mem (GB): 36.00 (31.03/43.00) | Time Elapsed: 00d 05h 16m | Losses/train_all_loss: 1.55e+00 (1.64e+00)
INFO 2025-12-10 03:37:27,557 train_utils.py: 271: Train Epoch: [34][40/45] | Batch Time: 18.12 (11.20) | Data Time: 0.00 (0.18) | Mem (GB): 22.00 (31.93/54.00) | Time Elapsed: 00d 05h 18m | Losses/train_all_loss: 1.18e+00 (1.65e+00)
INFO 2025-12-10 03:38:31,034 trainer.py: 950: Estimated time remaining: 00d 02h 10m
INFO 2025-12-10 03:38:31,034 trainer.py: 892: Synchronizing meters
INFO 2025-12-10 03:38:31,035 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 1.7897429565588634, 'Losses/train_all_loss_mask': 0.02322000723021726, 'Losses/train_all_loss_dice': 0.9529686205916934, 'Losses/train_all_loss_iou': 0.3389563858922985, 'Losses/train_all_loss_class': 0.033417802286150274, 'Losses/train_all_core_loss': 1.7897429565588634, 'Trainer/where': 0.6995555555555555, 'Trainer/epoch': 34, 'Trainer/steps_train': 1575}
INFO 2025-12-10 03:38:56,807 train_utils.py: 271: Train Epoch: [35][ 0/45] | Batch Time: 24.71 (24.71) | Data Time: 17.30 (17.30) | Mem (GB): 35.00 (35.00/35.00) | Time Elapsed: 00d 05h 19m | Losses/train_all_loss: 1.51e+00 (1.51e+00)
INFO 2025-12-10 03:40:47,888 train_utils.py: 271: Train Epoch: [35][10/45] | Batch Time: 7.20 (12.34) | Data Time: 0.00 (1.57) | Mem (GB): 35.00 (31.18/54.00) | Time Elapsed: 00d 05h 21m | Losses/train_all_loss: 6.85e-01 (1.37e+00)
INFO 2025-12-10 03:42:50,163 train_utils.py: 271: Train Epoch: [35][20/45] | Batch Time: 7.14 (12.29) | Data Time: 0.00 (0.82) | Mem (GB): 29.00 (31.90/64.00) | Time Elapsed: 00d 05h 23m | Losses/train_all_loss: 4.77e-01 (1.51e+00)
INFO 2025-12-10 03:44:41,628 train_utils.py: 271: Train Epoch: [35][30/45] | Batch Time: 6.90 (11.92) | Data Time: 0.00 (0.56) | Mem (GB): 21.00 (32.81/64.00) | Time Elapsed: 00d 05h 25m | Losses/train_all_loss: 4.11e-01 (1.35e+00)
INFO 2025-12-10 03:46:32,250 train_utils.py: 271: Train Epoch: [35][40/45] | Batch Time: 7.05 (11.71) | Data Time: 0.00 (0.42) | Mem (GB): 21.00 (32.83/64.00) | Time Elapsed: 00d 05h 27m | Losses/train_all_loss: 3.81e-01 (1.43e+00)
INFO 2025-12-10 03:47:12,680 trainer.py: 950: Estimated time remaining: 00d 02h 01m
INFO 2025-12-10 03:47:12,681 trainer.py: 892: Synchronizing meters
INFO 2025-12-10 03:47:12,681 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 1.357173372970687, 'Losses/train_all_loss_mask': 0.017432124871346686, 'Losses/train_all_loss_dice': 0.7500592509905497, 'Losses/train_all_loss_iou': 0.2373829677907957, 'Losses/train_all_loss_class': 0.021088635648337385, 'Losses/train_all_core_loss': 1.357173372970687, 'Trainer/where': 0.7195555555555555, 'Trainer/epoch': 35, 'Trainer/steps_train': 1620}
INFO 2025-12-10 03:47:38,061 train_utils.py: 271: Train Epoch: [36][ 0/45] | Batch Time: 24.31 (24.31) | Data Time: 16.82 (16.82) | Mem (GB): 42.00 (42.00/42.00) | Time Elapsed: 00d 05h 28m | Losses/train_all_loss: 1.14e+00 (1.14e+00)
INFO 2025-12-10 03:49:46,204 train_utils.py: 271: Train Epoch: [36][10/45] | Batch Time: 7.17 (13.86) | Data Time: 0.00 (1.53) | Mem (GB): 33.00 (31.91/43.00) | Time Elapsed: 00d 05h 30m | Losses/train_all_loss: 6.30e-01 (1.65e+00)
INFO 2025-12-10 03:51:54,210 train_utils.py: 271: Train Epoch: [36][20/45] | Batch Time: 7.15 (13.36) | Data Time: 0.00 (0.80) | Mem (GB): 22.00 (29.38/43.00) | Time Elapsed: 00d 05h 32m | Losses/train_all_loss: 2.81e-01 (1.54e+00)
INFO 2025-12-10 03:54:07,300 train_utils.py: 271: Train Epoch: [36][30/45] | Batch Time: 7.02 (13.34) | Data Time: 0.00 (0.54) | Mem (GB): 27.00 (31.00/64.00) | Time Elapsed: 00d 05h 35m | Losses/train_all_loss: 5.83e-01 (2.16e+00)
INFO 2025-12-10 03:55:58,733 train_utils.py: 271: Train Epoch: [36][40/45] | Batch Time: 13.09 (12.80) | Data Time: 0.00 (0.41) | Mem (GB): 45.00 (32.54/64.00) | Time Elapsed: 00d 05h 36m | Losses/train_all_loss: 1.36e+00 (1.96e+00)
INFO 2025-12-10 03:56:45,231 trainer.py: 950: Estimated time remaining: 00d 02h 03m
INFO 2025-12-10 03:56:45,232 trainer.py: 892: Synchronizing meters
INFO 2025-12-10 03:56:45,232 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 1.97721858686871, 'Losses/train_all_loss_mask': 0.025341622438281773, 'Losses/train_all_loss_dice': 0.9790157036648857, 'Losses/train_all_loss_iou': 0.3896497856411669, 'Losses/train_all_loss_class': 0.10172065408864582, 'Losses/train_all_core_loss': 1.97721858686871, 'Trainer/where': 0.7395555555555555, 'Trainer/epoch': 36, 'Trainer/steps_train': 1665}
INFO 2025-12-10 03:57:00,966 train_utils.py: 271: Train Epoch: [37][ 0/45] | Batch Time: 14.68 (14.68) | Data Time: 7.22 (7.22) | Mem (GB): 22.00 (22.00/22.00) | Time Elapsed: 00d 05h 38m | Losses/train_all_loss: 3.76e-01 (3.76e-01)
INFO 2025-12-10 03:59:03,617 train_utils.py: 271: Train Epoch: [37][10/45] | Batch Time: 18.36 (12.48) | Data Time: 0.00 (1.06) | Mem (GB): 43.00 (32.18/54.00) | Time Elapsed: 00d 05h 40m | Losses/train_all_loss: 2.66e+00 (1.42e+00)
INFO 2025-12-10 04:01:17,528 train_utils.py: 271: Train Epoch: [37][20/45] | Batch Time: 18.51 (12.92) | Data Time: 0.00 (0.55) | Mem (GB): 43.00 (33.76/54.00) | Time Elapsed: 00d 05h 42m | Losses/train_all_loss: 1.82e+00 (1.54e+00)
INFO 2025-12-10 04:03:37,368 train_utils.py: 271: Train Epoch: [37][30/45] | Batch Time: 18.51 (13.26) | Data Time: 0.00 (0.38) | Mem (GB): 62.00 (34.87/62.00) | Time Elapsed: 00d 05h 44m | Losses/train_all_loss: 9.01e+00 (1.94e+00)
INFO 2025-12-10 04:05:21,627 train_utils.py: 271: Train Epoch: [37][40/45] | Batch Time: 12.67 (12.57) | Data Time: 0.00 (0.28) | Mem (GB): 36.00 (33.59/62.00) | Time Elapsed: 00d 05h 46m | Losses/train_all_loss: 8.83e-01 (1.72e+00)
INFO 2025-12-10 04:05:50,966 trainer.py: 950: Estimated time remaining: 00d 01h 48m
INFO 2025-12-10 04:05:50,967 trainer.py: 892: Synchronizing meters
INFO 2025-12-10 04:05:50,967 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 1.6390622549586826, 'Losses/train_all_loss_mask': 0.022786919948541456, 'Losses/train_all_loss_dice': 0.8491671280728446, 'Losses/train_all_loss_iou': 0.29907497006158035, 'Losses/train_all_loss_class': 0.03508179063280107, 'Losses/train_all_core_loss': 1.6390622549586826, 'Trainer/where': 0.7595555555555555, 'Trainer/epoch': 37, 'Trainer/steps_train': 1710}
INFO 2025-12-10 04:06:13,490 train_utils.py: 271: Train Epoch: [38][ 0/45] | Batch Time: 21.49 (21.49) | Data Time: 14.14 (14.14) | Mem (GB): 22.00 (22.00/22.00) | Time Elapsed: 00d 05h 47m | Losses/train_all_loss: 1.91e-01 (1.91e-01)
INFO 2025-12-10 04:08:10,876 train_utils.py: 271: Train Epoch: [38][10/45] | Batch Time: 18.72 (12.62) | Data Time: 0.00 (1.29) | Mem (GB): 61.00 (35.36/61.00) | Time Elapsed: 00d 05h 49m | Losses/train_all_loss: 5.68e+00 (1.70e+00)
INFO 2025-12-10 04:10:07,717 train_utils.py: 271: Train Epoch: [38][20/45] | Batch Time: 13.22 (12.18) | Data Time: 0.00 (0.67) | Mem (GB): 53.00 (33.86/61.00) | Time Elapsed: 00d 05h 51m | Losses/train_all_loss: 1.77e+00 (1.46e+00)
INFO 2025-12-10 04:12:05,138 train_utils.py: 271: Train Epoch: [38][30/45] | Batch Time: 7.19 (12.04) | Data Time: 0.00 (0.46) | Mem (GB): 29.00 (33.74/61.00) | Time Elapsed: 00d 05h 53m | Losses/train_all_loss: 1.29e+00 (1.63e+00)
INFO 2025-12-10 04:14:12,522 train_utils.py: 271: Train Epoch: [38][40/45] | Batch Time: 18.58 (12.21) | Data Time: 0.00 (0.35) | Mem (GB): 52.00 (33.41/61.00) | Time Elapsed: 00d 05h 55m | Losses/train_all_loss: 3.36e+00 (1.79e+00)
INFO 2025-12-10 04:15:09,835 trainer.py: 950: Estimated time remaining: 00d 01h 42m
INFO 2025-12-10 04:15:09,836 trainer.py: 892: Synchronizing meters
INFO 2025-12-10 04:15:09,836 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 1.8212205555703904, 'Losses/train_all_loss_mask': 0.021659665518543786, 'Losses/train_all_loss_dice': 1.0593015498585172, 'Losses/train_all_loss_iou': 0.3261766315334373, 'Losses/train_all_loss_class': 0.002549070803553222, 'Losses/train_all_core_loss': 1.8212205555703904, 'Trainer/where': 0.7795555555555554, 'Trainer/epoch': 38, 'Trainer/steps_train': 1755}
INFO 2025-12-10 04:15:25,947 train_utils.py: 271: Train Epoch: [39][ 0/45] | Batch Time: 15.06 (15.06) | Data Time: 7.59 (7.59) | Mem (GB): 27.00 (27.00/27.00) | Time Elapsed: 00d 05h 56m | Losses/train_all_loss: 5.56e-01 (5.56e-01)
INFO 2025-12-10 04:17:17,089 train_utils.py: 271: Train Epoch: [39][10/45] | Batch Time: 18.63 (11.47) | Data Time: 0.00 (0.69) | Mem (GB): 52.00 (28.27/52.00) | Time Elapsed: 00d 05h 58m | Losses/train_all_loss: 1.29e+00 (9.69e-01)
INFO 2025-12-10 04:19:19,488 train_utils.py: 271: Train Epoch: [39][20/45] | Batch Time: 7.07 (11.84) | Data Time: 0.00 (0.36) | Mem (GB): 27.00 (32.10/53.00) | Time Elapsed: 00d 06h 00m | Losses/train_all_loss: 7.41e-01 (1.25e+00)
INFO 2025-12-10 04:20:59,991 train_utils.py: 271: Train Epoch: [39][30/45] | Batch Time: 7.22 (11.26) | Data Time: 0.00 (0.25) | Mem (GB): 42.00 (31.48/53.00) | Time Elapsed: 00d 06h 01m | Losses/train_all_loss: 7.55e-01 (1.53e+00)
INFO 2025-12-10 04:23:24,737 train_utils.py: 271: Train Epoch: [39][40/45] | Batch Time: 18.53 (12.05) | Data Time: 0.00 (0.19) | Mem (GB): 64.00 (33.34/64.00) | Time Elapsed: 00d 06h 04m | Losses/train_all_loss: 9.99e-01 (1.54e+00)
INFO 2025-12-10 04:24:16,782 trainer.py: 950: Estimated time remaining: 00d 01h 30m
INFO 2025-12-10 04:24:16,783 trainer.py: 892: Synchronizing meters
INFO 2025-12-10 04:24:16,783 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 1.528871652815077, 'Losses/train_all_loss_mask': 0.02101295673702326, 'Losses/train_all_loss_dice': 0.8087601562341055, 'Losses/train_all_loss_iou': 0.29316966202523975, 'Losses/train_all_loss_class': 0.006682679014366597, 'Losses/train_all_core_loss': 1.528871652815077, 'Trainer/where': 0.7995555555555555, 'Trainer/epoch': 39, 'Trainer/steps_train': 1800}
INFO 2025-12-10 04:24:47,964 train_utils.py: 271: Train Epoch: [40][ 0/45] | Batch Time: 30.15 (30.15) | Data Time: 16.95 (16.95) | Mem (GB): 45.00 (45.00/45.00) | Time Elapsed: 00d 06h 05m | Losses/train_all_loss: 1.10e+00 (1.10e+00)
INFO 2025-12-10 04:26:38,182 train_utils.py: 271: Train Epoch: [40][10/45] | Batch Time: 7.02 (12.76) | Data Time: 0.00 (1.54) | Mem (GB): 15.00 (29.73/45.00) | Time Elapsed: 00d 06h 07m | Losses/train_all_loss: 3.18e-01 (1.45e+00)
INFO 2025-12-10 04:28:30,323 train_utils.py: 271: Train Epoch: [40][20/45] | Batch Time: 6.92 (12.02) | Data Time: 0.00 (0.81) | Mem (GB): 14.00 (33.95/64.00) | Time Elapsed: 00d 06h 09m | Losses/train_all_loss: 4.74e-01 (1.48e+00)
INFO 2025-12-10 04:30:42,945 train_utils.py: 271: Train Epoch: [40][30/45] | Batch Time: 18.28 (12.42) | Data Time: 0.00 (0.55) | Mem (GB): 33.00 (33.84/64.00) | Time Elapsed: 00d 06h 11m | Losses/train_all_loss: 3.35e+00 (1.65e+00)
INFO 2025-12-10 04:32:43,819 train_utils.py: 271: Train Epoch: [40][40/45] | Batch Time: 18.16 (12.34) | Data Time: 0.00 (0.41) | Mem (GB): 42.00 (33.39/64.00) | Time Elapsed: 00d 06h 13m | Losses/train_all_loss: 3.20e+00 (1.57e+00)
INFO 2025-12-10 04:33:29,620 trainer.py: 950: Estimated time remaining: 00d 01h 22m
INFO 2025-12-10 04:33:29,621 trainer.py: 892: Synchronizing meters
INFO 2025-12-10 04:33:29,622 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 1.8159345934788387, 'Losses/train_all_loss_mask': 0.03264077024327384, 'Losses/train_all_loss_dice': 0.8618734646174643, 'Losses/train_all_loss_iou': 0.2814230333185858, 'Losses/train_all_loss_class': 0.01982274342596371, 'Losses/train_all_core_loss': 1.8159345934788387, 'Trainer/where': 0.8195555555555555, 'Trainer/epoch': 40, 'Trainer/steps_train': 1845}
INFO 2025-12-10 04:34:04,722 train_utils.py: 271: Train Epoch: [41][ 0/45] | Batch Time: 33.90 (33.90) | Data Time: 14.69 (14.69) | Mem (GB): 43.00 (43.00/43.00) | Time Elapsed: 00d 06h 15m | Losses/train_all_loss: 2.03e+00 (2.03e+00)
INFO 2025-12-10 04:35:38,337 train_utils.py: 271: Train Epoch: [41][10/45] | Batch Time: 7.12 (11.59) | Data Time: 0.00 (1.34) | Mem (GB): 29.00 (30.09/43.00) | Time Elapsed: 00d 06h 16m | Losses/train_all_loss: 2.38e-01 (1.09e+00)
INFO 2025-12-10 04:37:45,947 train_utils.py: 271: Train Epoch: [41][20/45] | Batch Time: 7.19 (12.15) | Data Time: 0.00 (0.70) | Mem (GB): 29.00 (30.52/43.00) | Time Elapsed: 00d 06h 18m | Losses/train_all_loss: 1.03e+00 (1.15e+00)
INFO 2025-12-10 04:39:37,165 train_utils.py: 271: Train Epoch: [41][30/45] | Batch Time: 18.57 (11.82) | Data Time: 0.00 (0.47) | Mem (GB): 62.00 (31.39/62.00) | Time Elapsed: 00d 06h 20m | Losses/train_all_loss: 1.47e+00 (1.15e+00)
INFO 2025-12-10 04:42:24,108 train_utils.py: 271: Train Epoch: [41][40/45] | Batch Time: 7.26 (13.01) | Data Time: 0.00 (0.36) | Mem (GB): 39.00 (34.71/62.00) | Time Elapsed: 00d 06h 23m | Losses/train_all_loss: 9.68e-01 (1.62e+00)
INFO 2025-12-10 04:43:26,949 trainer.py: 950: Estimated time remaining: 00d 01h 19m
INFO 2025-12-10 04:43:26,950 trainer.py: 892: Synchronizing meters
INFO 2025-12-10 04:43:26,950 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 1.7210362546973759, 'Losses/train_all_loss_mask': 0.019694435896558893, 'Losses/train_all_loss_dice': 0.98713149494595, 'Losses/train_all_loss_iou': 0.31083783614966604, 'Losses/train_all_loss_class': 0.029178271308871167, 'Losses/train_all_core_loss': 1.7210362546973759, 'Trainer/where': 0.8395555555555555, 'Trainer/epoch': 41, 'Trainer/steps_train': 1890}
INFO 2025-12-10 04:43:54,429 train_utils.py: 271: Train Epoch: [42][ 0/45] | Batch Time: 26.43 (26.43) | Data Time: 13.25 (13.25) | Mem (GB): 28.00 (28.00/28.00) | Time Elapsed: 00d 06h 24m | Losses/train_all_loss: 7.11e-01 (7.11e-01)
INFO 2025-12-10 04:45:51,159 train_utils.py: 271: Train Epoch: [42][10/45] | Batch Time: 7.06 (13.01) | Data Time: 0.00 (1.20) | Mem (GB): 27.00 (34.09/53.00) | Time Elapsed: 00d 06h 26m | Losses/train_all_loss: 6.26e-01 (1.31e+00)
INFO 2025-12-10 04:47:53,490 train_utils.py: 271: Train Epoch: [42][20/45] | Batch Time: 7.22 (12.64) | Data Time: 0.00 (0.63) | Mem (GB): 33.00 (33.48/54.00) | Time Elapsed: 00d 06h 28m | Losses/train_all_loss: 1.08e+00 (1.71e+00)
INFO 2025-12-10 04:49:55,513 train_utils.py: 271: Train Epoch: [42][30/45] | Batch Time: 7.09 (12.50) | Data Time: 0.00 (0.43) | Mem (GB): 35.00 (33.52/54.00) | Time Elapsed: 00d 06h 30m | Losses/train_all_loss: 9.34e+00 (1.90e+00)
INFO 2025-12-10 04:51:45,735 train_utils.py: 271: Train Epoch: [42][40/45] | Batch Time: 7.39 (12.14) | Data Time: 0.00 (0.32) | Mem (GB): 39.00 (33.17/61.00) | Time Elapsed: 00d 06h 32m | Losses/train_all_loss: 5.54e-01 (1.72e+00)
INFO 2025-12-10 04:52:42,866 trainer.py: 950: Estimated time remaining: 00d 01h 04m
INFO 2025-12-10 04:52:42,867 trainer.py: 892: Synchronizing meters
INFO 2025-12-10 04:52:42,867 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 2.1915465533733367, 'Losses/train_all_loss_mask': 0.030052089034062292, 'Losses/train_all_loss_dice': 1.0750113993883132, 'Losses/train_all_loss_iou': 0.39054418959551385, 'Losses/train_all_loss_class': 0.12494921009851143, 'Losses/train_all_core_loss': 2.1915465533733367, 'Trainer/where': 0.8595555555555555, 'Trainer/epoch': 42, 'Trainer/steps_train': 1935}
INFO 2025-12-10 04:53:16,725 train_utils.py: 271: Train Epoch: [43][ 0/45] | Batch Time: 32.77 (32.77) | Data Time: 13.85 (13.85) | Mem (GB): 41.00 (41.00/41.00) | Time Elapsed: 00d 06h 34m | Losses/train_all_loss: 4.47e+00 (4.47e+00)
INFO 2025-12-10 04:55:08,419 train_utils.py: 271: Train Epoch: [43][10/45] | Batch Time: 7.05 (13.13) | Data Time: 0.00 (1.26) | Mem (GB): 21.00 (34.36/53.00) | Time Elapsed: 00d 06h 36m | Losses/train_all_loss: 3.82e-01 (1.56e+00)
INFO 2025-12-10 04:57:26,580 train_utils.py: 271: Train Epoch: [43][20/45] | Batch Time: 18.06 (13.46) | Data Time: 0.00 (0.66) | Mem (GB): 43.00 (37.14/54.00) | Time Elapsed: 00d 06h 38m | Losses/train_all_loss: 3.37e+00 (2.14e+00)
INFO 2025-12-10 04:59:43,710 train_utils.py: 271: Train Epoch: [43][30/45] | Batch Time: 18.13 (13.54) | Data Time: 0.00 (0.45) | Mem (GB): 42.00 (36.65/54.00) | Time Elapsed: 00d 06h 40m | Losses/train_all_loss: 2.57e+00 (2.32e+00)
INFO 2025-12-10 05:01:53,530 train_utils.py: 271: Train Epoch: [43][40/45] | Batch Time: 18.00 (13.40) | Data Time: 0.00 (0.34) | Mem (GB): 32.00 (34.93/54.00) | Time Elapsed: 00d 06h 42m | Losses/train_all_loss: 1.84e+00 (2.26e+00)
INFO 2025-12-10 05:02:55,764 trainer.py: 950: Estimated time remaining: 00d 01h 01m
INFO 2025-12-10 05:02:55,765 trainer.py: 892: Synchronizing meters
INFO 2025-12-10 05:02:55,765 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 2.350135811832216, 'Losses/train_all_loss_mask': 0.03414040292457988, 'Losses/train_all_loss_dice': 1.2161663012372124, 'Losses/train_all_loss_iou': 0.4227032146934006, 'Losses/train_all_loss_class': 0.028458311514791952, 'Losses/train_all_core_loss': 2.350135811832216, 'Trainer/where': 0.8795555555555555, 'Trainer/epoch': 43, 'Trainer/steps_train': 1980}
INFO 2025-12-10 05:03:18,607 train_utils.py: 271: Train Epoch: [44][ 0/45] | Batch Time: 21.81 (21.81) | Data Time: 14.07 (14.07) | Mem (GB): 39.00 (39.00/39.00) | Time Elapsed: 00d 06h 44m | Losses/train_all_loss: 4.00e-01 (4.00e-01)
INFO 2025-12-10 05:05:27,144 train_utils.py: 271: Train Epoch: [44][10/45] | Batch Time: 18.09 (13.67) | Data Time: 0.00 (1.28) | Mem (GB): 32.00 (38.36/61.00) | Time Elapsed: 00d 06h 46m | Losses/train_all_loss: 3.70e+00 (2.24e+00)
INFO 2025-12-10 05:07:18,532 train_utils.py: 271: Train Epoch: [44][20/45] | Batch Time: 7.20 (12.46) | Data Time: 0.00 (0.67) | Mem (GB): 29.00 (35.57/61.00) | Time Elapsed: 00d 06h 48m | Losses/train_all_loss: 8.92e-01 (2.19e+00)
INFO 2025-12-10 05:09:42,242 train_utils.py: 271: Train Epoch: [44][30/45] | Batch Time: 7.18 (13.08) | Data Time: 0.00 (0.45) | Mem (GB): 35.00 (35.42/61.00) | Time Elapsed: 00d 06h 50m | Losses/train_all_loss: 6.38e-01 (2.05e+00)
INFO 2025-12-10 05:11:48,495 train_utils.py: 271: Train Epoch: [44][40/45] | Batch Time: 18.13 (12.97) | Data Time: 0.00 (0.34) | Mem (GB): 32.00 (34.37/61.00) | Time Elapsed: 00d 06h 52m | Losses/train_all_loss: 2.25e+00 (2.07e+00)
INFO 2025-12-10 05:12:45,569 trainer.py: 950: Estimated time remaining: 00d 00h 48m
INFO 2025-12-10 05:12:45,570 trainer.py: 892: Synchronizing meters
INFO 2025-12-10 05:12:45,570 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 2.0517599989970523, 'Losses/train_all_loss_mask': 0.022254800899989075, 'Losses/train_all_loss_dice': 1.1991987132363848, 'Losses/train_all_loss_iou': 0.3917763272093402, 'Losses/train_all_loss_class': 0.01568895691275634, 'Losses/train_all_core_loss': 2.0517599989970523, 'Trainer/where': 0.8995555555555554, 'Trainer/epoch': 44, 'Trainer/steps_train': 2025}
INFO 2025-12-10 05:13:01,760 train_utils.py: 271: Train Epoch: [45][ 0/45] | Batch Time: 15.17 (15.17) | Data Time: 7.73 (7.73) | Mem (GB): 29.00 (29.00/29.00) | Time Elapsed: 00d 06h 54m | Losses/train_all_loss: 2.84e-01 (2.84e-01)
INFO 2025-12-10 05:15:03,812 train_utils.py: 271: Train Epoch: [45][10/45] | Batch Time: 18.36 (12.47) | Data Time: 0.00 (0.70) | Mem (GB): 54.00 (32.91/61.00) | Time Elapsed: 00d 06h 56m | Losses/train_all_loss: 1.50e+01 (2.66e+00)
INFO 2025-12-10 05:17:10,738 train_utils.py: 271: Train Epoch: [45][20/45] | Batch Time: 18.34 (12.58) | Data Time: 0.00 (0.37) | Mem (GB): 52.00 (33.67/61.00) | Time Elapsed: 00d 06h 58m | Losses/train_all_loss: 1.59e+00 (2.22e+00)
INFO 2025-12-10 05:19:17,647 train_utils.py: 271: Train Epoch: [45][30/45] | Batch Time: 18.39 (12.61) | Data Time: 0.00 (0.25) | Mem (GB): 54.00 (33.35/61.00) | Time Elapsed: 00d 07h 00m | Losses/train_all_loss: 4.66e+00 (2.14e+00)
INFO 2025-12-10 05:21:35,382 train_utils.py: 271: Train Epoch: [45][40/45] | Batch Time: 18.17 (12.90) | Data Time: 0.00 (0.19) | Mem (GB): 43.00 (34.07/61.00) | Time Elapsed: 00d 07h 02m | Losses/train_all_loss: 2.23e+00 (2.28e+00)
INFO 2025-12-10 05:22:21,342 trainer.py: 950: Estimated time remaining: 00d 00h 38m
INFO 2025-12-10 05:22:21,343 trainer.py: 892: Synchronizing meters
INFO 2025-12-10 05:22:21,343 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 2.270688090059492, 'Losses/train_all_loss_mask': 0.023627763008698822, 'Losses/train_all_loss_dice': 1.1024104492531883, 'Losses/train_all_loss_iou': 0.3666492555911342, 'Losses/train_all_loss_class': 0.3290731038795775, 'Losses/train_all_core_loss': 2.270688090059492, 'Trainer/where': 0.9195555555555555, 'Trainer/epoch': 45, 'Trainer/steps_train': 2070}
INFO 2025-12-10 05:22:43,696 train_utils.py: 271: Train Epoch: [46][ 0/45] | Batch Time: 21.30 (21.30) | Data Time: 14.15 (14.15) | Mem (GB): 21.00 (21.00/21.00) | Time Elapsed: 00d 07h 03m | Losses/train_all_loss: 7.18e-01 (7.18e-01)
INFO 2025-12-10 05:25:02,165 train_utils.py: 271: Train Epoch: [46][10/45] | Batch Time: 7.21 (14.52) | Data Time: 0.00 (1.29) | Mem (GB): 27.00 (32.00/52.00) | Time Elapsed: 00d 07h 06m | Losses/train_all_loss: 6.50e-01 (2.46e+00)
INFO 2025-12-10 05:26:59,372 train_utils.py: 271: Train Epoch: [46][20/45] | Batch Time: 12.59 (13.19) | Data Time: 0.00 (0.67) | Mem (GB): 36.00 (34.67/64.00) | Time Elapsed: 00d 07h 07m | Losses/train_all_loss: 1.97e+00 (2.13e+00)
INFO 2025-12-10 05:29:06,291 train_utils.py: 271: Train Epoch: [46][30/45] | Batch Time: 7.23 (13.03) | Data Time: 0.00 (0.46) | Mem (GB): 42.00 (35.45/64.00) | Time Elapsed: 00d 07h 10m | Losses/train_all_loss: 5.76e-01 (2.23e+00)
INFO 2025-12-10 05:31:17,680 train_utils.py: 271: Train Epoch: [46][40/45] | Batch Time: 6.96 (13.06) | Data Time: 0.00 (0.35) | Mem (GB): 22.00 (33.51/64.00) | Time Elapsed: 00d 07h 12m | Losses/train_all_loss: 3.10e-01 (2.10e+00)
INFO 2025-12-10 05:32:09,785 trainer.py: 950: Estimated time remaining: 00d 00h 29m
INFO 2025-12-10 05:32:09,786 trainer.py: 892: Synchronizing meters
INFO 2025-12-10 05:32:09,786 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 2.069673366016812, 'Losses/train_all_loss_mask': 0.02460663674606217, 'Losses/train_all_loss_dice': 1.1570208612415525, 'Losses/train_all_loss_iou': 0.39178778645065093, 'Losses/train_all_loss_class': 0.028732047673255576, 'Losses/train_all_core_loss': 2.069673366016812, 'Trainer/where': 0.9395555555555555, 'Trainer/epoch': 46, 'Trainer/steps_train': 2115}
INFO 2025-12-10 05:32:32,408 train_utils.py: 271: Train Epoch: [47][ 0/45] | Batch Time: 21.55 (21.55) | Data Time: 8.35 (8.35) | Mem (GB): 28.00 (28.00/28.00) | Time Elapsed: 00d 07h 13m | Losses/train_all_loss: 2.40e+00 (2.40e+00)
INFO 2025-12-10 05:34:40,628 train_utils.py: 271: Train Epoch: [47][10/45] | Batch Time: 7.15 (13.62) | Data Time: 0.00 (0.76) | Mem (GB): 27.00 (36.91/62.00) | Time Elapsed: 00d 07h 15m | Losses/train_all_loss: 1.66e-01 (1.96e+00)
INFO 2025-12-10 05:37:10,086 train_utils.py: 271: Train Epoch: [47][20/45] | Batch Time: 7.21 (14.25) | Data Time: 0.00 (0.40) | Mem (GB): 35.00 (37.62/62.00) | Time Elapsed: 00d 07h 18m | Losses/train_all_loss: 6.98e-01 (2.18e+00)
INFO 2025-12-10 05:39:34,073 train_utils.py: 271: Train Epoch: [47][30/45] | Batch Time: 18.50 (14.30) | Data Time: 0.00 (0.27) | Mem (GB): 61.00 (37.61/62.00) | Time Elapsed: 00d 07h 20m | Losses/train_all_loss: 1.14e+00 (1.99e+00)
INFO 2025-12-10 05:41:40,153 train_utils.py: 271: Train Epoch: [47][40/45] | Batch Time: 18.10 (13.89) | Data Time: 0.00 (0.20) | Mem (GB): 32.00 (36.44/62.00) | Time Elapsed: 00d 07h 22m | Losses/train_all_loss: 5.13e+00 (2.08e+00)
INFO 2025-12-10 05:42:20,010 trainer.py: 950: Estimated time remaining: 00d 00h 20m
INFO 2025-12-10 05:42:20,011 trainer.py: 892: Synchronizing meters
INFO 2025-12-10 05:42:20,011 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 1.9756965107387967, 'Losses/train_all_loss_mask': 0.024504199303272696, 'Losses/train_all_loss_dice': 1.1324483619795904, 'Losses/train_all_loss_iou': 0.3527701422572136, 'Losses/train_all_loss_class': 0.0003940523975339369, 'Losses/train_all_core_loss': 1.9756965107387967, 'Trainer/where': 0.9595555555555555, 'Trainer/epoch': 47, 'Trainer/steps_train': 2160}
INFO 2025-12-10 05:42:47,949 train_utils.py: 271: Train Epoch: [48][ 0/45] | Batch Time: 26.86 (26.86) | Data Time: 7.62 (7.62) | Mem (GB): 33.00 (33.00/33.00) | Time Elapsed: 00d 07h 23m | Losses/train_all_loss: 1.79e+00 (1.79e+00)
INFO 2025-12-10 05:44:39,046 train_utils.py: 271: Train Epoch: [48][10/45] | Batch Time: 7.38 (12.54) | Data Time: 0.00 (0.69) | Mem (GB): 39.00 (33.45/54.00) | Time Elapsed: 00d 07h 25m | Losses/train_all_loss: 1.38e+00 (1.26e+00)
INFO 2025-12-10 05:46:35,252 train_utils.py: 271: Train Epoch: [48][20/45] | Batch Time: 18.24 (12.10) | Data Time: 0.00 (0.36) | Mem (GB): 33.00 (33.90/54.00) | Time Elapsed: 00d 07h 27m | Losses/train_all_loss: 3.51e+00 (1.58e+00)
INFO 2025-12-10 05:48:25,481 train_utils.py: 271: Train Epoch: [48][30/45] | Batch Time: 18.05 (11.75) | Data Time: 0.00 (0.25) | Mem (GB): 22.00 (32.61/54.00) | Time Elapsed: 00d 07h 29m | Losses/train_all_loss: 1.18e+00 (1.92e+00)
INFO 2025-12-10 05:50:10,292 train_utils.py: 271: Train Epoch: [48][40/45] | Batch Time: 18.39 (11.44) | Data Time: 0.00 (0.19) | Mem (GB): 32.00 (32.22/54.00) | Time Elapsed: 00d 07h 31m | Losses/train_all_loss: 2.24e+00 (1.67e+00)
INFO 2025-12-10 05:51:02,149 trainer.py: 950: Estimated time remaining: 00d 00h 08m
INFO 2025-12-10 05:51:02,150 trainer.py: 892: Synchronizing meters
INFO 2025-12-10 05:51:02,150 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 1.6441087216138839, 'Losses/train_all_loss_mask': 0.03345153697042002, 'Losses/train_all_loss_dice': 0.7208816432290607, 'Losses/train_all_loss_iou': 0.23884519781503413, 'Losses/train_all_loss_class': 0.015351176727374745, 'Losses/train_all_core_loss': 1.6441087216138839, 'Trainer/where': 0.9795555555555555, 'Trainer/epoch': 48, 'Trainer/steps_train': 2205}
INFO 2025-12-10 05:51:28,349 train_utils.py: 271: Train Epoch: [49][ 0/45] | Batch Time: 25.14 (25.14) | Data Time: 6.28 (6.28) | Mem (GB): 23.00 (23.00/23.00) | Time Elapsed: 00d 07h 32m | Losses/train_all_loss: 1.06e+00 (1.06e+00)
INFO 2025-12-10 05:53:02,621 train_utils.py: 271: Train Epoch: [49][10/45] | Batch Time: 7.35 (10.86) | Data Time: 0.00 (0.57) | Mem (GB): 42.00 (29.64/53.00) | Time Elapsed: 00d 07h 34m | Losses/train_all_loss: 4.96e-01 (1.93e+00)
INFO 2025-12-10 05:54:26,309 train_utils.py: 271: Train Epoch: [49][20/45] | Batch Time: 7.39 (9.67) | Data Time: 0.00 (0.30) | Mem (GB): 42.00 (31.52/53.00) | Time Elapsed: 00d 07h 35m | Losses/train_all_loss: 1.30e+00 (1.45e+00)
INFO 2025-12-10 05:56:16,136 train_utils.py: 271: Train Epoch: [49][30/45] | Batch Time: 7.02 (10.09) | Data Time: 0.00 (0.20) | Mem (GB): 15.00 (30.16/53.00) | Time Elapsed: 00d 07h 37m | Losses/train_all_loss: 1.18e+00 (1.29e+00)
INFO 2025-12-10 05:58:17,927 train_utils.py: 271: Train Epoch: [49][40/45] | Batch Time: 7.30 (10.60) | Data Time: 0.00 (0.15) | Mem (GB): 39.00 (31.78/54.00) | Time Elapsed: 00d 07h 39m | Losses/train_all_loss: 3.43e-01 (1.41e+00)
INFO 2025-12-10 05:58:52,943 trainer.py: 950: Estimated time remaining: 00d 00h 00m
INFO 2025-12-10 05:58:52,944 trainer.py: 892: Synchronizing meters
INFO 2025-12-10 05:58:52,944 trainer.py: 830: Losses and meters: {'Losses/train_all_loss': 1.3680843522151311, 'Losses/train_all_loss_mask': 0.014932820490664906, 'Losses/train_all_loss_dice': 0.7903685804870394, 'Losses/train_all_loss_iou': 0.2469409129685826, 'Losses/train_all_loss_class': 0.03211844278130195, 'Losses/train_all_core_loss': 1.3680843522151311, 'Trainer/where': 0.9995555555555555, 'Trainer/epoch': 49, 'Trainer/steps_train': 2250}
